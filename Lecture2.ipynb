{"cells":[{"cell_type":"markdown","metadata":{"_id":"FDCA025F718B4FC498E8A5BBE44A6E43","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E4F8B6B8488042CD9D19103E9E2E2986","notebookId":"66e2a33e20251d3377f9bcd3"},"source":" # <center>Lecture 2: Bayes' Rule  </center>  \n \n ## <center> Instructor: Dr. Hu Chuan-Peng  </center>"},{"cell_type":"markdown","metadata":{"_id":"9B23E8F257D24245B035991344E14DE8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0793EC332F134F5486D4824DD3E7239E","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"## Part 1: 【和鲸平台】整合教学+练习"},{"cell_type":"markdown","metadata":{"_id":"CBD7BE6CEACC42E3AF2D5C273FF36CB9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6D1D229B8C8F47E3AA334633E91FA2F2","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"本学期的贝叶斯课程将通过和鲸平台进行授课与代码练习，请大家提前注册好和鲸平台的账号。  \n\n关于和鲸平台的运行环境设置说明如下：  \n\n![Image Name](https://cdn.kesci.com/upload/sjmwr1smy0.jpeg?imageView2/0/w/960/h/960)  \n\n![Image Name](https://cdn.kesci.com/upload/sjmwr8pj5w.jpeg?imageView2/0/w/960/h/960)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"24FAE016A55E44179F8054656732F0B1","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E662E388971E45E781E0E99E9D80974D","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"更重要的是：任何问题都可以微信群或者平台里发帖提问。  \n\n助教和老师会尽快回复的 🚀。  \n\n\n![Image Name](https://cdn.kesci.com/upload/sjkvf5nlsl.jpeg?imageView2/0/w/960/h/960)  \n\n![Image Name](https://cdn.kesci.com/upload/sjkvfd5d65.jpeg?imageView2/0/w/960/h/960)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"3B3A1C3022C74C848C83413419C2C33F","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"29328C9BA0C74D72B73C52F983E9594B","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"当然，你也可以选择在gitee上进行提问。  \n点击链接访问gitee：  \nhttps://gitee.com/hcp4715/bayesian-analysis-nnupsy  \n\n![Image Name](https://cdn.kesci.com/upload/sjkvfsm4c1.jpeg?imageView2/0/w/960/h/960)  \n"},{"cell_type":"markdown","metadata":{"_id":"959962DB732A4DB59441904EFB17C296","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"75CB2F48CBC849B3BA8DFAA69BDF97A5","notebookId":"66e2a33e20251d3377f9bcd3"},"source":" ## Part 2: 单一事件的贝叶斯模型"},{"cell_type":"markdown","metadata":{"_id":"97A69A3273D64E7AA2D2CC8C6977E4B9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"35FE34ED85D846529BCB77BAC72DD505","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"## **“让我们从一个每个人都熟悉的事件开始”**  \n\n读文献时，大家是否有一个疑问：我看到的这个文章靠谱吗？  \n\n![Image Name](https://cdn.kesci.com/upload/sjpbvjqzx2.jpg?imageView2/0/w/640/h/640)  \n"},{"cell_type":"markdown","metadata":{"_id":"2E3BD9AE42324A669E83F4E27A2D3047","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BF380D74CF2C4A9FBF42BA0B04EEF62A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"2015年，**开放科学合作组织（Open Science Collaboration）** 在《Science》杂志上发表文章，发现只有**36%～47%** 的认知/社会心理学研究成果能被成功重复。  \n\n![Image Name](https://cdn.kesci.com/upload/sjos6fmkbs.png?imageView2/0/w/960/h/960)  \n\n\n> Open Science Collaboration ,Estimating the reproducibility of psychological science.Science349,aac4716(2015).DOI:10.1126/science.aac4716"},{"cell_type":"markdown","metadata":{"_id":"927FC0DD195D47A09AFCAFEECAA90F9E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7CE3DA38E0B2491F91B90C404D587C04","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"以这个论文为代表的系列讨论，引发了关于心理学“可重复性危机”的讨论[(胡传鹏等, 2018)](https://journal.psych.ac.cn/xlkxjz/CN/10.3724/SP.J.1042.2016.01504)。  \n\n知道这个事实之后，对我们阅读文章时对结果的信念是否产生了影响？  \n\n假设我们认同Science这个文章的结论，初步认为大约**40%** 的心理学实验是可重复的。我们以这个数据作为我们对文章的初步“信念”。  \n\n新的关于心理学研究可重复性的研究是否会进一步改变我们的信念？"},{"cell_type":"markdown","metadata":{"_id":"A17CA82F36AF4B1B9D9D426183B62303","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"33E2FA2D81B24BFC8BE7506AD7067333","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"2024年，一项针对299项预注册的重复实验数据的研究发现，可重复研究通常以自信、透明和确切的语言撰写，而不可重复的研究则往往表现出模糊性，并使用“边缘型”的说服技巧。  \n\n这个新研究可能帮助我们**更新**对心理学科学论文的预测。  \n\n假定我们现在从上述299个文章中抽取出一篇论文，我们会如何评估它的可重复性？  \n\n![Image Name](https://cdn.kesci.com/upload/sjoly6dhft.png?imageView2/0/w/960/h/960)  \n\n\n> Herzenstein, M., Rosario, S., Oblander, S., & Netzer, O. (2024). The language of (non)replicable social science. Psychological Science, 9567976241254037. https://doi.org/10.1177/09567976241254037  \n"},{"cell_type":"markdown","metadata":{"_id":"0431DA1DBB18442E8023EB69490F4AB1","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FD4775D522334DD4B3EC8AC45E839745","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"基于我们第一个研究（即认为大约40%的研究可以重复）和新证据（可重复性研究通常使用确切语言撰写），我们对随机抽取出的一项研究的可重复性的态度怎样呢？  \n\n假如我们仅根据*Science*的研究结果，我们可能会认为这项研究大约有40%可能性被重复出来？但是这意味着2024年新研究的信息没有被用上。  "},{"cell_type":"markdown","metadata":{"_id":"8276AE623A8941DD95D88D69E9C128F5","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5262601EB1094639B1C686E29F69625F","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"根据Herzenstein 等（2024）的研究结果，可重复的研究中，有56%的文章使用确切的语言风格；在不可重复的研究中，使用确切语言的比例为为45%。  \n\n根据这些信息，我们可以得到以下几个关键信息：  \n- 心理学研究可重复的概率为40%  \n- 心理学研究不可重复的概率为60%  \n- 可重复的研究中，使用确切语言的概率为56%  \n- 不可重复的研究中，使用确切语言的概率为45%  \n\n\n![Image Name](https://cdn.kesci.com/upload/sjoxpj2ivv.png?imageView2/0/w/640/h/640)"},{"cell_type":"markdown","metadata":{"_id":"21789174E0044E24B1CA5DDC803C1D4F","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"56CABB2E8F9848D49A4224A5CB86290A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"根据上述信息，现在我们可以进行以下的简单的运算：  \n\n- 研究可重复且使用确切语言的概率 $P = 0.40 \\times 0.56 = 0.224$  \n- 研究可重复但不使用确切语言的概率 $P= 0.40 * (1-0.56) = 0.176$  \n- 研究不可重复但使用确切语言的概率 $P= 0.60 * 0.45 = 0.27$  \n- 研究不可重复且不使用确切语言的概率 $P= 0.60 * (1-0.45) = 0.33$  \n\n\n![Image Name](https://cdn.kesci.com/upload/sjp0bqwjgl.png?imageView2/0/w/960/h/960)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"9A966B81FDF3433B90DB37EEA7449D65","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4FED68E9B5564EA5A89966F0B61D2456","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"假如我们抽取出一个文章使用了确切的语言风格，我们认为它可重复的可能性是多少呢？  \n\n$0.224/(0.224 + 0.27) = 0.453$"},{"cell_type":"markdown","metadata":{"_id":"7B86ECDD3D8C4CF4BC570379B7B8D4E0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F9D74B5B396248E49B17B611076F1219","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"在这个简单的例子当中，我们实际进行了一次“贝叶斯的证据更新”。  \n\n接下来我们再来重新审视一下这个事例。  \n\n我们选取Herzenstein 等（2024）年的部分真实数据进行探索，包括研究的编号 (title)，文章是否可被重复 (replicated), 文章结果描述的确切性 (certain)和文章表述的积极性 (posemo)。"},{"cell_type":"code","metadata":{"_id":"6650178E299B46A59FCD49B10A2F19CA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"815A3953C99A4A35992FC2997978F49B","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 非选课的同学，可以使用和鲸社区的Python镜像，运行以下的代码安装必要的模块，需要3-5分钟的时间完成加载\n# 后续会有专门的社区公开镜像，给大家提前配置好运行环境\n# 将下列代码行解除注释，删除“#”，运行即可：\n# !conda install -y graphviz bambi=0.13.0 pymc=5.16.2 PreliZ=0.9.0 ipympl=0.9.4 pingouin=0.5.4\n\n# docker部署和使用教程链接：https://zhuanlan.zhihu.com/p/719739087\n# docker pull hcp4715/pybaysian:latest\n# docker run -it --rm -p 8888:8888 hcp4715/pybaysian:latest","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"_id":"5E2EC868AAD6488CA5E5DFADCF965A1A","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F8749D8459D54D3D9AFC8C3F06B049E9","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 导入数据加载和处理包：pandas\nimport pandas as pd\n# 导入数字和向量处理包：numpy\nimport numpy as np\n# 导入基本绘图工具：matplotlib\nimport matplotlib.pyplot as plt\n\n# 使用 pandas 导入示例数据\ntry:\n  df = pd.read_csv(\"/home/mw/input/bayes3797/replicated_language_cleaned.csv\")  #TODO: 修改为和鲸平台数据路径\nexcept:\n  df= pd.read_csv('data/replicated_language_cleaned.csv')\n\ndf = df.drop('study_name', axis=1)\ndf.head()\n\n# 设置APA 7的画图样式\nplt.rcParams.update({\n    'figure.figsize': (4, 3),      # 设置画布大小\n    'font.size': 12,               # 设置字体大小\n    'axes.titlesize': 12,          # 标题字体大小\n    'axes.labelsize': 12,          # 轴标签字体大小\n    'xtick.labelsize': 12,         # x轴刻度字体大小\n    'ytick.labelsize': 12,         # y轴刻度字体大小\n    'lines.linewidth': 1,          # 线宽\n    'axes.linewidth': 1,           # 轴线宽度\n    'axes.edgecolor': 'black',     # 设置轴线颜色为黑色\n    'axes.facecolor': 'white',     # 轴背景颜色（白色）\n    'xtick.direction': 'in',       # x轴刻度线向内\n    'ytick.direction': 'out',      # y轴刻度线向内和向外\n    'xtick.major.size': 6,         # x轴主刻度线长度\n    'ytick.major.size': 6,         # y轴主刻度线长度\n    'xtick.minor.size': 4,         # x轴次刻度线长度（如果启用次刻度线）\n    'ytick.minor.size': 4,         # y轴次刻度线长度（如果启用次刻度线）\n    'xtick.major.width': 1,        # x轴主刻度线宽度\n    'ytick.major.width': 1,        # y轴主刻度线宽度\n    'xtick.minor.width': 0.5,      # x轴次刻度线宽度（如果启用次刻度线）\n    'ytick.minor.width': 0.5,      # y轴次刻度线宽度（如果启用次刻度线）\n    'ytick.labelleft': True,       # y轴标签左侧显示\n    'ytick.labelright': False      # 禁用y轴标签右侧显示\n})","outputs":[],"execution_count":2},{"cell_type":"code","metadata":{"_id":"7220F66CE63E4264AD38AC5B6A7C50A3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"68244846B25C4429B5ADF40C632D8EEF","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"df.head()","outputs":[],"execution_count":3},{"cell_type":"markdown","metadata":{"_id":"D1AB055B5890484881A9BA656B67D054","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F095F45E4117482FA0B3DD46192C2ECD","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 先验 (prior) 和 数据 (data)  \n\n重新回顾我们要评估的事件：我们认为从299项心理学研究中随机选出来的一项研究的可重复性如何？  \n\n在评估这个事件之前，我们知道Science于2015年发表了一个大规模重复实验，发现40%的心理学研究是可以被重复出来。  \n\n对于这这299项研究，它们有不同的语言风格："},{"cell_type":"code","metadata":{"_id":"69527C9D804D4A6B931487113C2E71BF","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3448FCA98DD44AD69A2850750226BF8C","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 数据预处理\n# 计算 'certain' 列的中位数\nmedian_certain = df['certain'].median()\n\n# 创建新列，编码规则：大于中位数为 1，小于等于中位数为 2\ndf['language_style'] = df['certain'].apply(lambda x: 1 if x > median_certain else 0)\n\n# 输出结果\ndf.head()","outputs":[],"execution_count":4},{"cell_type":"markdown","metadata":{"_id":"7D0BAB067DCB4951B131492739ACE9A6","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9291DCAAF9BA4F5F9CB65D7C124C70CD","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"研究能否被重复出来，与他们的语言风格有关系：  \n\n有 56%（71/126）的能被重复的研究使用了确切的语言风格；  \n\n约45%（78/173）的不能被重复研究使用了确切的语言风格。"},{"cell_type":"code","metadata":{"_id":"EE563704B3464650B00D8CDEB623D3E9","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"562CCA052A1A42BCAA2B97539F4A7754","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 计算不同水平的数量和百分比\nlevel_counts = df['replicated'].value_counts()\nlevel_percentages = df['replicated'].value_counts(normalize=True) * 100\n\n# 百分比保留两位小数\nlevel_percentages = level_percentages.round(2)\n\n# 创建一个新的 DataFrame 合并结果\nresult_df1 = pd.DataFrame({'数量': level_counts, '百分比': level_percentages})\n# 展示结果(0代表不可重复，1代表可重复)\nresult_df1","outputs":[],"execution_count":5},{"cell_type":"code","metadata":{"_id":"3216FB04D2094FABBE7FBDE352C58000","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"67FFF9B961E74B40BC197AD18B8207A8","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 计算不同水平的数量\nresult_df2 = df.groupby(['replicated', 'language_style']).size().unstack()\n# 结果\nresult_df2","outputs":[],"execution_count":6},{"cell_type":"markdown","metadata":{"_id":"D7B1CA15338E40EC923C2CD12E25E9C3","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"392C390F23524BAE8C89270E7B657008","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 先验 (prior) 和 数据 (data)  \n\n#### 先验  \n\n在我们这个事件中，我们评估某项研究可重复性之前，我们关于研究可重复性的信念，在贝叶斯统计中被称为先验（prior）。  \n\n假设我们的信念被2015年Science的文章所影响，相信约40%的心理学实验是可重复的。这就是我们开始了解这项研究前的信念。  \n\n- 先验（prior）：指没有观察到具体数据之前，根据已有知识、经验或主观判断对某个事件发生概率的初步估计。  \n\n本例中，40%的估计代表了我们基于已有文献和领域经验的先验信念——即在没有观察具体文章之前，推测它有40%的研究能够成功重复。  \n"},{"cell_type":"markdown","metadata":{"_id":"3AFE8BA367D04C728F6936BFE83C68D8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"03076DE5CF77444C96770713132240EB","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 先验 vs 数据  \n\n在了解到被评估的研究来自Herzenstein 等（2024）之后，我们又获得了新的信息，这个新信息我们将其称为数据（data）。  \n\n此时，我们会有两个信息：  \n\n- 先验信息 (prior)：约 40% 的研究是可重复。  \n- 数据 (data) ：有 56%能被重复的研究使用了确切的语言风格；约45%不能被重复研究使用了确切的语言风格。  \n\n我们会如何推断？"},{"cell_type":"markdown","metadata":{"_id":"B32FEE0C2D57457A83455C875FB2E8E8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8817CBA6832C47D8853760AD9894E7C9","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"在先验和数据之间找到平衡？  \n\n这正是贝叶斯的思路：基于数据对先验进行更新。  \n\n$$  \nPosterior = \\frac {data * \\, prior}{Average \\, probability \\, of \\, data}  \n$$  \n\n![Image Name](https://cdn.kesci.com/upload/sjkvl0f6gx.png?imageView2/0/w/960/h/960)  "},{"cell_type":"markdown","metadata":{"_id":"3CC4CAB875C945868176443036FE5CEF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EBBEE37621AD43A9B03937BD8CF8C3E8","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 先验概率(Prior probability)  \n我们现在使用更加正式一点的语言来对上述的信息进行描述：  \n\n假如一项心理学研究**能**被其他研究者独立地重复出来，我们认为一个特定的事件发生了。  \n\n我们将这个事件使用$B$来表示。  \n\n假如一项心理学研究**不能**被其他研究者独立地重复出来，我们认为一个特定的事件**没有**发生了，使用符号$B^{c}$(B的补集complement)。  \n\n根据Science于2015年的文章，我们可以得以下公式：  \n\n$$  \nP(B) = 0.40 \\\\  \n\nP(B^{c}) = 0.60  \n$$  "},{"cell_type":"markdown","metadata":{"_id":"84A1E61DCF1B49E3961E5D2DE1354729","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EF2E3E6E94E54C7F8E3C74E033E50A26","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"<style>  \ntable {  \n    width: 100%;  \n    table-layout: auto;  \n}  \n</style>  \n\n| 事件       | **$B$**   | **$B^{c}$** | **Total** |  \n|------------|-----------|-------------|-----------|  \n| **probability** | **0.4** | **0.6**     | **1**     |  \n\n\n换一句话说，在我们对需要被评估的研究进行评估前，我们关于事件$B$的先验信念是$P(B)$，这也被称为先验模型(prior model)  \n\n作为一个有效的概率模型(valid probability model)，它必须：  \n\n（1）考虑所有可能的事件（所有文章都必须是可重复或不可重复的，没有其他可能性）；  \n\n（2）它为每个事件分配先验概率；  \n\n（3）这些概率加起来为1。"},{"cell_type":"markdown","metadata":{"_id":"194A3554CB3042419CEE8B257085C841","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7C17C2355E7145E695A4ADC53CF603D4","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 数据模型（条件概率与似然性）  \n\n借鉴先验模型的构建方式，我们同样可以采用模型（即公式）对关于目标研究的新信息进行正式地描述。  \n- 我们用符号 $A$ 表示研究中使用了确切的语言风格。  \n\n我们要将如下一句话的信息进行形式化：  \n\n**有 56%能被重复的研究使用了确切的语言风格；约45%不能被重复研究使用了确切的语言风格。**  \n\n**有 56%能被重复的研究使用了确切的语言风格，44%的能被重复的研究没有使用确切的语言风格；约45%不能被重复研究使用了确切的语言风格；55%的不能被重复的研究没有使用确切的语言风格。**  \n\n将数据形式化，通过条件概率来量化文章展现出语言确切的可能性。具体如下：  \n\n$$  \nP(A|B) \\approx 56\\%  \n$$  \n- 当研究是可重复的，使用确切语言的概率大约 56%。  \n\n$$  \nP(A|B^{c}) \\approx 45\\%  \n$$  \n- 在研究不可重复的情况下，使用确切语言的概率大约为 45%。  \n"},{"cell_type":"markdown","metadata":{"_id":"7F15AB569AC94A4FB3ECAE20E73A67A9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"809B959C697A46DD9A280E90884DA9A6","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"\n\n![Image Name](https://cdn.kesci.com/upload/sjq96jfv8f.png?imageView2/0/w/960/h/960)  \n"},{"cell_type":"markdown","metadata":{"_id":"2B6980037F1B43238F991D9DF01B5581","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FB3522A611E54AFDB00A13B974283B53","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 条件概率  \n\n条件概率：给定某个条件下发生另一件事情的概率。  \n注意：条件概率的定义是有顺序的，$P(A|B)$ 与 $P(B|A)$ 并不相等。  \n\n例如：  \n- $P(A|B)$ 表示在研究可重复的情况下，使用确切语言的概率；  \n- $P(B|A)$ 表示的是在研究使用确切语言的情况下，该研究是可重复的概率。  \n\n很多时候，人们容易混淆这两者，尤其在贝叶斯推理中。因此，清楚条件的前提和结果是很重要的。"},{"cell_type":"markdown","metadata":{"_id":"FF041A9D25BC4D26B5B16147482E99AF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7C0F115AD5FA475EAB64AEA1E16784CF","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 似然(likelihood)  \n\n**似然的定义**  \n\n从条件概率中，我们知道 $P(A|B) = 0.56$ 和 $P(A|B^c) = 0.45$，即使用确切语言的研究更可能是可重复的。  \n\n似然（likelihood）描述的是在不同假设下，某个数据模式出现的可能性。在这个例子中，我们比较两种假设:  \n- $P(A|B) = 0.56$：在可重复研究的假设下，使用确切语言的概率较高。  \n- $P(A|B^c) = 0.45$：在不可重复研究的假设下，使用确切语言的概率较低。  \n\n因此，似然函数表明：当前数据模式（使用确切语言）在可重复的假设下更可能出现：  \n$P(A|B) = 0.56 > P(A|B^{c}) = 0.45$  \n\n这就是似然函数(likelihood function)的核心：反映了在不同的假设（可重复或不可重复）下，某个数据$A$出现的可能性。  \n"},{"cell_type":"markdown","metadata":{"_id":"EBF5574E5D514D099F1E542A25C73CB2","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"772B0BD0EFB143549649D45CD1811BEB","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"例如，针对“数据 A：研究使用确切语言”的似然可以写成：$L(*|A)$  \n$$  \nL(B|A) = P(A|B) \\quad\\quad L(B^{c}|A) = P(A|B^{c})  \n$$  \n\n上述两个式子分别表示在“研究可重复”和“研究不可重复”两种可能的情况下，使用确切语言的概率。  \n\n*注意，在似然函数中，数据是已知发生的，而假设是可能发生的"},{"cell_type":"markdown","metadata":{"_id":"522E8487320A4C03B55370205BC70957","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A87B5B372CA045F8ABF2094F62623BA8","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 概率(Probability) vs 似然(likelihood)  \n\n🤔概率和似然似乎都在表示某种可能性，它们的区别是什么呢？  \n  \n| 特性        | 概率 (Probability)                                      | 似然 (Likelihood)                                   |  \n|-------------|---------------------------------------------------------|----------------------------------------------------|  \n| 定义        | 已知假设条件，得到某个数据的可能性                           | 已知数据，不同假设条件下得到该数据的可能性     |  \n| 范围        | [0, 1]                                                 | 不限于 [0, 1]                                     |  \n| 总和        | 所有可能事件的总和为1                                  | 可以不等于1                                       |  \n| 应用        | 预测和决策                                           | 模型估计和选择                                     |  \n\n注意：  \n* 先验概率的总和等于1，因为先验表示所有可能结果的分布，表示事件B发生的概率，是我们的主观推测；  \n* 似然总和不等于1，因为似然函数不是概率函数，它告诉我们事件A在不同假设下发生的相对可能性。"},{"cell_type":"markdown","metadata":{"_id":"9C6D03A81823448BAF841D0A31BB7935","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AEC78CD413B44D44BBB2DDAC7F154C5A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"根据我们的例子，概率和似然可以整理为下表：  \n\nTABLE 2.2: Prior probabilities and likelihoods of reproducible research.  \n\n| event       |     $B$     |     $B^c$   |   total   |  \n|-------------|--------------|--------------|-----------|  \n| prior       |      0.4    |      0.6     |     1     |  \n| likelihood   |     0.56    |     0.45     |   ≠ 1     |"},{"cell_type":"markdown","metadata":{"_id":"5D88441C0EE945FCA95BD99A5040421D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3E77E01930C04D07A809FA6CBF39E526","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"## 分母（normalizing constant）-- 边际概率 (marginal probability)  \n\n似然函数描述了在可重复性研究和不可重复研究中使用确切语言的情况。  \n\n我们想知道的是：所有研究中使用自信语言的总体可能性是多少。  \n\n这被称为边际概率 $P(A)$"},{"cell_type":"markdown","metadata":{"_id":"BF86779031B04107B1939DF117337534","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4C05FBDC128148D48722A6933F1659FF","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们要做的，就是把每个假设下出现事件$A$的似然与每个假设本身的概率相乘（即把每个假设自身的概念纳入考虑），这两者之和即为边际概率。  \n$$  \n P(A) = P(A \\cap B) + P(A \\cap B^{c}) = L(B|A) * P(B) + L(B^{c} | A) * P(B^{c})  \n$$  \n\n$$ P(A) = 0.56 * 0.4 + 0.45* 0.6 = 0.494 $$  \n"},{"cell_type":"markdown","metadata":{"_id":"AE1A881A0B5049E188536745016CA9B7","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5586790CCFEA41C290E938A231FCC766","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 后验概率模型(Posterior probability model via Bayes’ Rule)"},{"cell_type":"markdown","metadata":{"_id":"215AEDEE85144A8B8EF61191D2C0D7BC","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D1F5981E41D2456D80F8FFF2C2940E0A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**直觉理解**  \n\n最后，我们来计算后事件$B$的后验概率，即，当我们知道某个研究使用了确切的语言风格之后，它能被重复的可能性是多少？  \n\n我们同样通过条件概率来描述它：$P(B|A)$。  \n\n在正式计算之前，我们可以回顾一下这个表格来建立一些直觉。   \n\n||$B$|$B^c$|Total|  \n|---|---|---|---|  \n|$A$|0.56 * 0.4 = 0.224|0.45* 0.6 = 0.27|0.494|  \n|$A^c$|0.176|0.33|0.506|  \n|Total|0.4|0.6|1.0|  \n\nnote：  \n- $A$ ：表示使用确切语言的研究。  \n- $A^c$ ：表示不使用确切语言的研究。  \n- $B$ ：表示研究是可重复的。  \n- $B^c$ ：表示研究不可重复的。  \n\n因为我们知道这项研究**使用确切语言风格**，所以我们直接锁定第一行，  \n- 在A行中，45.3%(0.224/0.494)的研究是可重复的，35.6%(0.176/0.494)的研究是不可重复的。  \n- 因此，根据后验概率 45.3%的可能性可以认为当前这一研究是可重复的。  \n"},{"cell_type":"markdown","metadata":{"_id":"2F6FEE1196FF413D9DC75E49DE27510D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C455B482525B4954AF0EA628B88174EA","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**正式计算**  \n\n如何凭借贝叶斯公式的数学形式推导得到该结果？  \n\n$$  \nPosterior \\sim P(B|A) = \\frac {data * prior}{Average \\, probability \\, of \\, data} ={\\frac{P(A\\cap B)}{P(A)}}={\\frac{L(B|A) * P(B)}{L(B|A) * P(B) + L(B^{c}|A) * P(B^{c})}}  \n$$  \n\n- $P(B|A)={\\frac{P(B)L(B|A)}{P(A)}}={\\frac{0.4\\cdot0.56}{0.494}}=0.453$  \n- 当带入之前计算得到的数值到贝叶斯公式中，我们得到了确切语言为不可重复研究的概率。  \n\n"},{"cell_type":"markdown","metadata":{"id":"EBFC7EE115B34FC4A4AA3FCF1F28A0AC","notebookId":"66e2a33e20251d3377f9bcd3","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"使用同样的方法，我们可以计算出未使用确切语言的研究为不可重复研究的概率，结果如下表。  \n- 可以注意到：先验概率和后验概率的和均等于1。  \n\nTABLE 2.4: The prior and posterior models of reproducibility.  \n\n\n| event    | $B$     | $B^c$ | Total    |  \n| --------  | -------- | -------- | -------- |  \n| prior probability | 0.4 | 0.6 | 1 |  \n| posterior probability | 0.453 | 0.547 | 1 |  \n"},{"cell_type":"markdown","metadata":{"_id":"3845FF266B2F4EC5A5A0B278B058A20D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8E19784675504B2E870A718BAA62D60F","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"思考时间🧐：是否加入分母的意义何在？"},{"cell_type":"markdown","metadata":{"_id":"CEB912EE1CC941F6981238ACA99290B0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8EFC71CE60D746A59B54C45313092A12","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 后验概率计算模拟练习  \n\n\n🤓为了深入理解先验知识、似然（数据）和后验概率，我们将通过编写代码来计算后验概率，以增强对这些概念的理解和实践能力。"},{"cell_type":"markdown","metadata":{"_id":"014643A57C28407E8B3FFABE2013D299","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FD752BB7473949E785ABBD6DA3926CFF","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"1. 定义研究的可重复性与相应的先验概率"},{"cell_type":"code","metadata":{"_id":"73947288991047B59848C3816D23BCFA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"863A7F94BE3B4732A8AF0B10B2F7DAAF","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 定义文章类型\narticle = pd.DataFrame({'replicated': ['yes', 'no']})\n\n# 定义先验概率\nprior = [0.6, 0.4]","outputs":[],"execution_count":7},{"cell_type":"markdown","metadata":{"_id":"778C6170F14C43CC947B8E9A3A624813","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"96F4A9677B384D0DAF822BA0CC9FD24A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"2. 模拟一些可能被投放给你的研究"},{"cell_type":"code","metadata":{"_id":"5FE6653043FA4C9AB98D071433A517EC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"2B26BE6D49FD43248CAB53AC4343A5B9","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 模拟生成 10000 项研究，包括其类型\nnp.random.seed(84735)\narticle_sim = article.sample(n=10000, weights=prior, replace=True)\n# 查看前 10 行数据\narticle_sim.head(10)","outputs":[],"execution_count":8},{"cell_type":"code","metadata":{"_id":"0798D80080374E6DB278A4BD30AFD568","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7F11556E45D04365AAD2F5EFA83247CB","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"#我们可以通过画图来查看这些被投放研究的可重复性比例。\narticle_sim['replicated'].value_counts().plot.bar()\nplt.xticks(rotation=0)\nplt.show()","outputs":[],"execution_count":9},{"cell_type":"markdown","metadata":{"_id":"A67F09F99463465D922E85F27AA61FAA","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F85E16D4530A4714935DADF9B149A816","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"3. 接下来我们需要模拟10000项研究使用确切语言风格的情况，  \n- 和之前相同，不可重复研究使用确切语言风格的可能性为45% ，  \n- 可重复研究使用确切语言风格的可能性为56% "},{"cell_type":"code","metadata":{"_id":"EDE9730D549649EAA93AD55395737CD7","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3F653B32D5A34B4BB551204E3F9BD2F6","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 设置条件概率\narticle_sim['data_model'] = np.where(article_sim['replicated'] == 'no', 0.2667, 0.222)\n\n# 定义研究是否使用确切语言\ndata = ['certain', 'uncertain']\n\n# 设置随机种子，以便得到重复的结果\nrng=np.random.default_rng(84735)\n# 生成确切语言相关的数据\narticle_sim['language'] = article_sim.apply(lambda x: rng.choice(data, 1, p = [x.data_model, 1-x.data_model])[0], axis=1)","outputs":[],"execution_count":10},{"cell_type":"code","metadata":{"_id":"E1F09028FF044BED8FFB4AE3E0CB8988","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"530464C930C94A3FB224DEB9D4375C0B","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 显示每个类别研究数量\n(\n  article_sim.groupby(['language', 'replicated'])\n    .size()\n    .unstack(fill_value=0)\n)","outputs":[],"execution_count":11},{"cell_type":"markdown","metadata":{"_id":"DE820DB7BC9A4260A72A97A92D175958","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BA37F8669EF94A479477718819C05BA5","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"4. 计算后验值  \n\n还记得我们的先验概率为：  \n- 可重复研究  $P(B)=0.4$  \n- 不可重复性研究 $P(B^c)=0.6$,  \n\n由以上结果可计算似然：  \n- 大约26%(1039/(1039+2899))的可重复性研究使用了确切语言, $P(A|B)=0.26$  \n- 22%的不可重复性研究使用确切语言(1360/(1360+4702)), $P(A|B^c)=0.224$"},{"cell_type":"markdown","metadata":{"_id":"491F9BD4FC4249B2A816ABEC734F72C5","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7D7AEC554C954B619CD044759F04C353","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"结合先验和似然，我们可以进一步计算分母(边际概率)：  \n- $L(B|A)*P(B) + L(B^{c}|A)*P(B^{c}) = 0.26*0.4 + 0.22*0.6 = 0.104 + 0.132 = 0.236$  \n\n最后，我们可以计算的到后验 (使用确切语言研究中，可重复性研究的概率)：  \n- $P(B|A) ={\\frac{L(B|A)*P(B)}{P(A)}}= (0.26*0.4)/0.236 = 44\\%$  \n- 在10000项研究中，使用确切语言的研究有2399篇(分母)  \n- 而现在，我们可以知道，在使用确切语言的研究中，43%(1039/2399)的研究为可重复研究"},{"cell_type":"code","metadata":{"_id":"463C518551694032AF27D25FB04F8AE7","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DD9955C584EC46AD8329CA4AD6ED05D3","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"usage_yes = article_sim[article_sim['language'] == 'certain']\nprint('使用确切语言的研究', usage_yes['replicated'].value_counts().sum())\nusage_yes['replicated'].value_counts()","outputs":[],"execution_count":12},{"cell_type":"markdown","metadata":{"_id":"4F9AD7BE225841788D37CEEDC528748B","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"29E6D172887A4B15BC632BAAC26842FB","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"同样地，通过画图来可视化使用确切语言的研究的情况"},{"cell_type":"code","metadata":{"_id":"0AEE39A369D24936AB824323E939DB11","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"93E0B8A984D94694B7671BCC4FEA492D","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 定义两幅图的坐标\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n# 绘制两幅图\nfor i, u in enumerate(article_sim['language'].unique()):\n    ax = axes[i]\n    data = article_sim[article_sim['language'] == u]\n    ax.bar(data['replicated'].unique(), data['replicated'].value_counts())\n    ax.set_title(f'language = {u}')\n    ax.set_ylim(0, 10000) \n\n# 显示   \nfig.tight_layout()\nplt.show()","outputs":[],"execution_count":13},{"cell_type":"markdown","metadata":{"_id":"E8021516E6B64E539FC5521887F739E6","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A04BC72A2FC840A19792EF755B92375B","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 总结 (Recap)  \n\n回到之前的问题：如何预测研究的可重复性？  \n\n\n\n![Image Name](https://cdn.kesci.com/upload/sjq96jfv8f.png?imageView2/0/w/960/h/960)  \n\n\n\n- 哪些信念可以作为先验概率？  \n- 信息的哪些属性可以作为数据？  \n- 如何结合先验和数据更新信念 (贝叶斯公式)。  "},{"cell_type":"markdown","metadata":{"_id":"9116A7CE222F4BDE8B8E3607286E0966","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"21474CBB768449D28D1F227B8625F2E6","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"## Part3 随机变量的贝叶斯模型"},{"cell_type":"markdown","metadata":{"_id":"E3B392ED97F84AE2A0B122A3581A9C4E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BFEE9BF88DCB4EB3875CCBC6C98C2E36","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**随机变量 (random variables)**  \n\n在之前的分析中，我们讨论的是对某项研究的“可重复性”这样一个单一事件。  \n\n同样的逻辑可以应用于更加抽象和一般性的**随机变量**进行分析。  \n\n假设为了研究可重复性问题，一个有能力且资金充足的研究团队计划进行一系列可重复性实验，他们希望知道这些实验成功重复的比例是多少。  \n\n首先我们来了解一个概念，胜率或成功率  \n\n* 想象你玩斗地主，有五局三胜，七局四胜这一说，一轮玩下来，就会出现胜率。  \n* 然而，胜率并不是一成不变的，它会随着每次游戏的输赢而变化。  \n* 在每一轮开始前，你并不会知道你这次的胜率是多少  "},{"cell_type":"markdown","metadata":{"_id":"3FD06461908142E698C9D59BBF2E0D18","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"08B2603E291D464C83E8A5352F28036F","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"在我们的例子中，假设计划对6项研究进行重复实验。  \n- 假设该团队对于任何研究成功复现的成功率为$\\pi$，$\\pi$是**未知的且可能会变化**，所以$\\pi$是一个随机变量。  \n- 根据团队先前的经验以及心理学研究的现状，我们猜测其成功复现的成功率为 $\\pi = 50\\%$。  \n- 他接下来可能成功复现的次数$Y$可能是0，可能是1，也可能是6，可以有7种可能的成功复现次数，$Y \\in \\{0,1,2,3,4,5,6\\}$ "},{"cell_type":"markdown","metadata":{"_id":"5097DA54E0F443E7A8E87A5310133378","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C849EAA82218450D900431AA0BA3B04B","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"🤔虽然我们知道他们的平均成功率为 $\\pi = 50\\%$，但问题在于，对于每一种复现成功的次数（1 ～ 6），其可能性分别是多少呢？ "},{"cell_type":"markdown","metadata":{"_id":"713A6C44D59C4EDAB7EE7E6B0770503F","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6C5BE22FFF0F41EC934506516A17995D","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**二项式模型**  \n\n由于每次重复实验，结果只有两种可能：成功 vs 失败。  \n\n该团队总共进行6次重复实验，我们想要知道的是成功1次，成功2次，成功3次，...，的概率。  \n\n对于这种情况，我们可以用二项分布来分析。  \n"},{"cell_type":"markdown","metadata":{"_id":"D03769BD6D2B4C808F77AC844D213504","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E1758CB2595A421895A42B76B38C20C7","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"该团队的成功率为$\\pi$，$在\\pi$下某成功次数发生的概率可表示为：  \n\n$$  \nf(y|\\pi) = \\binom{n}{y} \\pi^{y}(1-\\pi)^{n-y} \\quad\\quad for\\;y \\in \\{0,1,2,...,n\\}  \n$$  \n$$  \n\\binom{n}{y} = \\frac{n!}{y!(n-y)!}  \n$$  \n\n$\\pi$ 表示成功的可能性，$y$表示在$n$个试次中成功的次数，二项模型含有的前提假设是：  \n\n(1) 所有试次发生都是相互独立的  \n\n(2) 在每个试次中，成功的概率都是一个固定的值$\\pi$  "},{"cell_type":"markdown","metadata":{"_id":"B192E3FF5B4F439391B43E16A0B1A2A7","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E3E2DD0488A44BDB943815416004F6F6","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"成功次数为0~6 的可能性可以分别写成：  \n\n$$  \nf(Y=0|\\pi=0.5) = \\binom{6}{0} 0.5^0 (1-0.5)^{6}  \n$$  \n$$  \nf(Y=1|\\pi=0.5) = \\binom{6}{1} 0.5^1 (1-0.5)^{5}  \n$$  \n$$  \n...  \n$$  \n$$  \nf(Y=5|\\pi=0.5) = \\binom{6}{5} 0.5^{5} (1-0.5)^{1}  \n$$  \n$$  \nf(Y=6|\\pi=0.5) = \\binom{6}{6} 0.5^{6} (1-0.5)^{0}  \n$$  "},{"cell_type":"markdown","metadata":{"_id":"8D0F65AFF8784B9AA6D5DDC0D0B530D8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F9F9CB55F2864F2D9677A56D092266E6","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们可以使用代码帮助计算  \n `st.binom.pmf(y, n, p)`。其中 p 对应公式中的 $\\pi$。"},{"cell_type":"code","metadata":{"_id":"9B6ABDBAC2184D748BC14210FEC09798","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CC0A39BA5BB749F1A6FD32F6383FEB8D","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 导入数据加载和处理包：pandas\nimport pandas as pd\n# 导入数字和向量处理包：numpy\nimport numpy as np\n# 导入基本绘图工具：matplotlib\nimport matplotlib.pyplot as plt\n# 导入高级绘图工具 seaborn 为 sns\nimport seaborn as sns\n# 导入统计建模工具包 scipy.stats 为 st\nimport scipy.stats as st \n\n# 设置APA 7的画图样式\nplt.rcParams.update({\n    'figure.figsize': (4, 3),      # 设置画布大小\n    'font.size': 12,               # 设置字体大小\n    'axes.titlesize': 12,          # 标题字体大小\n    'axes.labelsize': 12,          # 轴标签字体大小\n    'xtick.labelsize': 12,         # x轴刻度字体大小\n    'ytick.labelsize': 12,         # y轴刻度字体大小\n    'lines.linewidth': 1,          # 线宽\n    'axes.linewidth': 1,           # 轴线宽度\n    'axes.edgecolor': 'black',     # 设置轴线颜色为黑色\n    'axes.facecolor': 'white',     # 轴背景颜色（白色）\n    'xtick.direction': 'in',       # x轴刻度线向内\n    'ytick.direction': 'out',      # y轴刻度线向内和向外\n    'xtick.major.size': 6,         # x轴主刻度线长度\n    'ytick.major.size': 6,         # y轴主刻度线长度\n    'xtick.minor.size': 4,         # x轴次刻度线长度（如果启用次刻度线）\n    'ytick.minor.size': 4,         # y轴次刻度线长度（如果启用次刻度线）\n    'xtick.major.width': 1,        # x轴主刻度线宽度\n    'ytick.major.width': 1,        # y轴主刻度线宽度\n    'xtick.minor.width': 0.5,      # x轴次刻度线宽度（如果启用次刻度线）\n    'ytick.minor.width': 0.5,      # y轴次刻度线宽度（如果启用次刻度线）\n    'ytick.labelleft': True,       # y轴标签左侧显示\n    'ytick.labelright': False      # 禁用y轴标签右侧显示\n})","outputs":[],"execution_count":14},{"cell_type":"code","metadata":{"_id":"964344C1AE4D492EBEE44169E13DAD6F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"75ED1F8F10CA43349A245EDF732F3A01","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"y = [0,1,2,3,4,5,6]  # 成功次数 \nn = 6                # 重复研究总次数\np = 0.5              # 假设的成功概率\n\n# 计算概率值\nprob = st.binom.pmf(y, n, p)\n\nresult_table = pd.DataFrame({\"成功次数\":y, \"概率\":prob})\nresult_table","outputs":[],"execution_count":15},{"cell_type":"markdown","metadata":{"_id":"0E0EE993EC7C4246864A50147A8E2736","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C78B12E3995346CC8514EFFA95E68295","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"显然，当团队的成功概率为 0.5 时，其在六次研究中获得 *y* = 3 次成功的概率最高(*p* = 0.3125)。"},{"cell_type":"code","metadata":{"_id":"41D47C047ABC4817902F877AC116E071","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0F04C8F7BDC84AACBCEDB48441B0C0B1","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 绘制灰色竖线\nfor i, j in zip(y , prob):\n    plt.plot([i, i], [j, 0], 'gray', linestyle='-', linewidth=1, zorder=1, )\n\n# 绘制黑色点(各成功率次数的成功率)\nplt.scatter(y, prob, c='black')\n\nplt.ylabel('$f(y|\\pi)$')\nplt.xlabel('y')\n\nplt.xlim(-0.2,6.2)\nplt.ylim(0,0.5)\nplt.show()","outputs":[],"execution_count":16},{"cell_type":"markdown","metadata":{"_id":"8041DF2125114C788A52694D4B45784E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7701CDC2BC0043DD89982F2812F268B8","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"\n**概率质量密度函数(probability mass function, pmf)：** 用来描述离散型随机变量在各特定取值上的概率  \n\n在上图中我们看到，成功次数y在不同的取值上的概率不同。  \n\n* 由于$y$的个数是有限的，并且是随机发生的，我们把$y$称为离散型随机变量，而$y$发生的概率$f(y)$则被称为概率密度函数  \n\n\n对于离散型随机变量$Y$，$Y$各取值的概率由$f(y)$指定：  \n$$  \nf(y) = P(Y=y)  \n$$  \n\n并且有如下性质：  \n\n* 对所有y的取值来说，$0\\leq f(y) \\leq 1$  \n* $\\sum_{all\\,\\pmb{y}}f(y) = 1$，y取值的所有概率之和为1"},{"cell_type":"code","metadata":{"_id":"05FC709EDC61405080FAEF84FC525F6E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"2B126FF9F8334DEB849C30EC9E6D7D8C","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"sum(result_table['概率'])","outputs":[],"execution_count":17},{"cell_type":"markdown","metadata":{"_id":"AA8EDB178D4B4E89A7544F8DE8489F30","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9747D261BB1848E99BAF02EA0B6A2A4B","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 二项似然函数(The Binomial likelihood function)"},{"cell_type":"markdown","metadata":{"_id":"49B4DD60B3174E9297B696DAEC178564","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"477CB10B6C184BE18BFB089F9EFE0F6A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**不同的信念**  \n\n虽然我们认为该团队重复6个实验的成功率是50%，但并非所有人都这么认为。    \n\n- 乐观派认为该团队的成功概率为 0.8，表示对实验成功复现持高度信心。  \n- 悲观派则认为该团队的成功概率仅为 0.2，意味着对实验成功复现不太乐观。  \n\n成功的概率影响着他们对研究复现结果的预期：如果团队的成功概率高，那么6次研究中成功复现的次数会更多；  \n反之，如果成功概率低，那么研究复现的失败次数就会更多。  \n\n我们可以计算持不同信念的人心中，该团队在6项研究中成功复现的次数的概率分布并画图。"},{"cell_type":"code","metadata":{"_id":"09496DE9C3554C5899C273188217941F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"22CF9D222E264727983E281661A95CBC","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"y = [0,1,2,3,4,5,6]  # 成功次数 \nn = 6                # 研究总次数\n\n# 计算似然值\np = 0.5              # 根据以往战绩假设的成功概率\nlikelihood1 = st.binom.pmf(y, n, p)\np = 0.8              # Kasparov支持者眼中的成功概率\nlikelihood2 = st.binom.pmf(y, n, p)\np = 0.2              # 深蓝支持者眼中的成功概率\nlikelihood3 = st.binom.pmf(y, n, p)\n\nresult_table = pd.DataFrame({\n  \"成功次数\":y, \n  \"本团队(pi=0.5)\":likelihood1, \n  \"悲观派(pi=0.2)\":likelihood2, \n  \"乐观派(pi=0.8)\":likelihood3})\nresult_table","outputs":[],"execution_count":18},{"cell_type":"code","metadata":{"_id":"DC62F21B049746FDA1E4D7D3062A8A9F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"538E3160577149D3BC864A7115E2F25D","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 创建子图\nfig, axs = plt.subplots(1, 3, figsize=(10, 4))\n\n# 绘制三个图,每个子图类似原图\nthree_pi = [\"Team itself ($\\pi = 0.5$)\",\"Optimists ($\\pi = 0.8$)\",\"Pessimists ($\\pi = 0.2$)\"]\nlikelihoods = [likelihood1, likelihood2, likelihood3]\nfor i, ax in enumerate(axs):\n    \n    ax.scatter(y, likelihoods[i], c='black')\n    \n    for xx, yy in zip(y, likelihoods[i]):\n        ax.plot([xx, xx], [yy, 0], 'gray', linestyle='-', linewidth=1, zorder=1)\n    \n    # 添加facet\n    ax.set_title(three_pi[i])\n\n    ax.set_xlim(-0.2,6.2)\n    ax.set_ylim(0,0.4)\n\nfig.supylabel('$f(y|\\pi)$')\nfig.supxlabel('y')\nplt.tight_layout()\nplt.show()","outputs":[],"execution_count":19},{"cell_type":"markdown","metadata":{"_id":"ECAB551A37B54158AC2B5734427CAD1E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"05BA6448E6F6417D9006DC61F4FD1EB4","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"显然，对于乐观派来说，团队取得六次成功的概率远高于其他成功次数。而对于悲观派来说，团队全败的可能性远高于其他成功次数。  \n- 换句话说，若团队在6项研究中仅成功复现一次，这种情况在低成功率下(悲观派设想的情境)更可能出现，在高成功率下(乐观派设想的情境)几乎不可能出现。  \n- 那么团队成功重复的成功率率，更可能(likelihood)是悲观派设想的那样($\\pi = 0.2$)。  \n\n例如，在乐观派和悲观派眼中(不同成功率$\\pi$下)，6项研究只成功1次的可能性(即似然，likelihood)。  "},{"cell_type":"code","metadata":{"_id":"44F114058962412AAEEF8D6DA01A1FB8","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A81CF1D6F04B4A479FF3596381E07D72","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 定义成功次数和研究总次数\ny = 1  # 成功次数，作为数组处理以便向量化计算\nn = 6  # 研究总次数\n\n# 计算似然值，对于三种不同的成功概率 p\np_values = [0.5, 0.8, 0.2]          # 定义三种成功率\nlikelihoods = []                    # 用于存储每种成功率的似然值结果\n\nfor p in p_values:\n    likelihood = st.binom.pmf(y, n, p)  # 使用st.binom.pmf计算似然值\n    likelihoods.append(likelihood)      # 将结果添加到列表中\n\n\n# 创建图形和子图\nfig, ax = plt.subplots()  # 此处应该是 plt.subplots() 而不是 plt.subplot()\nax.scatter(p_values, likelihoods, c='black')\n# 设置x轴和y轴的限制应该在绘制线条之前完成，以避免重复设置\nax.set_xlim(-0.2, 1.2)  # x轴范围根据p_values调整，最大不应超过1\nax.set_ylim(0, 0.5)\nfor xx, yy in zip(p_values, likelihoods):\n    ax.plot([xx, xx], [0, yy], 'gray', linestyle='-', linewidth=1, zorder=1)\n    # 注意这里的顺序是 [0, yy] 而不是 [yy, 0]，因为我们希望从x轴画到对应的似然值\n# 设置坐标轴标签，直接使用ax的方法，而不是fig的方法\nax.set_ylabel('$f(\\pi|y)$')  # 使用ax.set_ylabel而不是fig.supylabel\nax.set_xlabel('$\\pi$')         # 使用ax.set_xlabel而不是fig.supxlabel\nplt.tight_layout()  # 调整布局以避免标签重叠\nplt.show()","outputs":[],"execution_count":20},{"cell_type":"markdown","metadata":{"_id":"72AC4CDC23224E4D922F9C883E946616","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FE0D9D0F288144F692557C3D4A9B266C","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**似然函数**  \n\n当团队只成功复现一次时，该事件在不同成功率下出现的可能性可以写为：  \n\n$$  \nf(Y=1|\\pi=0.2) = \\binom{6}{1} 0.2^1 (1-0.2)^{5}  \n$$  \n$$  \nf(Y=1|\\pi=0.5) = \\binom{6}{1} 0.5^1 (1-0.5)^{5}  \n$$  \n$$  \nf(Y=1|\\pi=0.8) = \\binom{6}{1} 0.8^1 (1-0.8)^{5}  \n$$  \n\n因此，成功复现次数为1时的似然函数可以写成  \n\n$$  \nL(\\pi|y=1) = f(y=1|\\pi) = \\binom{6}{1} \\pi^{1}(1-\\pi)^{6-1} = 6\\pi(1-\\pi)^{5}  \n$$  \n\n不同成功率下的似然：  \n\n| $\\pi$          | 0.2   | 0.5   | 0.8   |  \n|---------------|-------|-------|-------|  \n| $f(\\pi \\| y=1)$ | 0.3932 | 0.0938 | 0.0015 |  \n\n\n\n\n**注意：**  \n\n似然函数表示的是，在各种可能的成功率$\\pi$下,成功次数$Y=1$的可能性，所以  \n1. 该似然函数公式只取决于$\\pi$  \n2. 似然函数的总和加起来不为1（从条件概率的公式来看，似然函数的分母是不同的）"},{"cell_type":"markdown","metadata":{"_id":"D0F1C949052B4862A5FF3F952B56246C","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"2ED94A371BB34BAC8ED7EB4367527F28","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 条件概率 VS 似然函数  \n\n🤓  \n当$\\pi$是一定时，条件概率质量密度函数$f(·|\\pi)$可以帮我们计算在$\\pi$取值下（各种模型），不同的数据$Y$(e.g., $y_{1},y_{2}$)发生的可能性。  \n$$  \nf(y_{1}|\\pi) \\; vs \\; f(y_{2}|\\pi)  \n$$  \n\n当$Y = y$一定时，似然函数$L(·|y)= f(y|·)$允许我们比较在各种不同的模型，即二项式的$\\pi$取值(e.g., $\\pi_{1},\\pi_{2}$)下，观察到这个数据$y$的可能性(relative likelihood)。  \n\n\n$$  \nL(\\pi_{1}|y) \\; \\text{与} \\; L(\\pi_{2}|y)  \n$$  \n$$  \n\\text{即}  \n$$  \n$$  \nf(y|\\pi_{1}) \\; \\text{与} \\; f(y|\\pi_{2})  \n$$  \n"},{"cell_type":"markdown","metadata":{"_id":"37CA7578F4774A4A80CE7B13B1DCFBE0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4359CD890D0A4F4DAFDAA3E1F167F78F","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**在二项分布模型下...**  \n\n进行$n = 6$个重复实验时，成功次数与成功率的关系符合二项式模型，可以用如下的形式来表示：  \n\n$$  \nY|\\pi \\sim Bin(6,\\pi)  \n$$  \n\n\n$$  \nf(y|\\pi) = \\binom{6}{y} \\pi^{y}(1-\\pi)^{6-y} \\quad\\quad for\\;y \\in \\{0,1,2,3,4,5,6\\}  \n$$  \n\n-----------------------------------  \n\n下图给出了几种 $\\pi$的取值，我们可以通过概率模型得到每种$Y$发生的可能性。  \n* 同时，我们可以看到，Y=1(赢一次)这一特定的数据模式，在各个$\\pi$取值(模型)下的似然。  "},{"cell_type":"code","metadata":{"_id":"880BEABE08684E0098F7AF48EAAF80F3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A547C6198ABB4D77B9B41914EC9D502F","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# Values for Y (number of successes in n trials)\ny = np.arange(0, 7)\n# Number of trials (n) and different probabilities (π values)\nn = 6\npi_values = [0.2, 0.5, 0.8]\n\n# Create subplots\nfig, axs = plt.subplots(1, 3, figsize=(12, 5))\n# Loop over each pi value to plot the corresponding binomial distribution\nfor i, pi in enumerate(pi_values):\n    # Calculate binomial probabilities for each y (number of successes)\n    likelihoods = st.binom.pmf(y, n, pi)\n    \n    # Scatter plot of the likelihoods\n    axs[i].scatter(y, likelihoods, color='black', zorder=2)\n    \n    # Draw gray vertical lines\n    for yy, likelihood in zip(y, likelihoods):\n        axs[i].plot([yy, yy], [0, likelihood], color='gray', linestyle='-', linewidth=1, zorder=1)\n    \n    # Highlight y = 1 with a black line\n    axs[i].plot([1, 1], [0, st.binom.pmf(1, n, pi)], color='black', linewidth=3, zorder=3)\n    \n    # Title with binomial parameters\n    axs[i].set_title(f'Bin({n},{pi})')\n    \n    # Set y and x axis limits\n    axs[i].set_xlim(-0.5, 6.5)\n    axs[i].set_ylim(0, 0.5)\n\n# Global labels\nfig.supylabel(r'$f(y|\\pi)$')\nfig.supxlabel('y')\n\n# Adjust layout for better fit\nplt.tight_layout()\nplt.show()","outputs":[],"execution_count":21},{"cell_type":"markdown","metadata":{"_id":"45541A93BE7B4F15B21B9284010EE053","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F22E63BEE04C418E8E339B35D1B49D41","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 先验概率模型(**Prior** probability model)"},{"cell_type":"markdown","metadata":{"_id":"8F39E31E1E4D40299FC0523F74F844E3","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8F374B8DFA2D49178FF49B1A26F345FC","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**建立先验模型**  \n\n从前面的描述可以看到，二项分布的参数$\\pi$也可以变化，也可以成为一个随机变量。  \n\n- 例如，我们想当一个更有深度的观察者，融合了乐观派、悲观派和中立者三者关于$\\pi$的估计。  \n- 但是，我们对三种观点的可能性有不同的信念。  \n\n假如我们总体上是一个乐观派，但不排除悲观派的观点，我们给三派观点分配了一定的概率(先验)。  \n- 例如，设定 $\\pi_{0.2} = 0.1$， 或者 $\\pi_{0.2} = 0.5$。 但需要所有$f(\\pi)$的总和为1。  \n\n\n| $\\pi$\t    |0.2  |0.5 |0.8 |Total  \n|---------- |-----|----|----|-----|  \n|$f(\\pi)$   |0.10  |0.25 |0.65   |1|  \n\n"},{"cell_type":"markdown","metadata":{"_id":"C4F7FE361F3B4A6F9838D276D5CE8611","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EF7986438B1E4865923A34F5DA4A433D","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们设定的$\\pi$ 的数量也是可以变化的。  \n\n- 例如，我们还可以将一种非常悲观的可能性也纳入进来，认为该团队成功率为0.01，即 $\\pi = 0.01$。  \n- 那么新形成的先验分布可能如下。  \n\n \n| $\\pi$    |   0.01  | 0.2  | 0.5  | 0.8  | Total |  \n| -------- | --- | ---- | ---- | ---- | ----- |  \n| $f(\\pi)$ |  0.10   | 0.10 | 0.25 | 0.55 | 1     |  \n\n\n"},{"cell_type":"markdown","metadata":{"_id":"38E98221461549329E95D8DA03AD6D66","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D4097E174A194B65958CD57B1E5BF9E7","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 后验概率模型(Posterior probability model)"},{"cell_type":"markdown","metadata":{"_id":"64BEDA6DE1DD49E18C1669669168502C","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7869A1922EA74E9AA1B28D719998E888","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"前述第一个先验模型，我们总体上是乐观的，认为团队高成功率的可能性很高 ($\\pi_{0.8} = 0.65$)。  \n\n\n\n| $\\pi$\t    |0.2  |0.5 |0.8 |Total  \n|---------- |-----|----|----|-----|  \n|$f(\\pi)$   |0.10  |0.25 |0.65   |1|  \n\n\n\n然而，最终结果发现：该团队只成功复现一次。  \n\n这个新的数据会如何改变我们的信念？"},{"cell_type":"markdown","metadata":{"_id":"54914C411AC241C4A174F09D4D4AADCA","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4F1C1E828C9244EFA100727840F99FB8","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们可以综合先验和似然，根据贝叶斯的思路，计算后验概率。  \n\n其中 团队成功复现的概率从$\\pi_{0.8}=0.65$降低为$\\pi_{0.8}=0.015$。意味着，他成功率为0.2的可能性是最大的 $\\pi_{0.2}=0.617$。  \n\n- 左图为先验模型  \n- 中间的图为似然模型  \n- 右边的图为后验模型"},{"cell_type":"code","metadata":{"_id":"D09B7260EFCF4428ABE9D295E1049C39","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"440819893F5341BCB91F58C563A72B71","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# Pi values and corresponding data\npi_values = [0.2, 0.5, 0.8]\nf_pi = [0.10, 0.25, 0.65]  # Prior probabilities\nL_pi_given_Y1 = [0.617, 0.367, 0.015]  # Likelihoods given Y=1\nposterior = [0.617, 0.367, 0.015]  # Posterior, assumed same as likelihoods here\n\n# Create subplots for prior, likelihood, and posterior\nfig, axs = plt.subplots(1, 3, figsize=(10, 4))\n\n# Prior Probability f(π)\naxs[0].scatter(pi_values, f_pi, color='black', zorder=2)\nfor xx, yy in zip(pi_values, f_pi):\n    axs[0].plot([xx, xx], [0, yy], color='black', linewidth=3, zorder=1)\naxs[0].set_title(r'Prior $f(\\pi)$')\naxs[0].set_xlim(0.15, 0.85)\naxs[0].set_ylim(0, 0.7)\n\n# Likelihood L(π|Y=1)\naxs[1].scatter(pi_values, L_pi_given_Y1, color='black', zorder=2)\nfor xx, yy in zip(pi_values, L_pi_given_Y1):\n    axs[1].plot([xx, xx], [0, yy], color='black', linewidth=3, zorder=1)\naxs[1].set_title(r'Likelihood $L(\\pi|Y=1)$')\naxs[1].set_xlim(0.15, 0.85)\naxs[1].set_ylim(0, 0.7)\n\n# Posterior Probability f(π|Y=1)\naxs[2].scatter(pi_values, posterior, color='black', zorder=2)\nfor xx, yy in zip(pi_values, posterior):\n    axs[2].plot([xx, xx], [0, yy], color='black', linewidth=3, zorder=1)\naxs[2].set_title(r'Posterior $f(\\pi|Y=1)$')\naxs[2].set_xlim(0.15, 0.85)\naxs[2].set_ylim(0, 0.7)\n\n# Set labels and layout\nfor ax in axs:\n    ax.set_xlabel(r'$\\pi$')\n\nfig.supylabel('Probability')\nplt.tight_layout()\nplt.show()","outputs":[],"execution_count":22},{"cell_type":"markdown","metadata":{"_id":"6E5372D39F5D48D58461B9A071A46D9C","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AF0C393E6228412D90235C3CB3002D27","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**后验模型的计算过程**  \n\n上图所表示的后验可写成：  \n\n$$  \nf(\\pi|y=1)  \n$$  \n\n表示当团队只赢成功复现一项研究时，他成功率$\\pi$的概率分布  \n\n根据贝叶斯公式，我们可以进一步对后验概率公式进行展开：  \n\n$$  \nposterior = \\frac{ prior*likelihood} {normalizing\\;\\;constant}  \n$$  \n\n$$  \nf(\\pi|y=1) = \\frac{ f(\\pi)L(\\pi|y=1)} {f(y=1)} \\quad\\quad for\\;\\pi \\in {0.2,0.5,0.8}  \n$$  \n\n$$  \nf(\\pi=0.2|y=1) = \\frac{0.10 \\times 0.3932} {0.0637} \\approx 0.617  \n$$  \n$$  \nf(\\pi=0.5|y=1) = \\frac{0.25 \\times 0.0938} {0.0637} \\approx 0.368  \n$$  \n$$  \nf(\\pi=0.8|y=1) = \\frac{0.65 \\times 0.0015} {0.0637} \\approx 0.015  \n$$ "},{"cell_type":"markdown","metadata":{"_id":"8436F519D4D24363BC40B88942193A50","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BB824A9A40594D1D9ED62D9B3F8020D9","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"下表对后验概率模型进行了总结，我们可知，经过了先前只成功了一项研究的复现经历后，该团队取得成功($\\pi$=0.8)的可能性已经从0.65降到了0.015  \n\n\n| $\\pi$\t        |0.2    |0.5    |0.8 |Total  \n|---------------|-----  |----   |----|-----|  \n|$f(\\pi)$   |0.10  |0.25 |0.65|1|  \n|$f(\\pi \\| y=1)$   |0.617  |0.368 |0.015|1|  \n"},{"cell_type":"markdown","metadata":{"_id":"08F23756A40C45C19D184E7F115C95E0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4752E1EB0DB44F6BA5346770E16A6981","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**补充材料**  \n\n省略分母的计算  \n- 考虑到分母是一个常数，我们常常会成功率计算它  \n\n省略分母后验的计算可写成：  \n$$  \nf(\\pi=0.2|y=1) = c⋅ 0.10⋅0.3932 \\propto 0.039320  \n$$  \n\n$$  \nf(\\pi=0.5|y=1) = c⋅ 0.25⋅0.0938 \\propto 0.023450  \n$$  \n$$  \nf(\\pi=0.8|y=1) = c⋅ 0.65⋅0.0015 \\propto 0.000975  \n$$  \n\n$\\propto$ 表示成比例，尽管这些未经标准化的后验概率总和不等于1  \n$$  \n0.039320 + 0.023450 + 0.000975 = 0.063745,  \n$$  \n但它们的比例关系并未改变(见下图)  "},{"cell_type":"code","metadata":{"_id":"E2DC4ED06D5D468495F62290EAE2A323","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A123EA5E1C5040599E53C7CEABBD1D01","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# Pi values and corresponding unnormalized posterior data\npi_values = [0.2, 0.5, 0.8]\nunnormalized_posterior = [0.03932, 0.02345, 0.000975]  # Unnormalized posterior values\nnormalized_posterior = [val / sum(unnormalized_posterior) for val in unnormalized_posterior]  # Normalized\n\n# Create subplots for normalized and unnormalized posteriors\nfig, axs = plt.subplots(1, 2, figsize=(8, 4))\n\n# Normalized posterior\naxs[0].scatter(pi_values, normalized_posterior, color='black', zorder=2)\nfor xx, yy in zip(pi_values, normalized_posterior):\n    axs[0].plot([xx, xx], [0, yy], color='black', linewidth=3, zorder=1)\naxs[0].set_title('Normalized $f(\\pi | y=1)$')\naxs[0].set_xlim(0.15, 0.85)\naxs[0].set_ylim(0, 0.7)\n\n# Unnormalized posterior\naxs[1].scatter(pi_values, unnormalized_posterior, color='black', zorder=2)\nfor xx, yy in zip(pi_values, unnormalized_posterior):\n    axs[1].plot([xx, xx], [0, yy], color='black', linewidth=3, zorder=1)\naxs[1].set_title('Unnormalized $f(\\pi | y=1)$')\naxs[1].set_xlim(0.15, 0.85)\naxs[1].set_ylim(0, 0.05)\n\n# Set labels and layout\nfor ax in axs:\n    ax.set_xlabel(r'$\\pi$')\n\nfig.supylabel('Probability')\nplt.tight_layout()\nplt.show()","outputs":[],"execution_count":23},{"cell_type":"markdown","metadata":{"_id":"039AEF64DD0447A8AB7E4DD44248D1EF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"B6B478D99F03438DB676482B3B8B2548","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们可以使用这些未经标准化的后验概率总和作为分母，来对后验概率进行标准化，会得到相同的计算结果。  \n\n$$  \nf(\\pi = 0.2 | y = 1) = \\frac{0.039320}{0.039320 + 0.023450 + 0.000975} \\approx 0.617  \n$$  \n\n注意，分母为所有似然值的总和，因此后验概率的计算公式还可以写成：  \n\n$$  \nf(\\pi | y) = \\frac{f(\\pi)L(\\pi|y)}{f(y)} = \\frac{f(\\pi)L(\\pi|y)}{\\sum_{\\text{all } \\pi} f(\\pi)L(\\pi|y)} .  \n$$"},{"cell_type":"markdown","metadata":{"_id":"51D4AEAA9DDC4AFC88B9C00AD781FB62","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"18CC11B301324A148C72FDAF5E4AD017","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"**Proportionality**  \n\n既然$f(y)$是一个用来标准化的常数，它并不受$\\pi$的影响，那么后验概率质量函数$f(\\pi|y)$ 就与$f(\\pi)$和$L(\\pi|y)$成正比  \n\n$$  \nf(\\pi | y) = \\frac{f(\\pi)L(\\pi|y)}{f(y)} \\propto f(\\pi)L(\\pi|y)  \n$$  \n即，  \n\n$$  \nposterior \\propto prior⋅ likelihood  \n$$  \n\n> 😜这个性质很重要。因为分母的计算量往往比较大，需要遍历所有参数，如果参数不止一个，计算量可想而知。因此，如过能不计算分母也能计算后验，那么这样的方法(后面会介绍的MCMC算法)将会非常有实践意义。"},{"cell_type":"markdown","metadata":{"_id":"F4A3D160AE5E4181A769E34E023A7033","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"53C975D48D904B288748A357780466D4","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### Posterior simulation (with code)"},{"cell_type":"markdown","metadata":{"_id":"744BDB3097544121BB3C1C271A5EEEE0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"07095A289E7646ABA7AFF4B24E88C7EF","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 1. 定义先验模型  \n- 定义多个可能的成功率  \n- 定义每个成功率出现的可能性 (注意，其和为1)"},{"cell_type":"code","metadata":{"_id":"AE14DA7DBF2E4C4AAC85A3A7A09A81B6","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D3D9636FD55348218D3B8FB4DDECED83","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"import pandas as pd\nimport numpy as np\n\n# 定义可能的成功率\nreplicated = pd.DataFrame({'pi':[0.2, 0.5, 0.8]})\n\n# 定义先验模型\nprior = [0.10, 0.25, 0.65]","outputs":[],"execution_count":24},{"cell_type":"markdown","metadata":{"_id":"A5593998CBBE463084B2DB31E612BAEB","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3235C43C83864CE09559A1EBB911F173","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 2. 模拟在特定成功率下，6项研究中的成功次数  \n- 重复这个过程10000次"},{"cell_type":"code","metadata":{"_id":"EB13D3BBC8AA444EB4751606BAE3948F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"08AC9E0617F14D7FAE86D1565A75CAE4","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 设置随机数种子保证可重复性\nnp.random.seed(84735)\n\n# 从先验中抽取10000个 pi 值，并生成对应的y值\n\nreplicated_sim = replicated.sample(n=10000, weights=prior, replace=True)\nreplicated_sim['y'] = np.random.binomial(n=6, p=replicated_sim['pi'], size=len(replicated_sim))\nreplicated_sim.head(10)","outputs":[],"execution_count":25},{"cell_type":"code","metadata":{"_id":"178104DAE86849BE8666A37AA8AB472E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7076030C09184E8986848D18E01B7EFF","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"#对pi的抽取情况进行总结\nreplicated_counts =  replicated_sim['pi'].value_counts().reset_index()\n\nreplicated_counts.columns = ['pi','n']\n\nreplicated_counts['percentage'] = (replicated_counts['n']/len(replicated_sim))\n\nreplicated_counts = replicated_counts.sort_values(by='pi')\n\nprint(replicated_counts)","outputs":[],"execution_count":26},{"cell_type":"markdown","metadata":{"_id":"AD3A5819F20D461597DD4193AF4D8A37","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F8D1FB5D760642C2A223A73E860C2D84","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 3.  不同成功率下，不同成功次数的分布情况$f(y|\\pi)$"},{"cell_type":"code","metadata":{"_id":"0F1BFF8B7EB74713A32B5E4C20A98CFA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CDED33525A644B6E85FB1B19C35B8CAA","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"# 导入绘图工具 seaborn\nimport seaborn as sns\n# 通过 facegrid 方法根据不同变量绘制不同的图形\nreplicated_lik = sns.FacetGrid(replicated_sim,col=\"pi\")\nreplicated_lik.map(sns.histplot,'y',stat='probability',discrete=True)\nplt.tight_layout()\nplt.show()","outputs":[],"execution_count":27},{"cell_type":"markdown","metadata":{"_id":"A9FFE801A1A24AEC97683A82E1DED0CF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9D658ECCD7FD4597BEA1B1F184CB993F","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 4. 查看$y=1$时，对应的$\\pi$的分布情况"},{"cell_type":"code","metadata":{"_id":"B07F0C7DA92949F8B37A353DD13C21AC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D7744DE62E0648F6A0D9E72FBFB19941","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"replicated_post = replicated_sim[replicated_sim['y'] == 1].value_counts()\nreplicated_post","outputs":[],"execution_count":28},{"cell_type":"code","metadata":{"_id":"E05EE4EBAB694DA3998A35F52F1512D9","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"67388C42A9CC4E189833427762E1E83B","notebookId":"66e2a33e20251d3377f9bcd3","trusted":true},"source":"replicated_post = replicated_sim[replicated_sim['y'] == 1]\n\nreplicated_post_plot = sns.histplot(data = replicated_post, x=\"pi\")\n\n#plt.xticks(np.arange(0.2,0.8,0.3))\n\nreplicated_post_plot.set(xticks=[0.2,0.5,0.8])\nsns.despine()","outputs":[],"execution_count":29},{"cell_type":"markdown","metadata":{"_id":"CA3B0BC65DD34D54AE5114F0CE22A127","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"507B910CAEAF474990459CE5B0AC5DEA","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"## Part 4: 频率学派与贝叶斯学派的对比"},{"cell_type":"markdown","metadata":{"_id":"A842C9E2D7844F2BBDCB08A4F2140E41","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1AE1E3517CDD40BA9D6662D948766B06","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 频率学派如何看待这个世界？  \n"},{"cell_type":"markdown","metadata":{"_id":"B6C1C56FE41D487D9365CE0A4F715A18","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CC2F2FC2DE1746ED997CC7518A36F3E3","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"在对比频率学派与贝叶斯学派的差异之前，让我们首先回顾一下频率学派是如何看待这个世界的。"},{"cell_type":"markdown","metadata":{"_id":"C4AF975224F640AC90822FFC750F1665","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1727C4CBB46441019079B1AE50E50841","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"频率学派(经典统计)会如何处理上述两个问题？  \n* 某项研究的课重复性  \n* 重复6次的成功率"},{"cell_type":"markdown","metadata":{"_id":"80A99F3DA602440B8E95342766243C59","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"748CCA2BCFC5466482F4336A776B51AC","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rhqcgapoeq.png?imageView2/0/w/960/h/960)  \n"},{"cell_type":"markdown","metadata":{"_id":"C7BE74D77FA743B1AA2FAEE498C98B43","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"61A7E1388BA747D2A3CCA76C2BDA6435","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"我们假设存在两个城市，其中A城市的平均工资为$6000$元每月，B城市的平均工资为$6500$元每月。  \n\n然后，由于两个城市的人口太多，通过两个城市中所有人的工资去计算平均工作是*费时费力的*。  \n\n因此，统计学家选择 **抽样** 的方式通过 **样本** 来估计两个城市 **总体** 的均值。"},{"cell_type":"markdown","metadata":{"_id":"3C44FAF81D784D8E9118803F62AE7B92","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"276DB197E82E41249744FF20FCB8E63A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"值得注意的是：  \n\n1. 这个例子中两个总体均值的差异(工资差异)是**固定的**，即世界的真相是固定的。然而在真实的“大世界”中，比如人们幸福感上的差异，差异的“真相”是我们想要探索的，未知的。  \n\n2. 通过抽样的方式去估计总体会存在**噪音**或者*偏差*。  \n\n3. 频率学派认为**概率**是噪音的体现。结合前两点，两个城市的差异是固定的，而抽样带来了误差，因此概率代表的是样本能代表总体的概率。  \n\n4. 噪音受到抽样**样本大小**和工资方差**变异**的影响。另一个常见的问题是抽样样本的概率分布与样本大小和总体方差有关，如下图。"},{"cell_type":"markdown","metadata":{"_id":"0FCA6EF4AA78482592316146BD52787E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5DFAB3F2CB5347E580D6AA72E069F8CD","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rhqcnfd9gl.png?imageView2/0/w/480/h/480)  \n"},{"cell_type":"markdown","metadata":{"_id":"3EE62AF4C66848F49FD783BB13F6089C","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C2D091C4212E4FB592A0ED68CFBF9CB1","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"最后，频率学派如何**推断**出两个总体之间的差异？  \n- 由于两个总体间的差异是固定的，因此，判断差异是否显著与噪声大小有关，即信噪比。  \n- 频率学派通过零假设的显著性检验(Null hypothesis significant test, NHST)来判断这个显著性。即通过拒绝极端值的方式避免噪音的影响。在数学上通过计算置信区间(confidence interval)和$p$值来帮助推断过程。"},{"cell_type":"markdown","metadata":{"_id":"98FA33B154154FD394615B7C7E3E480E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"725D7EC5DFD84C748E2B935B1B31EBAE","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 贝叶斯学派如何看待这个世界？"},{"cell_type":"markdown","metadata":{"_id":"D35A738FCE8E4F969B703E782C526F08","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AEFF6EEFEDFA4798ABBCC5DD19C1C60E","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"贝叶斯学派的出现与兴趣在于频率学派所存在的问题。  \n主要体现在2个方面：  \n1. 世界的真相(差异)可能不是固定的。比如对于复杂世界现象背后的机制是难以确定的。  \n2. 通过抽样样本去替代总体容易出现偏差。比如由于抽到极端值从而错误的估计总体。此外，相关的问题还有type Ⅰ错误，统计检验力，*p*-hacking等。"},{"cell_type":"markdown","metadata":{"_id":"B097FFCFD47B446CA85C3ADB55A3EFFD","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"567BC67A824F4FC7BFA31CE20B663CD7","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"贝叶斯学派提供了另一种角度去解释上述的问题。  \n\n- 首先，贝叶斯学派认为世界的真相不是固定不变的，并且他们通过概率去描述这种变化。比如，两个城市平均工资的差异可能受到各种因素的影响，因此这个差异不是固定的。而两个城市平均工资的差异或可能性，比如这个差异为$500$的概率为$80$%，代表了个体对这个差异的信念**(belief)**，比如有$80$%的把握相信这个差异为$500$。  \n\n- 其次，贝叶斯学派并不是通过NHST来推测这个差异。而是通过贝叶斯公式。需要注意的是，虽然贝叶斯学派认为世界的真相并不是固定的，但总世界中所观测的现象(抽样样本得到的数据)是固定的。因此，对于世界真相的信念可以根据数据进行更新。"},{"cell_type":"markdown","metadata":{"_id":"B16CE4FED77B4F8B90B7A4477D3FD9D4","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1C05A3D50E9046CF8079F62059298C39","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### Thomas Bayes  \n![Image Name](https://pic2.zhimg.com/v2-ae48785e2b67af851e236b3d38c78c8d_r.jpg)  \n"},{"cell_type":"markdown","metadata":{"_id":"E75F03A64A1F4D96A7F1430A22D99B20","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"66F77CE6532A402DBDC11708D11657D0","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### Pierre Simon Laplace  \n\n![Image Name](https://th.bing.com/th/id/R.c252b05834293b10a3005882940d6622?rik=Kr8G5HIK%2fObbHw&riu=http%3a%2f%2fimages.fineartamerica.com%2fimages-medium-large%2fpierre-simon-marquis-de-laplace-maria-platt-evans.jpg&ehk=uHIIZ0qdCLmD0FXAHR4lUGfySQGNKlhNkJgoWIOMJG4%3d&risl=&pid=ImgRaw&r=0)  \n"},{"cell_type":"markdown","metadata":{"_id":"5AD514DB85CD477D922B690EBB91FFAC","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"57968D8736154D1DB4E1BF8EE45AE1EB","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 两个学派的差异对比  \n\n\n|                     | 频率学派   | 贝叶斯学派   |  \n| ------------------- | ---------- | ------------ |  \n| 世界真相 (参数) | 固定       | 变化         |  \n| 概率                | 抽样的噪音 | 信念         |  \n| 推断过程            | NHST       | 贝叶斯定理   |  \n| 数据                | 存在噪音   | 固定         |  \n| 推断可更新性        | 否         | 是           |  \n| 主观性              | 前提预设   | 通过先验设定 |"},{"cell_type":"markdown","metadata":{"_id":"0544A3BE422D4BC1818D91F7704856D9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"452D8A8E9B4F434E887C2B863A01A575","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"### 贝叶斯的主观性  \n\n**任何统计分析方法都不可能完全客观，因此主观性是一个相对概念:**  \n\n* 贝叶斯学派的主观性通过先验的设定来体现，透明，不易让人产生误解  \n\n* 频率学派的主观性暗含在各种**前提预设**中，比如方差分析中的方差齐性和正态性，这种看似‘客观的’预设，一方面难以满足，一方面也是一种主观的设定。  \n\n* 更为宏观的来说，样本的抽取，数据清理方式的选择，分析方法的选择，$p$值的设定，这些都存在主观性。因此，频率学派并没有想象的那么‘客观’。  \n\n* 主观不一定是坏事：通过量化方法将个体的经验和专家知识整合到数据分析之中。  \n\n"},{"cell_type":"markdown","metadata":{"_id":"9FC3B71C668D4AEE92B138FA14DC5138","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"90BEE1B6C14D42BC94EA48179A63F503","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 重复抽样的不同作用"},{"cell_type":"markdown","metadata":{"_id":"0B90EAC736154922A720436EFE54E554","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EF5571E9949C4EADB792F1AB32FCF1AE","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"##### 频率学派  \n* 统计推断依赖于参数的**抽样分布**，即只要无限(long-run)的进行抽样，样本分布的参数就会有某种分布形式；  \n* NHST中的$p$值和置信区间的解读均依赖于“无限次抽样”的预设；  \n* 实际操作中，我们往往只会收集一次数据，并不会反复的进行抽样；有些情境中，预设“无限次重复抽样并不合理；  \n\n##### 贝叶斯学派  \n* 假定参数本身是分布，不确定性一起存在于推断之中；  \n* 直接根据数据对先验信念进行更新；  \n\n**置信区间(confidence interval) vs 可信区间(credible interval)**  \n\n**No free lunch: 各有优势和缺陷**"},{"cell_type":"markdown","metadata":{"_id":"C8726BADC78B4D119E9131D177873C4D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5DDE86D29B5241CEB2605B09ABBFED0E","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### 不同的先验和似然会产生不同的后验分布  \n\n![Image Name](https://cdn.kesci.com/upload/image/rhqcb9gji7.png?imageView2/0/w/500/h/500)  \n"},{"cell_type":"markdown","metadata":{"_id":"FC6BA06B185F4E489BC5CBD9BEF37A95","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"175813DE4CE646DEA39FE027B1DF9383","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"#### NHST的\"弱项\""},{"cell_type":"markdown","metadata":{"_id":"6F25768311A548E1A9B25A0A401E1C97","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BF407C9D70CA49E19DFF652B319C1D0A","notebookId":"66e2a33e20251d3377f9bcd3"},"source":"* 无法直接对零假设(null hypothesis)进行支持，即如果两个总体没有显著差异，他们的相似程度有多少？  (许岳培等, 2023, *应用心理学*)  \n\n* 一次性只能对比两个总体的假设进行比较；  \n\n* 控制假阳性是一个棘手的问题"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}