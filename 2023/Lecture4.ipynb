{"cells":[{"cell_type":"markdown","metadata":{"_id":"288F09E200B24B5C857739E7E320862F","id":"78CA3041A22949EFA570C3E2A80C0842","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":[" # <center>Lecture 4:  Balance and Sequentiality in Bayesian Analyses  </center>  \n"," ## <center>Instructor: Dr. Hu Chuan-Peng  </center>"]},{"cell_type":"markdown","metadata":{"_id":"3050F86141BC4BA693F1B7B6B9BC1EF7","id":"68A8774F133C4379A23F219208E103D6","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### Different priors, different posteriors"]},{"cell_type":"markdown","metadata":{"_id":"34CB6D98E05F4F65BA21D9D2F905E01E","id":"E992F2CEFC6F4C76AA2B9822FCC320E3","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**贝克德尔测验(Bechdel test)**  \n","\n","衡量一部电影对女性角色的刻画是否扁平且单一的测验。  \n","\n","* 假设你是一位女性主义者，你认为当前电影对女性角色的展现是远远不够的，那么你可能认为只有少部分电影能通过这个测试。  \n","\n","* 假设你是乐观派，你可能认为大多数电影都能通过这个测试。  \n","\n","* 假设你只是吃瓜的，不太了解电影行业，你可能对大多数电影是否能通过这个测试没有明显的看法。  \n","\n","\n","假设$\\pi$是一个0-1之间的值，它代表了一部电影通过贝克德尔测试的可能性。我们可以看到这三种人对于$\\pi$有着不同的信念，比如：  \n","\n","* 女性主义者认为少部分电影能通过测试，对$\\pi$的估计更可能位于小于0.5的区域  \n","* 乐观者认为大多数电影都能通过测试，对$\\pi$的估计更可能接近1  \n","* 吃瓜群众没有明显的偏好，那么$\\pi$可以处于0-1的任何位置  \n","\n","这就构成了三种不同的先验，我们可以使用不同的Beta分布来表示。  \n"]},{"cell_type":"code","execution_count":1,"metadata":{"_id":"1AFCD5492A58422D8F141B97E590339C","collapsed":false,"id":"70E8042687AF4BED843128D8FE3DED6A","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/70E8042687AF4BED843128D8FE3DED6A/s1l4lo9q56.png\">"],"text/plain":["<Figure size 1500x500 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import scipy.stats as st\n","from scipy.stats import beta\n","from matplotlib.lines import Line2D\n","\n","# 定义不同的 Beta 分布参数\n","params = [(1,1),(5,11),(14,1)]\n","\n","# 创建一个包含三个子图的画布\n","fig, axes = plt.subplots(1,3,figsize=(15,5),sharex=True,sharey=True)\n","\n","# 定义横坐标的值\n","x = np.linspace(0,1,10000)\n","\n","# 循环遍历不同的参数组合\n","for i,(alpha_,beta_) in enumerate(params):\n","    # 计算 Beta 分布的概率密度函数值\n","    pdf_values = beta.pdf(x,alpha_,beta_)\n","    # 绘制 Beta 分布的线图\n","    sns.lineplot(x=x,y=pdf_values,ax=axes[i],color=\"black\")\n","    # 填充 Beta 分布下的区域\n","    axes[i].fill_between(x, pdf_values, color=\"#f0e442\", alpha=0.5)\n","    # 设置子图标题\n","    axes[i].set_title(f'Prior: Beta({alpha_},{beta_})')\n","    # 设置 x 和 y 轴标签\n","    axes[i].set_xlabel('$\\pi$')\n","    axes[i].set_ylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),]\n","\n","# 将图例放置在子图外部的右上角       \n","fig.legend(custom_lines, ['prior'],loc='outside upper right',bbox_to_anchor=(1, 1))\n","\n","# 移除图的上、右边框线\n","sns.despine()\n"]},{"cell_type":"markdown","metadata":{"_id":"009B9470B47F45F08E68DDCEAE9311BE","id":"6FFABD16022441B4B555202CB3C504B8","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**不同类型的先验**  \n","\n","我们来回顾一下从先验中我们可以获得什么信息  \n","\n","* 在上图中，不同的先验，反映了人们对测试通过率的不同信念(认为$\\pi$主要集中分布在哪里)  \n","\n","* 同时，先验分布的集中程度也反映了人们对某种信念的肯定程度  \n","\n","比如，对于$Beta(14,1)$这个先验，$\\pi$的取值集中分布在0.8-1.0这种“高通过率区域”，说明乐观主义者的信念是很肯定的。  \n","\n","而对于$Beta(1,1)$这个先验，$\\pi$的取值均匀分布在0-1之间，吃瓜群众觉得$\\pi$取任何值的可能性都是一样的，换言之她们也不知道$\\pi$可能是多少。  \n","\n","-------------------------  \n","\n","以上两种先验，可被总结为**信息型先验(informative prior)** 和 **模糊型先验(vague prior)** ，其中：  \n","\n","* **信息型先验**：先验分布比较窄，可变范围小，说明此先验强烈，可以提供比较确定的信息，如$Beta(14,1)$  \n","\n","* **模糊型先验**：先验分布的可变范围大，无法提供确定的信息，如$Beta(1,1)$"]},{"cell_type":"markdown","metadata":{"_id":"F74FFB5588C7402DBB6824EFB7714AE1","id":"62B94F92A1B74DD4BD13721C43609330","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**调查数据**  \n","\n","在继续探究不同的先验如何影响后验之前，我们还需要一些数据  \n","\n","假设现在随机抽取20部电影，并对这些电影进行测试，结果显示有9部电影可以通过测试"]},{"cell_type":"code","execution_count":2,"metadata":{"_id":"E58D97ACDDCD43C19BE62EC1EC776E9A","collapsed":false,"id":"4B6F8DB3F6FA41A3971372291EB99B5D","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1690</th>\n","      <td>1984</td>\n","      <td>Gremlins</td>\n","      <td>FAIL</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>2011</td>\n","      <td>The Green Hornet</td>\n","      <td>FAIL</td>\n","    </tr>\n","    <tr>\n","      <th>1069</th>\n","      <td>2003</td>\n","      <td>Wrong Turn</td>\n","      <td>PASS</td>\n","    </tr>\n","    <tr>\n","      <th>784</th>\n","      <td>2006</td>\n","      <td>Quinceanera</td>\n","      <td>PASS</td>\n","    </tr>\n","    <tr>\n","      <th>1373</th>\n","      <td>1998</td>\n","      <td>Sliding Doors</td>\n","      <td>PASS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      year             title binary\n","1690  1984          Gremlins   FAIL\n","283   2011  The Green Hornet   FAIL\n","1069  2003        Wrong Turn   PASS\n","784   2006       Quinceanera   PASS\n","1373  1998     Sliding Doors   PASS"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","\n","# 读取 bechdel.csv 文件的数据\n","try:\n","  bechdel = pd.read_csv(\"/home/mw/input/bayes20238001/bechdel.csv\")\n","except:\n","  bechdel = pd.read_csv('data/bechdel.csv')\n","\n","# 设置随机数种子以确保结果可复现\n","np.random.seed(84735)\n","\n","# 从 bechdel 数据中随机抽取 20 条数据\n","bechdel_20 = bechdel.sample(n=20)\n","\n","# 打印前 5 条抽取的数据\n","bechdel_20.head()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"_id":"FC2859F149234F0CAD9702FFD12FDBB1","collapsed":false,"id":"758785FAB0C34E2A92646BD23E8F0FF8","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["FAIL    11\n","PASS     9\n","Name: binary, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#统计 'binary' 列中各个值的出现次数\n","bechdel_20['binary'].value_counts()"]},{"cell_type":"markdown","metadata":{"_id":"E7FEF3C47C8947C6B342312CC1CED62E","id":"2B6CEDA412574AD0BA0608E5A3E3686A","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**beta-binomial组合**  \n","\n","在某一通过率$\\pi$下，随机抽取20部电影，其中有9部电影通过的可能性，这个似然函数可以用二项分布来表示。  \n","\n","$$  \n","\n","Y | \\pi  \\sim \\text{Bin}(n, \\pi)  \n","\n","$$  \n","\n","$$  \n","f(y|\\pi) = P(Y=y | \\pi) = \\binom{20}{9} \\pi^9 (1-\\pi)^{11}  \n","$$  \n","\n","------------------------  \n","\n","这里，我们的通过率$\\pi$服从$Beta$分布，似然函数服从二项分布  \n","\n","$$  \n","Y | \\pi  \\sim \\text{Bin}(n, \\pi)  \\\\  \n","\\pi  \\sim \\text{Beta}(\\alpha, \\beta) \\\\  \n","$$  \n","\n","从上一节我们知道，这种情况下的后验仍是beta分布，并且可以表示为：  \n","$$  \n","\\pi | (Y = y) \\sim \\text{Beta}(\\alpha + y, \\beta + n - y)  \n","$$  \n","\n"]},{"cell_type":"markdown","metadata":{"_id":"3C824974CB554041880F6EFC0351E45C","id":"9DA463B76CDE427683AD48E6727D96D2","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**🤔 思考时间**  \n","\n","下图画出了三种先验-似然组合，  \n","\n","我们可以猜测一下，哪一种后验分布的形状和似然分布的形状最为类似：  \n"]},{"cell_type":"code","execution_count":4,"metadata":{"_id":"9403921947EF40B59993B5E7E9C2CD8C","collapsed":false,"id":"631748881EE04AB1820C7BCFA01A04BA","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/631748881EE04AB1820C7BCFA01A04BA/s1l4lpfxf8.png\">"],"text/plain":["<Figure size 1500x500 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# 定义不同的 Beta 分布参数\n","params = [(1, 1), (5, 11), (14, 1)]\n","\n","# 创建一个包含三个子图的画布\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n","x = np.linspace(0, 1, 10000)\n","\n","# 计算二项分布的 likelihood\n","likelihood_value = st.binom.pmf(9, 20, x) / np.sum(st.binom.pmf(9, 20, x))\n","\n","# 循环遍历不同的参数组合\n","for i, (alpha_, beta_) in enumerate(params):\n","    # 计算 Beta 分布的概率密度函数值\n","    pdf_values = beta.pdf(x, alpha_, beta_) / np.sum(beta.pdf(x, alpha_, beta_))\n","    \n","    # 绘制 Beta 分布的线图\n","    axes[i].plot(x, pdf_values, color=\"black\")\n","    axes[i].fill_between(x, pdf_values, color=\"#f0e442\", alpha=0.5)\n","    \n","    # 绘制 likelihood 的线图\n","    axes[i].plot(x, likelihood_value, color=\"black\")\n","    axes[i].fill_between(x, likelihood_value, color=\"#0071b2\", alpha=0.5)\n","    \n","    # 设置子图标题\n","    axes[i].set_title(f'prior: Beta({alpha_},{beta_})')\n","\n","# 设置 x 和 y 轴标签\n","axes[1].set_xlabel('$\\pi$')\n","axes[0].set_ylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),\n","                Line2D([], [], color=\"#0071b2\")]\n","        \n","# 将图例放置在子图外部的右上角\n","fig.legend(custom_lines, ['prior', 'likelihood'], loc='outside upper right', bbox_to_anchor=(1, 1))\n","\n","# 移除图的上、右边框线\n","sns.despine()\n"]},{"cell_type":"markdown","metadata":{"_id":"9EF7F36C5E2B45FEA6C627915CE81881","id":"490254018BBC4BF5BC4022A8C5B1E9DD","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**后验图示**  \n","\n","我们可以使用公式来快速得到三种后验的表达式  \n","$$  \n","\\pi | (Y = y) \\sim \\text{Beta}(\\alpha + y, \\beta + n - y)  \n","$$  \n","\n","<center>  \n","\n","|Analyst|Prior  |Posterior  \n","|----|-----|----|  \n","|$\\alpha$   |Beta(5,11)|Beta(14,22)|  \n","|$\\beta$   |Beta(1,1)|Beta(10,12)|  \n","|mean   |Beta(14,1) |Beta(23,12)|  \n","\n","</center>  \n","\t\n","然后，我们可以把这些分布画出来：  \n"," "]},{"cell_type":"code","execution_count":5,"metadata":{"_id":"2647F2B7E94B4F81A323B506D5498E68","collapsed":false,"id":"4DE752A04A444391A732A8FFB72D3664","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/4DE752A04A444391A732A8FFB72D3664/s1l4lqfe1i.png\">"],"text/plain":["<Figure size 1500x500 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# 定义不同的 Beta 分布参数\n","params = [(1, 1), (5, 11), (14, 1)]\n","\n","# 创建一个包含三个子图的画布\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n","x = np.linspace(0, 1, 10000)\n","\n","# 循环遍历不同的参数组合\n","for i, (alpha_, beta_) in enumerate(params):\n","    # 计算二项分布的似然值\n","    likelihood_value = st.binom.pmf(9, 20, x)\n","    \n","    # 计算 Beta 分布的概率密度函数值并进行归一化\n","    pdf_values = beta.pdf(x, alpha_, beta_) / np.sum(beta.pdf(x, alpha_, beta_))\n","    \n","    # 计算后验概率\n","    posterior = pdf_values * likelihood_value\n","    posterior /= np.sum(posterior)\n","    likelihood_value /= np.sum(likelihood_value)\n","    \n","    # 绘制先验分布的线图\n","    axes[i].plot(x, pdf_values, color=\"black\", label=\"prior\")\n","    axes[i].fill_between(x, pdf_values, color=\"#f0e442\", alpha=0.5)\n","    \n","    # 绘制似然值的线图\n","    axes[i].plot(x, likelihood_value, color=\"black\", label=\"likelihood\")\n","    axes[i].fill_between(x, likelihood_value, color=\"#0071b2\", alpha=0.5)\n","    \n","    # 绘制后验概率的线图\n","    axes[i].plot(x, posterior, color=\"black\", label=\"posterior\")\n","    axes[i].fill_between(x, posterior, color=\"#009e74\", alpha=0.5)\n","\n","    # 设置子图标题\n","    axes[i].set_title(f'prior: Beta({alpha_},{beta_})')\n","\n","# 设置 x 和 y 轴标签\n","axes[1].set_xlabel('$\\pi$')\n","axes[0].set_ylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),\n","                Line2D([], [], color=\"#0071b2\"),\n","                Line2D([], [], color=\"#009e74\")]\n","        \n","# 将图例放置在子图外部的右上角\n","fig.legend(custom_lines, ['prior', 'likelihood', 'posterior'], loc='outside upper right', bbox_to_anchor=(1, 1))\n","\n","# 移除图的上、右边框线\n","sns.despine()\n"]},{"cell_type":"markdown","metadata":{"_id":"1AC4EFD555B243CF86412E14C0976974","id":"F09820D159214222B4FD5BB87F8C5C76","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["我们关注信息型先验和模糊型先验下的后验有什么区别：  \n","\n","* 在吃瓜群众这里，后验分布和似然分布重合了，这是因为她们的先验分布无法提供任何关于$\\pi$的有效信息，因此对$\\pi$的认知更新都来源于似然分布。  \n","\n","* 乐观主义者对$\\pi$的后验估计仍集中于0.6 - 0.8的区域，因为她们一开始对$\\pi$的信念是很强烈的（均值高，可变性小），所以只有45%的电影能够通过测试这一事件并未对她们的乐观信念产生较大影响。  \n"]},{"cell_type":"markdown","metadata":{"_id":"5108D8B5EBA54FEEBFAB1E0B9C07F483","id":"E399BDE9392E4E01BF3C2319B16ADAB7","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### Different data, different posteriors"]},{"cell_type":"markdown","metadata":{"_id":"DFF5673949D048AA8BD86FB46F723495","id":"77B1B1952CBB487C9EB7ACCEEE2ED691","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**不同的似然**  \n","\n","在看过乐观主义者的例子之后，你或许会想，当人们的先验认知过于主观时，客观数据难以对认知更新产生影响。  \n","\n","但并不是一直如此，通过贝叶斯公式我们知道，后验的分布主要取决于先验与似然  \n","\n","$$  \n","f(\\pi | y) = \\frac{f(\\pi)L(\\pi|y)}{f(y)} \\propto f(\\pi)L(\\pi|y)  \n","$$  \n","\n","接下来我们将看到，在强先验下，不同的似然对后验分布的影响。  \n","\n","------------------  \n","-----------------  \n","\n","\n","假设现在新增了三位调查员，小红、小蓝、小绿，她们都是乐观主义者，对$\\pi$有着**共同的先验信念Beta(14,1)**，但在调查的过程中，她们接触到了**不同的数据**。  \n","\n","\n","* 小红调查了1991年的13份电影，其中有6部(46%)通过了测试  \n","* 小蓝调查了2000年的63份电影，其中有29部(46%)通过了测试  \n","* 小绿调查了2013年的99份电影，其中有46部(46%)通过了测试  \n","\n","\n","在这里，三位调查员调查的电影数量不同，但调查结果都是相似的46%  \n","\n","我们可以把三种似然函数写出来：  \n","$$  \n","小红：  \n","f(6|\\pi) = \\binom{13}{6} \\pi^6 (1-\\pi)^{7}  \n","$$  \n","\n","$$  \n","小蓝：  \n","f(29|\\pi) = \\binom{63}{29} \\pi^{29} (1-\\pi)^{34}  \n","$$  \n","\n","$$  \n","小绿：  \n","f(46|\\pi) = \\binom{99}{46} \\pi^{46} (1-\\pi)^{53}  \n","$$  \n","\n","\n","我们同样可以把三种不同的似然分布画出来："]},{"cell_type":"code","execution_count":6,"metadata":{"_id":"4918F2C31CC64670A175493E3DA5CF49","collapsed":false,"id":"23DC10BFD2BC41C0AC7877D864D3170F","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/23DC10BFD2BC41C0AC7877D864D3170F/s1l4lrwfm7.png\">"],"text/plain":["<Figure size 1500x500 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# 定义不同的二项分布参数 (y, n)\n","params = [(6, 13), (29, 63), (46, 99)]\n","\n","# 创建一个包含三个子图的画布\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n","x = np.linspace(0, 1, 10000)\n","\n","# 设置 Beta 分布的参数\n","alpha_ = 14\n","beta_ = 1\n","\n","# 计算 Beta 分布的概率密度函数值并进行归一化\n","pdf_values = beta.pdf(x, alpha_, beta_) / np.sum(beta.pdf(x, alpha_, beta_))\n","\n","# 循环遍历不同的参数组合 (y, n)\n","for i, (y, n) in enumerate(params):\n","    # 计算二项分布的似然值并进行归一化\n","    likelihood_value = st.binom.pmf(y, n, x) / np.sum(st.binom.pmf(y, n, x))\n","\n","    # 绘制先验分布的线图\n","    axes[i].plot(x, pdf_values, color=\"black\", label=\"prior\")\n","    axes[i].fill_between(x, pdf_values, color=\"#f0e442\", alpha=0.5)\n","    \n","    # 绘制似然值的线图\n","    axes[i].plot(x, likelihood_value, color=\"black\", label=\"likelihood\")\n","    axes[i].fill_between(x, likelihood_value, color=\"#0071b2\", alpha=0.5)\n","\n","    # 设置子图标题\n","    axes[i].set_title(f'data: Y={y}, n={n}')\n","\n","# 设置 x 和 y 轴标签\n","axes[1].set_xlabel('$\\pi$')\n","axes[0].set_ylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),\n","                Line2D([], [], color=\"#0071b2\")]\n","        \n","# 将图例放置在子图外部的右上角\n","fig.legend(custom_lines, ['prior', 'likelihood'], loc='outside upper right', bbox_to_anchor=(1, 1))\n","\n","# 移除图的上、右边框线\n","sns.despine()\n","\n"]},{"cell_type":"markdown","metadata":{"_id":"D1F0CBD66E6B4E938529B381BBA7CF36","id":"4E142C9132344B18B76307D38B7F90F8","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["🤔思考时间：  \n","谁的后验分布受到数据的影响更大？"]},{"cell_type":"markdown","metadata":{"_id":"5D0B626C7F4B4344893F01B624DAB5A8","id":"09BF40F2CA594D15AEE686541D4033F7","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**似然对后验的影响**  \n","\n","\n","我们可以发现，虽然三种似然分布的均值都是0.46，但是随着样本量增大，似然的分布越窄，反映的信息越集中。  \n","\n","*注意：在似然中，y轴为$f(y|\\pi)$，表示在特定的$\\pi$值下产生当前数据的相对可能性。*  \n","\n","* 在小红的似然函数中，“13部电影中有6部通过测试”的结果在$\\pi$为0.15-0.75时，都有可能出现。  \n","\n","* 但在小绿的似然函数中，“99部电影中有46部通过测试”的结果只在$\\pi$为0.35-0.55时，才有可能出现。  \n","\n","* 换言之，小绿的似然函数直接将pi的可能取值缩小到一个更小的范围  \n","\n","\n","**当似然反映的信息越集中时，它对后验的影响越大**  \n","\n","\n","-----------------------------  \n","\n","同样的，我们可以使用公式快速计算出后验beta分布中的参数，并画图  \n","\n","<center>  \n","\n","|Analyst|Data  |Posterior  \n","|----|-----|----|  \n","|red   |Y = 6 of n = 13|Beta(20,8)|  \n","|blue   |Y = 29 of n = 63|Beta(43,35)|  \n","|green   |Y = 46 of n = 99|Beta(60,54)|  \n","\n","</center>"]},{"cell_type":"code","execution_count":7,"metadata":{"_id":"8BB3246508AE4BC19D039106A180AEA1","collapsed":false,"id":"44FFEB2047DC499E80E9AB39C2A936D8","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/44FFEB2047DC499E80E9AB39C2A936D8/s1l4lr9usf.png\">"],"text/plain":["<Figure size 1500x500 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# 定义不同的二项分布参数 (y, n)\n","params = [(6, 13), (29, 63), (46, 99)]\n","\n","# 创建一个包含三个子图的画布\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n","x = np.linspace(0, 1, 10000)\n","\n","# 设置 Beta 分布的参数\n","alpha_ = 14\n","beta_ = 1\n","\n","# 计算 Beta 分布的概率密度函数值\n","pdf_values = beta.pdf(x, alpha_, beta_)\n","\n","# 循环遍历不同的参数组合 (y, n)\n","for i, (y, n) in enumerate(params):\n","    # 计算二项分布的似然值\n","    likelihood_value = st.binom.pmf(y, n, x)\n","    \n","    # 计算后验概率\n","    posterior = pdf_values * likelihood_value\n","    \n","    # 归一化后验概率、先验概率和似然值\n","    posterior /= np.sum(posterior)\n","    pdf_values /= np.sum(pdf_values)\n","    likelihood_value /= np.sum(likelihood_value)\n","\n","    # 绘制先验分布的线图\n","    axes[i].plot(x, pdf_values, color=\"black\", label=\"prior\")\n","    axes[i].fill_between(x, pdf_values, color=\"#f0e442\", alpha=0.5)\n","    \n","    # 绘制似然值的线图\n","    axes[i].plot(x, likelihood_value, color=\"black\", label=\"likelihood\")\n","    axes[i].fill_between(x, likelihood_value, color=\"#0071b2\", alpha=0.5)\n","    \n","    # 绘制后验概率的线图\n","    axes[i].plot(x, posterior, color=\"black\", label=\"posterior\")\n","    axes[i].fill_between(x, posterior, color=\"#009e74\", alpha=0.5)\n","\n","    # 设置子图标题\n","    axes[i].set_title(f'data: Y={y}, n={n}')\n","\n","# 设置 x 和 y 轴标签\n","axes[1].set_xlabel('$\\pi$')\n","axes[0].set_ylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),\n","                Line2D([], [], color=\"#0071b2\"),\n","                Line2D([], [], color=\"#009e74\")]\n","        \n","# 将图例放置在子图外部的右上角\n","fig.legend(custom_lines, ['prior', 'likelihood', 'posterior'], loc='outside upper right', bbox_to_anchor=(1, 1))\n","\n","# 移除图的上、右边框线\n","sns.despine()"]},{"cell_type":"markdown","metadata":{"_id":"4E3712DDFD534F439C8AE6AC3728B6C3","id":"41B51E7406204BABA742EB7EB4ABFB66","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### Striking a balance between the prior & data"]},{"cell_type":"markdown","metadata":{"_id":"08A274500ED44CEAABAB26873B736445","id":"EEF0D13A483D4B98A556EA26BB84E310","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**不同先验+不同似然产生的后验分布**  \n","\n","我们已经看到不同的先验和不同的数据对后验分布的影响  \n","\n","**实际上，后验分布是两者间的平衡。**  \n","\n","我们可以将不同的先验和似然组合在一起，观察后验的变化"]},{"cell_type":"code","execution_count":8,"metadata":{"_id":"C445C27FC3874FC1893266C24648FABC","collapsed":false,"id":"2062245640034457B00D1BFFB83933AD","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/2062245640034457B00D1BFFB83933AD/s1l4mcl179.png\">"],"text/plain":["<Figure size 1200x1200 with 9 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# 生成一系列 pi 值\n","x = np.linspace(0, 1, 10000)\n","\n","# 创建一个 DataFrame 以存储 pi 值和后验分布\n","df = pd.DataFrame({'pi': x})\n","\n","# 定义似然值\n","likelihoods = [(6, 13), (29, 63), (46, 99)]\n","\n","# 定义先验分布\n","priors = [(14, 1), (5, 11), (1, 1)]\n","\n","# 创建一个 3x3 的子图网格，用于绘制九个图\n","fig, axs = plt.subplots(3, 3, figsize=(12, 12), sharex=True, sharey=True)\n","\n","# 计算并绘制所有似然值和先验分布组合的后验分布\n","for i, prior_params in enumerate(priors):\n","    for j, lik_params in enumerate(likelihoods):\n","\n","        prior_name = f'prior_{prior_params[0]}_{prior_params[1]}'\n","        lik_name = f'lik_{lik_params[0]}_{lik_params[1]}'\n","        posterior_name = f'posterior_{lik_params[0]}_{lik_params[1]}_{prior_params[0]}_{prior_params[1]}'\n","        \n","        # 计算先验分布\n","        df[prior_name] = df['pi'].apply(lambda x: beta.pdf(x, prior_params[0], prior_params[1]))\n","\n","        # 计算似然值\n","        df[lik_name] = df['pi'].apply(lambda x: st.binom.pmf(lik_params[0], lik_params[1], x))\n","\n","        # 计算后验分布通过将似然值和先验分布相乘\n","        df[posterior_name] = df[lik_name] * df[prior_name]\n","\n","        # 对似然值、先验分布和后验分布进行归一化\n","        df[lik_name] /= df[lik_name].sum()\n","        df[prior_name] /= df[prior_name].sum()\n","        df[posterior_name] /= df[posterior_name].sum()\n","        \n","        # 绘制先验分布、归一化似然值和后验分布的密度图\n","        axs[i, j].plot(df['pi'], df[prior_name], label='prior', color='black')\n","        axs[i, j].fill_between(df['pi'], df[prior_name], color=\"#f0e442\", alpha=0.5)\n","\n","        axs[i, j].plot(df['pi'], df[lik_name], label='likelihood', color='black')\n","        axs[i, j].fill_between(df['pi'], df[lik_name], color=\"#0071b2\", alpha=0.5)\n","\n","        axs[i, j].plot(df['pi'], df[posterior_name], label='posterior', color='black')\n","        axs[i, j].fill_between(df['pi'], df[posterior_name], color=\"#009e74\", alpha=0.5)\n","\n","        axs[0, j].set_title(f'data: Y={lik_params[0]}, n={lik_params[1]}')\n","\n","    axs[i, 0].set_ylabel(f'prior: Beta{prior_params}', fontsize=12)\n","\n","fig.supxlabel('$\\pi$')\n","fig.supylabel('density')\n","\n","# 创建自定义图例\n","custom_lines = [Line2D([], [], color=\"#f0e442\"),\n","                Line2D([], [], color=\"#0071b2\"),\n","                Line2D([], [], color=\"#009e74\")]\n","        \n","# 将图例放置在图的右上角\n","fig.legend(custom_lines, ['prior', 'likelihood', 'posterior'], loc='outside upper right', bbox_to_anchor=(1, 1))\n","\n","# 调整子图之间的间距\n","plt.tight_layout()\n","\n","# 移除图的上、右边框线\n","sns.despine()\n","\n"]},{"cell_type":"markdown","metadata":{"_id":"E5EBA4D65FE34810AA485816C46A759A","id":"605F89B431244C1384C79FF66165886E","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["* 从左往右，数据的样本量从13增加到99，似然的分布越集中，对后验的影响也越来越大  \n","\n","* 从上往下，先验分布从信息型(informative prior)变为模糊型(vague prior)，先验分布对后验分布的影响也就越来越小  \n","\n","* 而最后一列告诉我们，无论三种人先验的差异有多大，只要似然的分布够集中，即数据提供的信息足够丰富，那么后验分布主要受到来自数据的影响，三种人的后验分布也并不会相差太大。"]},{"cell_type":"markdown","metadata":{"_id":"FE4F90855AB94C8785FB45652E95C5F3","id":"F6888BB52B974BDDBB075667C1CF0FB4","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### Sequential analysis: Evolving with data "]},{"cell_type":"markdown","metadata":{"_id":"818FB22437214CAC9C4864EFCE5F3E12","id":"420C27B5458F4B78A8D34007B3FF579B","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["\n","> 🎈Recap: 在之前我们探讨了随着更多数据的到来，数据的影响力逐渐增加，先验观念的影响力逐渐减小，从而影响后验理解的演进。  \n","\n","我们再次回顾一下 第3节课中例子。纣王让姬发在质子团中组织对于自己支持率的民意调查。  \n","- 其中，π 代表的是支持纣王的概率。  \n","- 我们假设一开始他的支持率很低：π ∼ Beta(1, 10)。  \n","- 但随着纣王施展他的权威，越来越多人对他的态度开始产生了改变。  \n","- 当然，一些人在纣王的淫威下选择倒戈于他，另一些人不满于的他霸权选择反抗。  \n","- 现在，姬发每天都会对纣王支持率进行一次统计，并把之前的统计作为先验，而帮当天的统计作为数据，从而推测纣王在之后的支持率。  \n","\n","![Image Name](https://cdn.kesci.com/upload/s141bvd2cb.PNG?imageView2/0/w/600/h/600)  "]},{"cell_type":"markdown","metadata":{"_id":"45F61ADE48344427B363B1A04CBA346D","id":"A3B7E12E8AE24238963C47C1EE037DEC","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["- 第一天，姬发评估了 n=10 名质子，只有 Y=1 名质子选择支持纣王。因此，到第一天结束时，姬发对 π 的理解已经发生了改变：  \n","    $$  \n","    \\pi | (Y = 1) \\sim \\text{Beta}(2,19)  \n","    $$  \n","\n","> 后验参数是通过 α + y = 1 + 1 和 β + n − y = 10 + 10 − 1 计算的。  \n"]},{"cell_type":"markdown","metadata":{"_id":"D6ED5670C67B42CA884EA1C86A926B36","id":"216818867EB74756937A97862579CECE","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["- 第二天，被调查的质子更多：在 n = 20 质子中，有 Y = 17 的突然选择支持纣王(🤐听说他们的父亲受到了威胁)。因此，到第二天结束时，姬发对 π 的估计再次发生了改变：  \n","\n","> ❔问题！第二天结束时，姬发对 π 的后验估计是什么？  \n","> - a) Beta(19,22)  \n","> - b) Beta(18,13)"]},{"cell_type":"markdown","metadata":{"_id":"6268E23A07544A3F91E13585E23033C7","id":"8E3D66AB72194347A661B979415DD697","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["如果你的答案是“a”，那么你和姬发的估计是一致的！  \n","\n","- 第二天结束时 π 的后验模型是 Beta(19,22)。  \n","\n","在第三天，n = 10 质子中 Y = 8质子选择支持纣王 (情况似乎不妙了😱)  \n","\n","- 姬发对纣王支持率 π 的估计从 Beta(19,22) 逐渐演变为 Beta(27,24)。  \n","\n","可以发现，姬发对纣王的支持率的估计从原始的 Beta(1,10) 巨变为在三天研究结束时的 Beta(27,24)。"]},{"cell_type":"markdown","metadata":{"_id":"43B18192BEB04AA78D63F2FE63947D92","id":"3466EBB620A9407A9AFD0499833BBEAD","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**顺序贝叶斯分析(sequential Bayesian analysis)**  \n","\n","姬发刚刚逐步更新对纣王支持率 π 的后验模型的过程，更一般地被称为顺序贝叶斯分析或贝叶斯学习(Bayesian learning)。  \n","- 第二天：后验参数是通过 α + y = 2 + 17 和 β + n − y = 19 + 20 − 17 计算的。  \n","- 第三天：后验参数是通过 α + y = 19 + 8 和 β + n − y = 22 + 10 − 8 计算的。  \n","\n","|Day|Data|Model  \n","|---|---|---|  \n","|0|NA|Beta(1,10)|  \n","|1|Y = 1 of n = 10|Beta(2,19)|  \n","|2|Y = 17 of n = 20|Beta(19,22)|  \n","|3|Y = 8 of n = 10|Beta(27,24)|  \n","\n","![](https://www.bayesrulesbook.com/bookdown_files/figure-html/ch4-sequential-plot-1-1.png)"]},{"cell_type":"markdown","metadata":{"_id":"FFEBFC88CBF744CAB547515FF2EB02A7","id":"78E0A49A905B4E1498D8901002E76809","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**顺序贝叶斯分析（又称贝叶斯学习）**  \n","\n","- 在顺序贝叶斯分析中，随着新数据的到来，后验模型会逐步更新。  \n","- 每一份新数据都会使前一次后验模型（反映我们在观察到这些数据之前的理解）成为新的先验模型。  \n","\n","\n","![Image Name](https://cdn.kesci.com/upload/image/rhqd6akbc6.gif?imageView2/0/w/500/h/500)  "]},{"cell_type":"markdown","metadata":{"_id":"5DB911831BF74C8587208899A104AF38","id":"04CC9376D87F4EDBAB170E5D8257F5C5","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["贝叶斯框架的一个最强大的特性就是能够随着新数据的到来而演进。这种顺序分析还维持了两个基本的且符合常识的特性。  \n","\n","- 首先，最终的后验模型是数据顺序不变的，即，它不受我们观察数据的顺序的影响。  \n","- 例如，姬发以第三天的观测为先验，以第一和二天的观测为数据：第三天 Y = 8 的 n = 10，第二天 Y = 17 的 n = 20，第一天 Y = 1 的 n = 10。  \n","- 虽然姬发对 π 的推断的演进路径不同。但是，它仍然会最终达到相同的地方——Beta(27,24) 后验。  \n","\n","|Day|Data|Model|  \n","|---|---|---|  \n","|0|NA|Beta(1,10)|  \n","|1|Y = 8 of n = 10|Beta(9,12)|  \n","|2|Y = 17 of n = 20|Beta(26,15)|  \n","|3|Y = 1 of n = 10|Beta(27,24)|  \n","\n","![](https://www.bayesrulesbook.com/bookdown_files/figure-html/ch4-sequential-plot-2-1.png)  \n","\n","顺序分析的第二个基本特性是，最终的后验只依赖于累积的数据。  \n","- 例如，在姬发三天的观测中，共有 n = 10 + 20 + 10 = 40 被观测者，其中 Y = 1 + 17 + 8 = 26 的质子施选择支持纣王。  \n","- 甚至，姬发可以一次性评估这些数据，而不是逐步评估。这样，他可以直接从原始的 Beta(1,10) 先验模型跳到 π 的 Beta(27,24) 后验模型。  \n","- 也就是说，无论我们是逐步评估数据还是一次性评估，我们最终会得到相同的结果。"]},{"cell_type":"markdown","metadata":{"_id":"62953446131E46A882B260341852337C","id":"6EE887BF41714B6A9CAED9327E6E468B","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["**补充：贝叶斯顺序分析两大特征的数学证明**  \n","\n","在之前我们看到了数据顺序不变性的实例。接下来，我们将证明这一特性适用于所有贝叶斯模型。  \n","\n","> 数据顺序不变性 定义 θ 为感兴趣的任意参数，其先验概率密度函数为 f (θ)。那么，我们先观察数据点 y1，然后观察第二个数据点 y2 的顺序，将产生与先观察 y2，然后观察 y1 相同的后验模型 θ：f (θ∣y1, y2) = f (θ∣y2, y1)。同样，后验模型对于一次性观察所有数据和顺序观察数据是不变的。  \n","\n","为了证明数据顺序不变性的性质，让我们首先指定后验概率密度函数 f (θ∣y1, y2) 的结构，该函数通过依次观察数据 y1 和 y2 的方式进行演化。在这个演化的第一步中，我们从原始先验概率密度函数 f (θ) 和给定第一个数据点 y1 的似然函数 L(θ∣y1) 构建后验概率密度函数：  \n","\n","$$  \n","f(\\theta|y_1) = \\frac{\\text{先验概率} \\cdot \\text{似然函数}}{\\text{归一化常数}} = \\frac{f(\\theta)L(\\theta|y_1)}{f(y_1)}  \n","$$  \n","\n","在第二步中，我们根据观察到的新数据 y2 更新我们的模型。在这样做时，不要忘记我们从由 f (θ∣y1) 指定的先验模型开始，因此  \n","\n","$$  \n","f(\\theta|y_2) = \\frac{\\frac{f(\\theta)L(\\theta|y_1)}{f(y_1)}L(\\theta|y_2)}{f(y_2)} =  \\frac{f(\\theta)L(\\theta|y_1)L(\\theta|y_2)}{f(y_1)f(y_2)}  \n","$$  \n","\n","类似地，以相反的顺序观察数据 y2 然后 y1，会产生等价的后验模型：  \n","\n","$$  \n","f(\\theta|y_2,y_1) =  \\frac{f(\\theta)L(\\theta|y_2)L(\\theta|y_1)}{f(y_2)f(y_1)} .  \n","$$  \n","\n","最后，不仅数据的顺序不影响 θ 的最终后验模型，而且观察数据是一次性还是顺序观察也无关紧要。为此，假设我们从原始的 f (θ) 先验开始，并同时观察数据 (y1, y2)，而不是顺序观察。进一步假设这些数据点在无条件和有条件下是独立的，因此  \n","\n","$$  \n","f(y_1,y_2) = f(y_1)f(y_2) \\;\\; \\text{ 和 } \\;\\; f(y_1,y_2 | \\theta) = f(y_1|\\theta)f(y_2|\\theta)  .  \n","$$  \n","\n","那么，从这个\"数据扔进来\"的过程得到的后验概率密度函数等同于以上顺序分析得到的结果：  \n","\n","$$  \n","\\begin{split}  \n","f(\\theta|y_1,y_2)  \n","& = \\frac{f(\\theta)L(\\theta|y_1,y_2)}{f(y_1,y_2)} \\\\  \n","& = \\frac{f(\\theta)f(y_1,y_2|\\theta)}{f(y_1)f(y_2)} \\\\  \n","& = \\frac{f(\\theta)L(\\theta|y_1)L(\\theta|y_2)}{f(y_1)f(y_2)}  . \\\\  \n","\\end{split}  \n","$$"]},{"cell_type":"markdown","metadata":{"_id":"231B6484088A41E48EB3D81B7FCAAF36","id":"668AC678D88045619BB4C8889CBE5915","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### 极端先验对于顺序分析的影响"]},{"cell_type":"markdown","metadata":{"_id":"2DEE14FAFF0C494099DAC33B2B3CDBF5","id":"6207D8D51B70499680BA6C4E43AB3E64","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["\n","一个极端固执的先验模型可能会使得贝叶斯失去顺序分析的优势。  \n","\n","- 这样的极端先验模型往往包含先验概率为零的信念。  \n","- 如果姬发一开始对纣王的支持有着固执的信念，坚持认为纣王不可能获得支持。例如 π 在 0 到 0.25 之间的任何值是等可能的，并且肯定不会超过 0.25。通过在 0 到 0.25 上的均匀模型(uniform model)可以表达这种先验信念：  \n","\n","$$  \n","\\pi \\sim \\text{Unif}(0,0.25)  \n","$$  \n","\n","$$  \n","f(\\pi) = 4 \\; \\text{ for } \\pi \\in [0, 0.25]  \n","$$  \n","\n","现在，假设姬发被告知 10 名质子中有 8 人支持纣王。这个 80% 的数据与姬发的信念相悖。  \n","\n","> ❔问题！请根据这个数据猜测一下姬发对于纣王支持率的后验推断。  \n","\n","![](https://www.bayesrulesbook.com/bookdown_files/figure-html/ch4-stubborn-plot-1.png)"]},{"cell_type":"markdown","metadata":{"_id":"40294A0483254F699480C054E52B1D9E","id":"104F4DFBBA324B9B8BD3DE43EEF3171F","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["\n","尽管图 (c)看起来奇怪， 但它的确代表了姬发在观察到数据的情况下对信念 π 的更新。  \n","\n","- **后验概率模型的定义与先验概率模型的定义相同**。  \n","- 也就是说，后验模型的形状继承自先验模型。  \n","- 由于姬发的先验信念不存在对于纣王的信任，也就是超过 0.25 的 π 值的概率分配为零，他们的后验模型也必须将该范围内的任何值的概率分配为零。  \n","- 从数学上讲，对于任意的 π ∉ [0, 0.25]，后验概率密度函数 f (π∣y = 8) = 0，对于任意的 π ∈ [0, 0.25]，有  \n","\n","$$  \n","\\begin{split}  \n","f(\\pi | y=8)  \n","& \\propto f(\\pi)L(\\pi | y=8) \\\\  \n","& = 4 \\cdot \\left(\\!\\begin{array}{c} 10 \\\\ 8 \\end{array}\\!\\right) \\ \\pi^{8} (1-\\pi)^{2} \\\\  \n","& \\propto \\pi^{8} (1-\\pi)^{2}. \\\\  \n","\\end{split}  \n","$$  \n","\n","这个数学结果的含义是巨大的。  \n","- 无论姬发收集到多少相反的证据，他的后验概率永远不会超过 0.25 的上限"]},{"cell_type":"markdown","metadata":{"_id":"A9AE4A6D266840A9ADEE695F4EE78662","id":"299BF60D91914EFC97079A7E559B6A6F","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["> Tips：如何避免令人遗憾的先验模型  \n","> - 幸运的是，我们有一些好消息, 这种使得贝叶斯顺序分析失效的情况是完全可以避免的。  \n","> - 确保对每个可能的 π 值都分配非零的可信度，即使这个可信度接近于零。例如，如果 π 是一个可以从 0 到 1 的比例，那么你的先验模型也应该在这个连续范围内进行定义。  \n","\n","![Image Name](https://cdn.kesci.com/upload/image/rhqcb9gji7.png?imageView2/0/w/500/h/500) "]},{"cell_type":"markdown","metadata":{"_id":"A19DCE3B29614C04BF52E2A60C9159A5","id":"96F406DAC29149228B391B282AA116DB","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### 贝叶斯的主观性"]},{"cell_type":"markdown","metadata":{"_id":"9164388608B54F5F958291A84F56504F","id":"F71F423EEDAC4D89AD27D009A4CA3DCA","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["在之前我们提到了一个关于贝叶斯统计的常见批评观点——它的主观性。  \n","  \n","- 一些人担心“主观地”调整先验模型会使贝叶斯分析人员得出他们想要的任何结论。  \n","- 在学习完这节课后我们可以更严谨地回应这个观点。  \n","\n","> 在我们回应之前，重新思考并扩展一下你在整本书中探讨过的一些概念。  \n","> ❔问题！对于下面的每个陈述，请判断该陈述是真还是假，并提供你的推理。  \n","\n","- 所有的先验选择都是具有信息量的。  \n","- 有可能有充分的理由选择具有信息量的先验。  \n","- 任何先验选择都可以被足够多的数据克服。  \n","- 频率学派的范式是完全客观的。"]},{"cell_type":"markdown","metadata":{"_id":"2EC2C430E7584ABDBB2AC92FB53A50DB","id":"568641035703472899A04C804A17B49E","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["答案：  \n","\n","1. 错误。模糊的先验通常是不具有信息量的。  \n","2. 正确。我们可能有充足的先前数据或专业知识来构建我们的先验。  \n","3. 错误。如果你将潜在的参数值赋予零先验概率，任何数量的数据都无法改变它！  \n","4. 错误。主观性总是渗透到频率学派和贝叶斯分析中。在贝叶斯范式中，我们至少可以命名和量化这种主观性的方面。"]},{"cell_type":"markdown","metadata":{"_id":"9D91EC2E98164CF28DF06FC37FF0B6D8","id":"8AB810E0342C48089C813819D0E2C87B","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["在第4节课中，你已经确认贝叶斯分析确实可以基于“主观”经验建立先验。  \n","\n","- 在最理想的情况下，这不是件坏事，主观先验可以反映出丰富的过去经验，应该纳入我们的分析中——不这样做是不幸的。即使主观先验与实际观察到的证据相矛盾，随着这些证据的累积，它对后验的影响会逐渐消失。  \n","- 我们已经见过一个最糟糕的例外情况。而且这是可以预防的。如果主观先验足够顽固和极端，它会将可能的参数值的概率分配为零，那么任何数量的反证据都不足以改变它。"]},{"cell_type":"markdown","metadata":{"_id":"A249C9C936B344EDA087802CC1585A41","id":"32937A23E88845248E123AE7C50FEC2B","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["贝叶斯学派和频率学派的差异对比  \n","\n","**任何统计分析方法都不可能完全客观，因此主观性是一个相对概念:**  \n","\n","* 贝叶斯学派的主观性通过先验的设定来体现，透明，不易让人产生误解  \n","\n","* 频率学派的主观性暗含在各种**前提预设**中，比如方差分析中的方差齐性和正态性，这种看似‘客观的’预设，一方面难以满足，一方面也是一种主观的设定。  \n","\n","* 更为宏观的来说，样本的抽取，数据清理方式的选择，分析方法的选择，$p$值的设定，这些都存在主观性。因此，频率学派并没有想象的那么‘客观’。  \n","\n","* 主观不一定是坏事：通过量化方法将个体的经验和专家知识整合到数据分析之中。  \n","\n","|                     | 频率学派   | 贝叶斯学派   |  \n","| ------------------- | ---------- | ------------ |  \n","| 世界真相 (参数) | 固定       | 变化         |  \n","| 概率                | 抽样的噪音 | 信念         |  \n","| 推断过程            | NHST       | 贝叶斯定理   |  \n","| 数据                | 存在噪音   | 固定         |  \n","| 推断可更新性        | 否         | 是           |  \n","| 主观性              | 前提预设   | 通过先验设定 |  \n","\n","最后，尽管我们鼓励你在应用贝叶斯方法时保持批判性，但请不要担心它们比频率主义方法更主观。没有人能够从分析中完全消除主观性。我们所拥有的生活经验和知识影响着我们的一切，从我们提出的研究问题到我们收集的数据。在贝叶斯和频率主义分析中都要考虑这种主观性的潜在影响是很重要的。"]},{"cell_type":"markdown","metadata":{"_id":"091CE8C7E79A441289954B5285171619","id":"B9B4B69DF21542E09064A6784238907E","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["练习 4.1（将先验与描述配对）。  \n","\n","下面列出了五种不同的π的先验模型。  \n","请用以下描述之一标记每个先验：有些偏向π < 0.5，有些强烈偏向π < 0.5，有些将π置于0.5中心，有些偏向π > 0.5，有些强烈偏向π > 0.5。  \n","- a) Beta(1.8,1.8)  \n","- b) Beta(3,2)  \n","- c) Beta(1,10)  \n","- d) Beta(1,3)  \n","- e) Beta(17,2)  \n","\n","练习 4.2（将图形与代码配对）。  \n","\n","下面的绘图函数更可能使用了哪些参数生成了下面的图形？  \n","![](https://www.bayesrulesbook.com/bookdown_files/figure-html/unnamed-chunk-142-1.png)  \n","- a) alpha = 2, beta = 2, y = 8, n = 11  \n","- b) alpha = 2, beta = 2, y = 3, n = 11  \n","- c) alpha = 3, beta = 8, y = 2, n = 6  \n","- d) alpha = 3, beta = 8, y = 4, n = 6  \n","- e) alpha = 3, beta = 8, y = 2, n = 4  \n","- f) alpha = 8, beta = 3, y = 2, n = 4"]},{"cell_type":"code","execution_count":9,"metadata":{"_id":"517D7BBE1AA34E968FFF860A7666215E","collapsed":false,"id":"821750ED26F74A49B4C6D76526AE5EA9","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"ename":"TypeError","evalue":"'>' not supported between instances of 'ellipsis' and 'int'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 形成先验分布 \u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m prior \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(st\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mpdf(x,a,b))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 形成似然\u001b[39;00m\n\u001b[1;32m     32\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mbinom\u001b[38;5;241m.\u001b[39mpmf(y,n,x)\n","File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py:1984\u001b[0m, in \u001b[0;36mrv_continuous.pdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1982\u001b[0m dtyp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpromote_types(x\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1983\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray((x \u001b[38;5;241m-\u001b[39m loc)\u001b[38;5;241m/\u001b[39mscale, dtype\u001b[38;5;241m=\u001b[39mdtyp)\n\u001b[0;32m-> 1984\u001b[0m cond0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_argcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m (scale \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1985\u001b[0m cond1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_support_mask(x, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m&\u001b[39m (scale \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1986\u001b[0m cond \u001b[38;5;241m=\u001b[39m cond0 \u001b[38;5;241m&\u001b[39m cond1\n","File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py:950\u001b[0m, in \u001b[0;36mrv_generic._argcheck\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    948\u001b[0m cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[0;32m--> 950\u001b[0m     cond \u001b[38;5;241m=\u001b[39m logical_and(cond, (\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m))\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cond\n","\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'ellipsis' and 'int'"]}],"source":["# 导入数据加载和处理包：pandas\n","import pandas as pd\n","# 导入数字和向量处理包：numpy\n","import numpy as np\n","# 导入基本绘图工具：matplotlib\n","import matplotlib.pyplot as plt\n","# 导入高级绘图工具 seaborn 为 sns\n","import seaborn as sns\n","# 导入统计建模工具包 scipy.stats 为 st\n","import scipy.stats as st \n","\n","\n","#---------------------------------------------------------------------------\n","#                            请填入 Beta 分布参数，alpha 和 beta\n","#---------------------------------------------------------------------------\n","# 设置 Beta 分布参数\n","a = ...     # alpha\n","b = ...     # beta\n","\n","#---------------------------------------------------------------------------\n","#                            请填入观测数据 y 和 n\n","#---------------------------------------------------------------------------\n","y = ...     # y 代表支持数\n","n = ...     # n 代表总人数\n","\n","\n","# 设置 x 轴范围 [0,1]\n","x = np.linspace(0,1,10000)\n","# 形成先验分布 \n","prior = st.beta.pdf(x,a,b)/np.sum(st.beta.pdf(x,a,b))\n","# 形成似然\n","likelihood = st.binom.pmf(y,n,x)\n","\n","# 计算后验\n","unnorm_posterior = prior * likelihood                  # 计算分子\n","posterior = unnorm_posterior/np.sum(unnorm_posterior)  # 结合分母进行计算\n","likelihood = likelihood /np.sum(likelihood)            # 为了方便可视化，对似然进行类似后验的归一化操作 \n","\n","# 绘图\n","plt.plot(x,posterior, color=\"#009e74\", alpha=0.5, label=\"posterior\")\n","plt.plot(x,likelihood, color=\"#0071b2\", alpha=0.5, label=\"likelihood\")\n","plt.plot(x,prior, color=\"#f0e442\", alpha=0.5, label=\"prior\")\n","plt.legend()\n","plt.xlabel(\"Michelle's support ratio $\\pi$\")\n","plt.fill_between(x, prior, color=\"#f0e442\", alpha=0.5)\n","plt.fill_between(x, likelihood, color=\"#0071b2\", alpha=0.5)\n","plt.fill_between(x, posterior, color=\"#009e74\", alpha=0.5)\n","sns.despine()"]},{"cell_type":"markdown","metadata":{"_id":"42E2906CD63B496181BF56467EA74CCB","id":"DABDFE152DA9404280C1CEB20FCA766C","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### 总结  \n","\n","在本节课程中，我们探讨了后验模型在先验模型和数据之间的平衡。总的来说，我们观察到以下趋势：  \n","\n","- 先验影响：先验越不模糊、越具有信息量，即我们对先验越有确定性，先验对后验的影响就越大。  \n","- 数据影响：我们拥有的数据越多，数据对后验的影响就越大。因此，即使具有不同的先验，如果两次测量的数据充足并且相似，那么他们的后验结果会非常相似。  \n","- 此外，我们还看到在顺序贝叶斯分析中，随着越来越多的数据的出现，我们逐步更新后验模型。这个后验的最终结果不受观察数据的顺序（即后验对数据的顺序不变）或者是一次性观察数据还是逐步观察数据的影响。"]},{"cell_type":"markdown","metadata":{"_id":"C0B8909E5EA949FEAF334E5705ED7605","id":"01A82DFE6A544B0D94A3B48FCAB0D313","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["### Bonus：使用数学公式证明，后验确实利用了来自先验和似然的信息"]},{"cell_type":"markdown","metadata":{"_id":"71FCBECB297D481E9789BD954097DC95","id":"77298B80B08642D0BCD5957BA8D5FD6F","jupyter":{},"notebookId":"65122128bec8ab1021e0f1f4","runtime":{"execution_status":null,"is_visible":false,"status":"default"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":["（* 注：以下涉及的公式包含上一节bonus中的内容）  \n","\n","由于后验分布属于beta分布，因此它的平均值可以写成：  \n","\n","$$  \n","E(\\pi | Y=y)  = \\frac{\\alpha + y}{\\alpha + \\beta + n}  .  \n","$$  \n","\n","我们可以将$\\frac{\\alpha + y}{\\alpha + \\beta + n}$拆成以下两部分  \n","\n","$$  \n","E(\\pi | Y=y)  \n","= \\frac{\\alpha}{\\alpha + \\beta + n} + \\frac{y}{\\alpha + \\beta + n}  \\\\  \n","= \\frac{\\alpha}{\\alpha + \\beta + n}\\cdot\\frac{\\alpha + \\beta}{\\alpha + \\beta} + \\frac{y}{\\alpha + \\beta + n}\\cdot\\frac{n}{n}  \\\\  \n","= \\frac{\\alpha + \\beta}{\\alpha + \\beta + n}\\cdot\\frac{\\alpha}{\\alpha + \\beta} + \\frac{n}{\\alpha + \\beta + n}\\cdot\\frac{y}{n}  \\\\  \n","= \\frac{\\alpha + \\beta}{\\alpha + \\beta + n}\\cdot E(\\pi) + \\frac{n}{\\alpha + \\beta + n}\\cdot\\frac{y}{n}  .  \\\\  \n","$$  \n","\n","$$  \n","y:success trial,\\; n:total trials \\\\  \n","y/n表示观察到的数据比例  \n","$$  \n","\n","且，  \n","$$  \n","\\frac{\\alpha + \\beta}{\\alpha + \\beta + n} + \\frac{n}{\\alpha + \\beta + n} = 1.  \n","\n","$$  \n","\n","\n","可以看到，后验均值可以被分解为  \n","<center>  \n","权重*先验均值 + 权重*数据  \n","</center>  \n","\n","那么，当数据越多，即n越大时，先验的权重就会更小，接近0；而数据的权重就会越大  \n","\n","因此，后验正是权衡了来自先验和似然的信息"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}
