{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"AB2F72934DA24227B3A2E1EF18DAD1C4","jupyter":{},"notebookId":"6365fc97022a27bd59fcb767","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### 模型的泛化能力：预测准确性\n\n前面提到的诸多模型拟合优度 (Goodness of fit) 指标，只能衡量模型对于当前样本的拟合程度。\n\n对于样本外的数据，我们不确定该模型是否具有**泛化能力**，即该模型是否能准确的预测样本外的数据。\n\n为了评估模型的预测能力，我们有以下3种策略：\n1. 通过新数据对模型进行评估。我们可以收集新的数据，并检验模型的预测能力。\n2. 从已有样本中拿出一部分数据用来预测。即交叉验证。\n3. 通过统计方法进行近似。比如使用对交叉验证近似的信息熵指标来评估模型的泛化能力。"},{"cell_type":"markdown","metadata":{"id":"449A531CF85F4E9ABEED728BB22EABF7","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 交叉验证\n\n收集新数据来检验模型的预测能力是一种理所当然的直觉。但心理学数据不同于其他学科的数据，它常受到**时间因素**和**抽样**的影响。\n- 比如，心境可能随着季节变化，因此在不同季节收集到的数据会受到时间的影响。\n\n因此，一种更高效的方法是，一次性多收集一些数据，选择其中的一部分作为预测数据。\n\n但问题在于，我们选择哪一部分数据作为预测数据呐？或者说，我们该如何有效的对数据进行抽取呐？\n\n**交叉验证**的目的就在于：提供不同的抽取预测数据的策略"},{"cell_type":"markdown","metadata":{"id":"B1CADF6BDCDC42E79918C6A1FC066CBC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"常见的交叉验证策略：\n1. 分半交叉验证 (Split-half cross-validation)\n\t- 分半交叉验证将观测数据对半分成两部分，分别在不同的数据集上拟合模型，并在另外一半数据集上验证模型，最后再对比不同的模型在两份数据集作为验证集时的预测准确度。\n2. K 折交叉验证 (K-fold cross-validation) \n\t- K 折交叉验证把数据分成 K 分，其中一份作为训练集，其余的 K-1 分数据集作为验证集，总共重复这个流程 K 次。以 K 次验证结果的均值作为验证标准。\n3. 留一法交叉验证 (Leave-one-out cross-validation)\n\t- 留一法交叉验证是 K 折交叉验证的一个特例，当分折的数量等于数据的数量时，K 折留一法便成了留一法交叉验证。留一法交叉验证相较于普通的交叉验证方法，几乎使用了所有数据去训练模型，因此留一法交叉验证的训练模型时的**偏差 (bias) 更小、更鲁棒**，但是又因为验证集只有一个数据点，验证模型的时候**留一法交叉验证的方差 (Variance) 也会更大**。"},{"cell_type":"markdown","metadata":{"id":"268B2411BC6A473E9DE411265BF42AAC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"K 折交叉验证图示\n![](https://hub.packtpub.com/wp-content/uploads/2019/05/KFold.png)\n\nsource: https://hub.packtpub.com/cross-validation-strategies-for-time-series-forecasting-tutorial/"},{"cell_type":"markdown","metadata":{"id":"15E81112F633419FA4F9DB96C71AC219","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 信息准则(information criteria)\n\n尽管交叉验证存在诸多优势，并且避免了收集数据的潜在问题，但是交叉验证**在认知神经科学里的认知建模领域里的使用并不广泛**，\n\n其最主要的原因在于，研究者收集的数据**样本量往往有限**，然而很多计算模型却对数据样本量有所需求，如果使用交叉验证，将数据拆分，那么很有可能导致拟合模型的试次数量不足，使得模型拟合和验证的结果较差，进而导致产生一类错误和二类错误的概率增大。\n\n为了解决这些问题，统计学家们凭借数学与统计工具可以近似得到与交叉验证相似的结果。\n\n这类近似交叉验证的指标被称为**信息准则**(information criteria)。"},{"cell_type":"markdown","metadata":{"id":"A835429E78A748B5BE97549F139A2844","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"信息准则是对统计模型**预测精度**的一种度量。它考虑**模型与数据的匹配程度**，并通过**模型的复杂性**进行惩罚。\n\n从前面关于模型**偏差方差权衡 **(Bias variance trade-off)的讨论中我们了解到\n- **偏差 bias** 会随着模型的复杂度的增大而减小，偏差大的模型往往*欠拟合*；\n- **方差 error** 则会随着模型复杂度的增大而增大，方差大的模型往往*过拟合*。\n- 方差和偏差之间存在一种**权衡关系**。\n- 一般来说，复杂的模型容易过拟合，而简单的模型则容易欠拟合。\n\n其中：\n- **模型与数据的匹配程度**更多的体现在模型的**偏差 bias**上。\n- 而**模型的复杂性**更多的体现在模型的**方差 error**上。"},{"cell_type":"markdown","metadata":{"id":"A3BA6B8A87B3496C9D44EF22D9BA5588","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"通过稍微数学化的语言表达就是：\n\n$ 信息准则 = 偏差 + 方差 = bias + error $\n- 其中 bias 往往与模型的似然值相关。可以想象，似然值越大，模型的偏差越小。\n- error 与模型的复杂程度相关。比如，模型的参数越多模型越复杂。\n\n可见，信息准则越小，偏差和方差就越小。因此，**信息准则越小，代表模型的预测性越好**。"},{"cell_type":"markdown","metadata":{"id":"F22BA4CC600F4E28B125358CAD77ACB1","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"常见的4类信息准则：\n1. AIC (Akaike information criterion)\n2. DIC (Deviance information criterion)\n3. WAIC (Widely applicable information criterion)\n4. LOO-CV (Leave-one-out cross-validation)"},{"cell_type":"markdown","metadata":{"id":"63741BADA01A47B294A0839838677898","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 1. AIC (Akaike information criterion)"},{"cell_type":"markdown","metadata":{"id":"7ABEB248AF6F4249831570CE2472A8D4","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"AIC是最简单的信息准则标准，由日本统计学家赤池弘次 (Hirotugu Akaike) 提出 (Akaike, 1974)，是频率主义统计学里最为经典的模型比较指标之一。\n\n其表达式如下：\n$$\nA I C= bias + error = -2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)+2 p_{A I C}\n$$\n\n别被公式吓到🧐，它的原理其实很简单。"},{"cell_type":"markdown","metadata":{"id":"7FB883B7C30141078092183CC90662E5","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"$A I C= bias + 2 p_{A I C}$\n\n- 其中，$2 p_{A I C}$ 就是 error，代表模型参数数量的两倍。\n- error 描述了模型的复杂程度。即参数越多，模型越复杂，相应的 AIC 值越大，模型预测性越差。"},{"cell_type":"markdown","metadata":{"id":"316727DBDAB14FB6988BEA5AFE02591C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"$A I C = -2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)+2 p_{A I C}$\n\n- $-2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)$ 为 bias，描述了模型对于当前数据的匹配程度。\n- bias 与 似然函数 $p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)$ 相关。$\\hat{\\theta}_{m l e}$为最大似然发求得的参数值。 \n  \n  我们知道，模型拟合的越好，似然值越大，因此$\\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)$越大。相应的 $-2\\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)$ 的值越小。那么 AIC的值也越小。"},{"cell_type":"markdown","metadata":{"id":"1969289189F7477D81C4D7AAB053F640","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"需要注意的是 AIC 只考虑了最大似然对应的参数值 $\\hat{\\theta}_{m l e}$, 因此它适用于频率学派模型的评估。而对于贝叶斯学派来说，**由于参数为分布，因此不能使用AIC来评估模型**。"},{"cell_type":"markdown","metadata":{"id":"F6A3B2A44A7E436A82E7203F999F3247","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 2. DIC (Deviance information criterion)\n\n为了解决 AIC 无法评估贝叶斯模型。加之 AIC 只考虑到了**模型参数数量**所带来的复杂性。\n\n统计学家们提出了\"贝叶斯参数估计版的 AIC\"，即 DIC (Deviance information criterion) 。\n\n$$\n\\mathrm{DIC} = -2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\bar{\\theta}\\right) +2 p_{D}\n$$"},{"cell_type":"markdown","metadata":{"id":"1CF12B426CF1487B911DDC8733679EE6","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"可以看到，DIC 与 AIC 的公式非常相似。\n\n- 其中$-2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\bar{\\theta}\\right)$ 为 bias。也称为 deviance，即 DIC 的 D。\n- 与 AIC 的区别在于，由于贝叶斯模型中的参数 $\\theta$ 为概率分布，DIC 选择用参数分布的均值 $\\bar{\\theta}$ 来替代 AIC 中的 $\\hat{\\theta}_{m l e}$。"},{"cell_type":"markdown","metadata":{"id":"E4D2CC031C994610BD2798D372AC15C1","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"DIC 对于 error 的理解与 AIC 不同。DIC 考虑了参数后验分布中所有采样对于数据的预测性。\n\n$$\n\\frac{1}{2}error = p_{D} = \\bar{D} - D_{\\hat{\\theta}}\n$$\n\n- 要理解 DIC 中的 error 与 DIC 如何评估后验分布中不同参数采样的影响，关键在于了解 D (deviance) 的意义。\n- D (deviance) 的公式为 $-2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\theta\\right)$。\n- 可见，bias 也可以用 D 来表示，即 $D_{\\hat{\\theta}}$ 。差异在于，公式中的 $\\theta$ 变为 $\\hat{\\theta}$。 并且这个 bias $\\hat{\\theta}$ 也出现在 $p{D}$ 的公式中。\n- 有了 $\\hat{\\theta}$，只需要再得到 $\\bar{D}$ 就行了。我们可以用参数后验分布中所有采样(如n个采样)求得，n个 $D_i$， i为1到n。那么这 n个 $D_i$ 的均值就可以表示**参数后验分布中所有采样对于数据的平均预测性**，即 $\\bar{D}$。\n- $p_{D} = 所有参数采样 D 的均值 - 参数分布均值的D = \\bar{D} - D_{\\hat{\\theta}}$\n- 可以想象，当两种 D 的差异最小时，$p_{D} =0$，此时模型的预测性最好，DIC值也更低。"},{"cell_type":"markdown","metadata":{"id":"6AD7CD1D11794FA6936075E4C9555E8B","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rkv282l86v.png?imageView2/0/w/640/h/640)\n\n\nDIC 通过 deviance 评估模型的预测性，避免了 AIC 只考虑参数数量复杂性对于模型的影响。"},{"cell_type":"markdown","metadata":{"id":"26F33DA106EC494DA0F7A8ABAEE7A02E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 3. WAIC (Widely applicable information criterion)\n\nDIC 很好的解决了 AIC 无法适用于贝叶斯模型的问题，并且考虑了参数后验分布的影响。\n\nDIC 的问题在于：\n- 如果参数后验分布不是正态分布，那么 $D_{\\hat{\\theta}}$ 的估计会存在偏差。\n- 这进而反应为，$p{D}$ 是负数。$p{D}$ 为负数导致整个 DIC 为负数，也是 DIC 的一大问题。\n\n为了解决上面的问题，日本统计学家渡边澄夫提出了“DIC 的升级版”的升级版，WAIC (Widely applicable information criterion)。\n\n$$\nW A I C=\\sum_{i}^{n} \\log \\left(\\frac{1}{s} \\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right)-\\sum_{i}^{n}\\left({V}^{s}_{j} \\log p\\left(Y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right)\n$$"},{"cell_type":"markdown","metadata":{"id":"826C805F8C7F4C06AFA50144FAE507C3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"$\\sum_{i}^{n} \\log \\left(\\frac{1}{s} \\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right)$ 为 bias 与 似然函数有关。\n- $\\sum_{i}^{n} \\log \\left(\\frac{1}{s} \\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right) = \\sum_{i}^{n} \\log \\bar{L}$，L 为似然函数。\n- $\\bar{L}$ 类似于 $\\bar{D}$，是参数后验分布中所有参数对应的似然值的均值。\n- 区别在于：\n  - WAIC 每次选择一个数据点，计算它在所有后验采样上的似然值 $\\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right) = \\sum_{i}^{n} \\log \\bar{L}$，\n  - 再求这些似然值在不同后验上的平均值 $\\frac{1}{s} \\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right) = \\sum_{i}^{n} \\log \\bar{L}$，\n  - 最后将不同数据点上的似然值求和，即 $\\sum_{i}^{n} \\log \\left(\\frac{1}{s} \\sum_{j}^{S} p\\left(y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right) = \\sum_{i}^{n} \\log \\bar{L}$。"},{"cell_type":"markdown","metadata":{"id":"20285AAC5F27430CBC659F9E7878CFD9","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"$\\sum_{i}^{n}\\left({V}^{s}_{j} \\log p\\left(Y_{i} \\mid \\boldsymbol{\\theta}^{j}\\right)\\right)$  为 error，与 bias 不同的是，bias 计算的是似然的均值，而 error 通过 V 计算似然值的变异。\n- 与上面的流程类似，首先选择一个数据点i，求得它在不同参数j下的似然值 $\\log p(Y_{i} \\mid \\boldsymbol{\\theta}^{j})$，\n- 计算该数据点在不同参数采样j下似然的变异 $({V}^{s}_{j} \\log p(Y_{i} \\mid \\boldsymbol{\\theta}^{j}))$\n- 最后，将每个数据点的变异加起来 $\\sum_{i}^{n}({V}^{s}_{j} \\log p(Y_{i} \\mid \\boldsymbol{\\theta}^{j}))$"},{"cell_type":"markdown","metadata":{"id":"832D98262DB94193AF874E9F4CA43F2B","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rkv28lzzs8.png?imageView2/0/w/640/h/640)\n"},{"cell_type":"markdown","metadata":{"id":"4BB20F8A4C8343D7ACEEFE33934CCB87","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 4. LOO-CV (Leave-one-out cross-validation)\n\nWAIC 是非常优秀且常用的指标，其本质是模型对于未知数据的预测能力的**近似**。\n\n另一种与 WAIC 非常类似的近似方法是前文提到的**留一交叉验证法** (Leave-one-out cross-validation, LOO-CV) \n\n$$\nELPD_{LOO-CV} = \\sum_{\\mathrm{y}} \\log E_{\\theta}\\left(L\\left(y_{i}|\\theta_{-i}\\right)\\right)\n$$"},{"cell_type":"markdown","metadata":{"id":"D040BC3FBBD146BA9E557E5145D48374","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"$ELPD_{LOO-CV}$ 的数学表达式非常类似，其特点为：\n- $ELPD_{LOO-CV}$ (expected log pointwise predictive density) 利用了留一交叉验证的思想，用去除数据点i剩下的数据拟合模型；再回过来用该模型的参数去预测数据点i。\n- 因此，ELPD 与 WAIC 的 bias 非常类似。区别在于，似然中的参数值不是通过所有数据进行拟合的，而是通过去除数据点i剩下的数据拟合得到的参数 $\\theta_{-i}$。\n- 此外，更巧妙的是，由于 $ELPD_{LOO-CV}$ 是直接对未来数据进行预测，因此不需要再惩罚模型，即不需要 error项了。"},{"cell_type":"markdown","metadata":{"id":"4D961BE79CBD470D9D4F433F03968BFB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rkv28zavh6.png?imageView2/0/w/640/h/640)\n"},{"cell_type":"markdown","metadata":{"id":"E05B1ACC376F44319A541C7CA6225850","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"在实际操作中，我们通过 `ArViz` 的函数可以很容易的获得 WAIC 和 $ELPD_{LOO-CV}$，我们称为 **LOO** 方法。\n\n此外，由于 $ELPD_{LOO-CV}$ 的计算量也比较大，ArViz 会使用 Pareto Smooth Importance Sampling Leave Once Out Cross Validation (PSIS-LOO-CV) 来近似 $ELPD_{LOO-CV}$。\n\nPSIS-LOO-CV 有两大优势：\n1. 计算速度快，且结果稳健\n2. 提供了丰富的模型诊断指标"},{"cell_type":"markdown","metadata":{"id":"BAC3D301FD7A4A4AB3F901150EE94C98","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"### Model Averaging\n\n前面我们讨论了如何评估单个模型的**拟合优度**与**预测精度**。\n\n但判断模型预测性能的另一个思路是：拟合多个模型，比较不同模型的预测能力。在实践中，我们对不同的模型赋予不同的权重，并组合他们生成一个元模型 (meta-model)，进而进行元预测，以此评估不同模型权重的影响。\n\n这种给不同模型赋予权重的方法称为 模型平均法 Model Averaging。\n常见有三种计算模型权重的方式：\n1. Marginal likelihood\n2. BIC (Bayesian information criterion)\n3. Pseudo Bayesian model averaging"},{"cell_type":"markdown","metadata":{"id":"2CE5C18A893341EF88BEE954BE7ED75C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 1. Marginal likelihood\n\n边缘似然或者边际似然 (marginal likelihood) 是贝叶斯公式的分布部分\n- 即 $p(\\theta|data)=\\frac{p(data|\\theta)p(\\theta)}{p(data)}$ 中的 $p(data) = \\int_{\\theta}^{} p(data|\\theta)p(\\theta)d\\theta$ \n- 边缘似然与贝叶斯公式分子部分的似然不同，表达了模型对数据的平均拟合 (Average fit)，因此它可以作为模型选择的指标。*边缘似然越大，说明模型对样本数据解释的越好*。\n- 当比较两个模型时，可以将边缘似然转化为**贝叶斯因子**(Bayes factor)。"},{"cell_type":"markdown","metadata":{"id":"9252096431E94EB8B0709D86806D7304","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"Bayesian Model Averaging\n\n$$\nw_k = \\frac{e^{-ML_{k}}}{\\sum e^{-ML_{k}}}\n$$\n\n通过边缘似然可以计算 Bayesian Model Averaging。\n- 假设有 k 各模型。\n- k个模型的边缘似然为 $ML_{k}$。\n- k个模型的权重 $w_k$ 为当前模型的边缘似然 $ML_{k}$ 比上 所有模型边缘似然之和 $\\sum e^{-ML_{k}}$。\n"},{"cell_type":"markdown","metadata":{"id":"FB0E8CFCEA9D41648EA1FBD5E38F844F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 2. BIC (Bayesian information criterion)\n\n因为边缘似然计算量巨大，因此我们需要一些快速的计算方式，比如 BIC (Bayesian information criterion)。\n\n$$\nA I C=-2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right)+2 k\n$$\n\n$$\nB I C=-2 \\sum_{i}^{n} \\log p\\left(y_{i} \\mid \\hat{\\theta}_{m l e}\\right) + 2 k*ln(n)\n$$\n\nBIC 与 AIC 非常类似，区别在于惩罚项 error的不同。\n- BIC 中的 error 在 AIC error 的基础上乘以 ln(n)。\n- 其中，k为模型参数的数量；n为数据的数量。"},{"cell_type":"markdown","metadata":{"id":"DFFEF5A074ED4E95B4D5A765CFD44CC9","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"BIC 的特点：\n- 在公式上与 AIC 高度相似，因此可以用来检验模型拟合优度，其值越小，模型拟合越好。\n- BIC 的 error 往往比 AIC 的更大，即惩罚更大，因此，**BIC 通常会选择简单的模型**。\n- BIC 虽然适用于贝叶斯模型，但是它没有考虑先验的影响。\n- 最重要的是，BIC **是边缘似然的近似**，计算速度比 ML 更快，并且同样也可以被用来计算贝叶斯因子。"},{"cell_type":"markdown","metadata":{"id":"3B6D6D3C66DA4A71834A49A9C31DAEF4","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"#### 3. Pseudo Bayesian model averaging\n\nBIC 虽然能近似边缘似然， 但是其 error 只考虑了参数数量和数据数量的复杂性，也没有考虑到先验的影响。\n这样计算的模型权重很可能存在偏差。\n\n为了更高效的计算模型的权重。一种可行的方法是 Pseudo Bayesian model averaging。\n- 即通过 WAIC 与 LOO 来近似边缘似然。\n- 再通过 Bayesian model averaging 公式计算模型权重。\n\n\n$$\nw_i = \\frac{e^{-\\Delta_{i}}}{\\sum_{j}^{k} e^{-\\Delta_{j}}}\n$$\n"},{"cell_type":"markdown","metadata":{"id":"9B858DB4D2AC49628342C875DC189A4D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"上面的公式与 Bayesian model averaging 的公式 $w_k = \\frac{e^{-ML_{k}}}{\\sum e^{-ML_{k}}}$ 很像。\n区别在于：\n- 通过 WAIC 或者 LOO 在模型中的差值 $\\Delta_{j}$ 替代了 边缘似然 ML。\n- $\\Delta$ 表示的是，第 i 或者 j个模型的 WAIC 与 最优模型的 WAIC 的差值。\n\nPyMC3 与 Arviz 提高了很多关于 Pseudo Bayesian model averaging 计算的方法，之后的实践中，我们将注重于通过 Pseudo Bayesian model averaging 展示模型平均法的作用。"},{"cell_type":"markdown","metadata":{"id":"A65A8202204D49F59C88220EC39413DB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6365fc97022a27bd59fcb767","trusted":true},"source":"总结：\n\n模型拟合优度的方法包括：\n- 拟合优度 \n- mse \n- 对数似然\n\n模型预测进度的方法包括：\n- AIC\n- DIC\n- WAIC\n- LOO\n\n模型平均法包括：\n- Bayesian model averaging\n- BIC\n- Pseudo Bayesian model averaging"},{"cell_type":"markdown","source":"|          | AIC                          | DIC                              | WAIC   | LOOCV  | BIC                          |\n| -------- | ---------------------------- | -------------------------------- | ------ | ------ | ---------------------------- |\n| 适用框架 | 频率论                       | 贝叶斯                           | 贝叶斯 | 贝叶斯 | 贝叶斯/频率论                |\n| bias     | 最大似然所对应参数下的似然值 | 参数均值对应的似然 D               | ELPD   | $ELPD_{LOO-CV}$   | 最大似然所对应参数下的似然值 |\n| error    | 参数数量的两倍               | $D = \\bar{D} - D_{\\hat{\\theta}}$                      | 似然的变异   |    | 参数数量+数据数量            |","metadata":{"id":"DBE02B0FAB6140E383E8301C9FF4EEC6","notebookId":"6365fc97022a27bd59fcb767","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}