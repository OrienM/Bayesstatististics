{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D89B0EAB542642F98900CCC4D4E49360","jupyter":{},"mdEditEnable":false,"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":[" ## Part 3: 似然与最大似然 (Maximum Likelihood)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"48C4483CE3334F1283C8DFEDBA662683","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["在现实中，我们很少知道疾病在人群中的患病率$θ$。\n","\n","因此，我们的目的就是估计这些参数（患病率$θ$），估计这些参数也是统计建模的主要重点。\n"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B03FAA02AD7748C98F757D40EC311700","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["频率学派估计模型参数最常用的方法为最大似然法（Maximum Likelihood）。（其实我们心理统计的大多数方法都可以视作模型，而我们想要估计的均值和均值差异等统计量，就是模型中的参数，因此我们对这个估计过程并不陌生）。\n","\n","极大似然估计的原理很简单\n","- 首先，假设一个参数的可能性，即假设模型参数值为多少。\n","- 然后，根据数据样本推测该参数的最大可能性，通过变化参数，看在那个参数下，样本数据最有可能出现。"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"AD8F15CC2C4146A0B6D0EA2AD8A9707B","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["### 3.1 Estimating disease prevalence via Maximum Likelihood"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"C9C3B9EA855B493B86BFEEDAA7020F16","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["回到估计患病率的例子。\n","\n","假设在100个人的随机样本中，有10人是疾病阳性。\n","\n","- 我们可以本能的做出假设：人患病的可能性为$0.1 = 100/10$\n","- 但我们可以进行怀疑，在其他患病率条件下，比如 $\\theta = {0.05,0.2,0.5,0.8}$的时候，100人中出现10人阳性的可能为多少。\n","我们可以做一些尝试，找到使得可能性最大的参数值。"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"5DA2D2CF923341748F44EC74EC4F1FA1","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["比如，我们假设患病率参数$\\theta=0.1$ （根据我们直觉得到，后续我们可以假设其他值），加上我们获取的数据 总人数$n=100$，阳性患者人数 $\\beta=10$。\n","\n","再根据的二项分布公式 $\\operatorname{Pr}(\\beta,n \\mid \\theta) = \\binom{\\beta}{n} \\theta^{\\beta}(1-\\theta)^{n-\\beta}$，可以计算得到 $\\operatorname{Pr}(10, 100 \\mid 0.1) = 0.13 =   \\binom{10}{100}0.1^{10}(1-0.1)^{100-10}$，说明我们假设的可能性为 0.13。"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"id":"A004ED60DF2B44A89E96260E9CC6F851","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["假设Θ为0.1条件下，100人中有10人患病的可能性为：0.13186534682448803\n"]}],"source":["# 通过代码进行计算\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import binom, bernoulli\n","from scipy import stats\n","\n","# 函数对应前文的二项分布公式 binom.pmf(β,n,θ)，\n","# 带入影响参数β,n,θ可计算得到我们假设参数θ出现的可能性\n","theta = 0.1\n","beta = 10\n","n = 100\n","L = binom.pmf(beta,n,theta)\n","print(f\"假设Θ为{theta}条件下，100人中有10人患病的可能性为：{L}\")"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"C678CFF448FE412A8616403B21324335","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["我们已经完成了最大似然的第一步，通过假设参数值估计在当前数据下参数出现的可能性。\n","\n","🧐现在我们进行第二个步骤，通过一些尝试，找到使得L最大的参数。比如假设 $\\theta = {0.05,0.2,0.5,0.8}$，看此时假设成立可能性的变化。"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"id":"FC633E63869C4A6E9C3801CA7AB2E57C","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["假设Θ为Ellipsis条件下，100人中有10人患病的可能性为：0.13186534682448803\n"]}],"source":["######################################################\n","# 练习阶段\n","######################################################\n","theta = ... # 请尝试不同的 θ假设\n","beta = 10\n","n = 100\n","L = binom.pmf(10,100,0.1)\n","print(f\"假设Θ为{theta}条件下，100人中有10人患病的可能性为：{L}\")"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"8A0D9DD28FE141A29A5F7CD48942FA3E","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["如果我们尝试（遍历）所有参数$\\theta$的值，我们可以画参数$\\theta$和假设可能性$L$的关系。"]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":false,"id":"E3686F12F36448559670E37DA45CBC86","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<img src=\"https://cdn.kesci.com/upload/rt/E3686F12F36448559670E37DA45CBC86/ri8p3gd5ur.png\">"],"text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["theta = np.linspace(0,1,1000)\n","L = binom.pmf(beta,n,theta)\n","\n","fig, ax = plt.subplots()\n","ax.plot(theta,L)\n","ax.vlines(0.1,ymin=0,ymax=0.13,color=\"red\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"AC9D139DBE1E4CAF92C743073F0BB863","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["可以看到，当$\\theta$为0.1时，该参数出现的可能性最大，这验证了我们的假设。\n","\n","通过尝试各种参数寻找可能性最大的那个参数，这就是 **最大似然估计**。\n","- 与通过一次计算（求平均值）得到参数不同，最大似然估计强调去尝试更多的可能性\n","- 结合参数与数据计算的可能性$L$，就是似然值（Likelihood），我们的目的就是找到最大似然值所对应的参数\n","- 最大似然估计的关键在于似然函数，只有知道似然函数，才能计算似然值\n","- 最大似然估计的过程是在固定数据$\\beta,n$的条件下变化参数$\\theta$\n","\n","根据以上特性，似然函数的公式可以写作 $\\operatorname{L}(\\theta \\mid \\beta,n ) = \\binom{\\beta}{n} \\theta^{\\beta}(1-\\theta)^{n-\\beta}$，最大似然估计可以表达为 $\\theta^*= arg\\max_{\\theta}\\operatorname{L} =arg\\max_{\\theta}Pr(\\beta,n|\\theta)$"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"F0DF17E8FCE842C7B08A6E7FD5D02483","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["### 3.2 Maximum likelihood 的真实计算过程"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B615133739AB48F5B24D99C4DC25DFD9","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["- 获取实验数据，比如，100中有10人患病。\n","- 确定似然函数，比如二项分布函数$\\operatorname{L}(\\theta \\mid \\beta,n ) = \\binom{\\beta}{n} \\theta^{\\beta}(1-\\theta)^{n-\\beta}$\n","- 通过对数log将似然函数中的连乘变为求和，比如 $log(\\theta^{\\beta}(1-\\theta)^{n-\\beta}) = log(\\theta^{\\beta}) + log((1-\\theta)^{n-\\beta})$。\n","- 对似然函数求导（微分）以获取最大似然。在前文图中的演示里我们发现，最大似然对应的参数值 $\\theta = 0.13$（红色线）即为分布的峰部（peak），因此可以通过求导的方式计算出峰部的位置，即参数的估计值。"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6B60EB5314544884864338B348DD106A","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["### Maximum Likelihood的推断过程"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"8AE8BC009B3042F18986D7CCA349B3E1","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["很容易发现，最大似然估计是一个点估计的过程，即我们通过最大似然值，找到最符合数据的参数值$\\theta$。\n","\n","这与我们之前学心理统计时的统计方法相似，比如单样本t检验中估计样本在总体的位置，或者回归模型中估计参数$\\beta$。\n","\n","但这个方法好像与我们现在学习的贝叶斯方法并不相同，因为这个方法的主角并不是概率分布，而是似然函数。\n","\n","另一个需要注意的问题是，同频率学派的其他方法容易受到极端值的影响一样，通过似然函数的推断也容易受到采样误差的影响 （因为，极大似然估计的过程是固定数据不变，变化的参数值）。\n","\n","为了进一步确定最大似然估计的准确性，频率学派采取调查似然函数曲率的方式确定最大似然估计的准确性。\n","\n","如图：\n","![Image Name](https://cdn.kesci.com/upload/image/ri8tjni0ka.png?imageView2/0/w/960/h/960)\n","\n","如果似然在最大似然估计附近**快速的**达到峰值(见图中的黑线)，那么这表明只有一小范围的参数可以产生相似的似然值。在这种情况下，我们对参数估计会有更多的信心。\n","\n","相比之下，如果似然在最大似然估计值的附近**平缓地**达到峰值(见图4.8中的红线)，那么一个大范围的参数值可以产生相似的似然值。我们对该估计就不那么有信心了。\n","\n"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"20B491BD371C4F6C8624F133795B2058","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["### Summary"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CBBFF416FB53455A80ECA388BA6FEFCB","jupyter":{},"notebookId":"6322ba0f9caeb667565ccc14","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":["- 似然（likelihood）和概率（probability）的区别\n","\t- 概率（probability）：参数固定，数据不固定\n","\t- 似然（likelihood）：数据固定，参数不固定\n","- 最大似然估计（maximum likelihood）\n","\t- 频率学派的点估计方法\n","\t- 通过似然函数的曲率（curvature）评估估计的准确性（certainty）\n","\t- 不是有效的概率分布（probability distribution）\n","\n","如何获得有效的概率分布进行推断，而不只是基于似然函数进行推断。\n","\n","我们需要贝叶斯公式，通过贝叶斯公式（结合先验经验）把似然函数转化为概率分布。"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"7698be9997df07547d4a08fe6d7a8ab77df170c0c470ab0ace6a1c514673cd42"}}},"nbformat":4,"nbformat_minor":0}
