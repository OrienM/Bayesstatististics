{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B2E13C03C0E748919DA40A0B58CB4468","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"## Part 2: 广义线性模型(Generalized linear model, GLM)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D1C645DC1627451E809A160B16451896","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"本节的目的在与：了解如何通过广义线性模型(Generalized linear model, GLM)拟合正确率等二元决策变量。\n\n重点在于：\n- 了解使用 Pymc 进行数据分析的完整 workflow\n- 了解因变量为正确率等二元决策变量(往往记录为0或1，1代表回答正确，0代表回答错误)的特征\n- 了解广义线性模型(Generalized linear model)中的伯努利(Bernoulli)分布和链接函数(link function)\n"},{"cell_type":"markdown","metadata":{"id":"98F4B59B26B34C4BBD49DD1736936910","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"### 什么是GLM？"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6832CF0A887A408FA3F1126ADD7DEF47","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"GLM 是一般线性模型的一种扩展。我们首先介绍一般线性模型的基础知识。\n\n在一般线性模型中，因变量被假定为服从正态分布 $y \\sim Normal(\\mu,sigma)$。\n- 其中，y为观测项；$\\mu$为预测项；sigma 为误差项。\n- 预测项展开为 $\\mu  = \\alpha + \\beta *x$。\n- 例子，比如用员工工龄(x)预测他们的工资(y)，其中x和y都为连续变量。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/rll49b8jn9.png?imageView2/0/w/640/h/640)"},{"cell_type":"markdown","metadata":{"id":"0A68FE9572BC4C1DBD879D023E2ED6FD","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"**当自变量为离散变量**\n\n比如自变量为性别，因变量为智力测量成绩(如瑞文推理测验分数)。\n\n由于性别为二分变量，因此我们使用 **虚拟变量(dummy coding)** 对性别进行编码。\n- 虚拟变量(或哑变量)是一种对称名（或名义）变量的分类重新编码，使得它们能在回归方程中作为自变量的方式。\n- 它将某一初始名义变量重新建构得到一个或多个二分变量。\n- 当某个样本观测值属于名义变量的某个类别时，表征这个类别的虚拟变量就被赋值为1，否则便被赋值为0。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/rlo9kb4fsn.png?imageView2/0/w/640/h/640)\n"},{"cell_type":"markdown","metadata":{"id":"28298CEAA9B046719D2525297FACDE0D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"比如，我们这里男性编码为0，将女性编码为1。\n\n$Y = \\beta_0 + \\beta_1 X + \\epsilon$\n- 当虚拟变量赋值为X=0时， $E(Y) = \\beta_0$ 代表男性的平均家庭收入\n- 当虚拟变量赋值为X=1时，$E(Y) = \\beta_0+\\beta_1$ 代表女性的平均家庭收入\n- $\\beta_1$ 表示女性相对于男性的家庭收入的差值\n"},{"cell_type":"markdown","source":"- 当自变量为二分变量时，t 检验是线性模型的特殊形式。包括独立样本t检验和配对样本t检验。\n- 当自变量为超过俩水平的分类变量时，方差分析是线性模型的特殊形式。包括方差分析和重复测量方差分析。\n\n例子中的性别为二分变量，对应独立样本t检验。\n\n与独立样本t检验不同，在线性模型中检查两组之间的差异相当于检查回归系数 $b_1 $的显著性。\n\n![Image Name](https://cdn.kesci.com/upload/image/rloa41zjxa.png?imageView2/0/w/640/h/640)\n","metadata":{"id":"98BC16E313F843098B3A213138574B58","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}},{"cell_type":"markdown","metadata":{"id":"662739358C174FF4BE1A887CA032BE86","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"**当因变量为离散变量**\n\n比如，因变量为答题正确率，其中1代表回答正确，0代表回答错误。\n\n正确率为离散变量，并不服从正态分布，而是服从伯努利(Bernoulli)分布。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/rloa62fn8w.png?imageView2/0/w/960/h/960)\n\n\n![](https://docs.pymc.io/en/v4.3.0/_images/pymc-Bernoulli-1.png)"},{"cell_type":"markdown","metadata":{"id":"21931ABBEDF54EF8AC54ADB62E69E4F3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"广义线性模型(Generalized linear model，GLM)的特点：\n\n| 一般线性模型 | 广义线性模型 | \n|---|---|\n| $y \\sim Normal(\\mu,sigma)$ | $y \\sim dist(p)$ |\n| $\\mu = \\alpha + \\beta *x$ | $p = g(\\mu)$|\n\n\n- 首先，GLM 可以将 $y \\sim Normal(\\mu,sigma)$ 扩展为 $y \\sim Bernoulli(p)$ ，使得因变量y服从伯努利分布。\n- 同样，参数 p 可以与自变量联系在一起， $p  = \\alpha + \\beta * x$。\n- 需要注意的是，由于 p 的范围被限定在0到1的，而 $\\alpha + \\beta * x$ 的范围为 $(-\\infty, +\\infty)$。我们需要通过**链接函数g()** 将 $\\alpha + \\beta * x$  映射到 p 所在的范围。\n\n\n"},{"cell_type":"markdown","metadata":{"id":"90DA33F621E14FBF98F3620F1A7003D8","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"链接函数的具体转化过程，以逻辑(logit)回归为例：\n1. 令 $z = \\alpha + \\beta *x$，$\\mu$的范围为 $(-\\infty, +\\infty)$。\n2. $p = g(z)$，其中 g() 为链接函数，输出结果 p 的范围为 $(0,1)$。\n3.  最后将 p 输入到分布函数中 $y \\sim Bernoulli(p)$。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/rloa6zyf5a.png?imageView2/0/w/600/h/600)\n"},{"cell_type":"markdown","metadata":{"id":"85FC3DDC5C004DEAAB54E81C29E9051A","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"637ac5cb53342897d983e412","trusted":true},"source":"### Workflow\n\n在了解GLM的基础知识后，我们通过实际的例子来体验PyMC建模的完整workflow。\n\n![Image Name](https://cdn.kesci.com/upload/image/rkvikqg9q6.png?imageView2/0/w/650/h/650)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6FF8EC3420AA40608BCFA62EF53D10CB","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (1) 提出研究问题\n\nStroop 任务试图探究一致和不一致条件下的认知控制能力。\n\n对于不一致(incongruent)条件的刺激的反应正确率往往低于一致(incongruent)的刺激。\n\n研究问题为：通过广义线性模型(Generalized linear model)检验不同刺激条件下正确率的差异。\n\n![](https://www.researchgate.net/profile/Ata_Akin/publication/281167153/figure/download/fig1/AS:391418049777669@1470332743733/Three-different-stimulus-conditions-in-the-Stroop-task-neutral-congruent-and.png?_sg=ibeklp8QZ2sbyR29ZZxbOgfS--_RjcKP_uVY36qBahzEJlnMLYPxQyzgYT2Au85eDBClhLqol0A)\n\n\n\n图片来源：https://www.researchgate.net/publication/281167153_Similarity_analysis_of_functional_connectivity_with_functional_near-infrared_spectroscopy/figures?lo=1&utm_source=bing&utm_medium=organic"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"67488C0B681C40AF8373C9C410AEF7F8","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (2) 数据收集"},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"id":"8DFB687F35914AFB8C05853D55E5D139","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"WARNING (theano.link.c.cmodule): install mkl with `conda install mkl-service`: No module named 'mkl'\n"}],"source":"#加载需要使用的库\n%matplotlib inline\nimport numpy as np \nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport arviz as az\nimport pymc3 as pm\n\nnp.random.seed(123)  # 随机数种子，确保随后生成的随机数相同"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"3E80F13DCB2F47FD8BC73C286A337EE9","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"这里我们使用的数据来自 Eisenberg et al (2019)。\n\n为了简化问题，我们仅考虑有一个被试的数据。其中：\n- worker_id 为被试编号。\n- correct 为被试在 stroop 任务中每个试次判断的正确性，其中1代表判断正确，0代表判断错误。\n- condition 为刺激的类别，congruent为颜色和字意一致，incongruent为颜色和字意不一致。"},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"id":"C4D9175DA9954AF59A8412AE637998E2","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":true,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"# 加载数据\ndata = pd.read_csv(\"./stroop.csv\")\n# 选取第一个被试在正式实验(test)中的数据\ndata = data[(data.worker_id == \"s001\") & (data.exp_stage == \"test\")]\n# 选取数据中的判断正确率，刺激条件，和被试编号\ndata = data[[\"worker_id\",\"correct\",\"condition\"]]\n# 重置每个试次的编号\ndata.reset_index(inplace=True,drop=True)"},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"id":"563B73EAC81D4F3498872D3E42BBCCE4","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"  worker_id  correct  condition\n0      s001      1.0  congruent\n1      s001      0.0  congruent\n2      s001      1.0  congruent\n3      s001      1.0  congruent\n4      s001      1.0  congruent","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>worker_id</th>\n      <th>correct</th>\n      <th>condition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s001</td>\n      <td>1.0</td>\n      <td>congruent</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s001</td>\n      <td>0.0</td>\n      <td>congruent</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>s001</td>\n      <td>1.0</td>\n      <td>congruent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>s001</td>\n      <td>1.0</td>\n      <td>congruent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>s001</td>\n      <td>1.0</td>\n      <td>congruent</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}],"source":"data.head()"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"17F53A4FAC4F4CCF920B5B6EB4772427","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"对数据进行描述统计分析\n\n可以发现，一致条件下的正确率(M = 0.875)高于不一致条件(M = 0.813)。"},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"id":"86953A7EF773439E8E0ED8670E7D3454","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"             count    mean       std  min  25%  50%  75%  max\ncondition                                                    \ncongruent     48.0  0.8750  0.334219  0.0  1.0  1.0  1.0  1.0\nincongruent   48.0  0.8125  0.394443  0.0  1.0  1.0  1.0  1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>condition</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>congruent</th>\n      <td>48.0</td>\n      <td>0.8750</td>\n      <td>0.334219</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>incongruent</th>\n      <td>48.0</td>\n      <td>0.8125</td>\n      <td>0.394443</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}],"source":"data.groupby('condition').correct.describe() "},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"id":"97741053F5304EC184ED4A6C091FD0CE","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/97741053F5304EC184ED4A6C091FD0CE/rloahfwazw.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"source":"data.groupby(['condition']).correct.mean().plot.bar()\nplt.show()"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"61C5CABC8CA34E878D153FBA69542021","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (3) 选择模型"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"2CBD863320E140559585B352D50434B7","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"在我们的例子中，由于因变量(反应的正确性)不是连续变量，因此预测变量不服从正态分布。\n\n考虑到反应的正确性服从伯努利(Bernoulli)分布，因此我们需要广义线性模型(Generalized linear model，GLM)来扩展一般线性模型：\n- 首先，GLM 可以将 $y \\sim Normal(\\mu,sigma)$ 扩展为 **$y \\sim Bernoulli(p)$** ，使得因变量y服从伯努利分布。\n- 同样，参数 p 可以与自变量联系在一起， $p  = \\alpha + \\beta * x$。\n- 需要注意的是，由于 p 的范围被限定在0到1的，而 $\\alpha + \\beta * x$ 的范围为 $(-\\infty, +\\infty)$。我们需要通过**链接函数** 将 $\\alpha + \\beta * x$  映射到 p 所在的范围。\n\t1. 令 $z = \\alpha + \\beta *x$，$\\mu$的范围为 $(-\\infty, +\\infty)$。\n\t2. $p = g(z)$，其中 g() 为链接函数，输出结果 p 的范围为 $(0,1)$。\n\t3.  最后将 p 输入到分布函数中 $y \\sim Bernoulli(p)$。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"C24612EBE8DE46538C3C68A040CD7B57","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (4)选择先验"},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"id":"93354443BB024809A575978EEC4B3BEC","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"# 将‘condition’进行编码，其中一致条件(congruent)编码为0，不一致条件(incongruent)编码为1。\ndata.condition = data.condition.map({'incongruent':1,'congruent':0})"},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":false,"id":"8E89C676474E4E2AA6E63B19D7FA8B90","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"# 在pymc3中，pm.Model()定义了一个新的模型对象，这个对象是模型中随机变量的容器\n# 在python中，容器是一种数据结构，是用来管理特殊数据的对象\n# with语句定义了一个上下文管理器，以 linear_model 作为上下文，在这个上下文中定义的变量都被添加到这个模型\nwith pm.Model() as GLM_model:\n    # 设定先验分布: \n    alpha = pm.Normal('alpha',mu=0,sd=1)\n    beta = pm.Normal('beta',mu=0,sd=1)\n    # x为自变量，是之前已经载入的数据\n    x = pm.Data(\"x\", data['condition'])\n    # 通过链接函数对参数进行转换\n    z = alpha + beta * x                            # 对应步骤1\n    p = pm.Deterministic(\"p\", pm.math.invlogit(z))  # 对应步骤2\n\n    # 先验预测检查\n    prior_checks = pm.sample_prior_predictive(samples=50)"},{"cell_type":"code","source":"az.plot_density(\n    {'alpha':prior_checks['alpha'],\n    'beta':prior_checks['beta']}\n    )\nplt.show()","metadata":{"id":"DE257BA291E3439195D7598C98314116","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 993.6x331.2 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/DE257BA291E3439195D7598C98314116/rlob1nbrmt.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"execution_count":30},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":false,"id":"47053D46ABF54C6FB352FD0DF7715D11","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":true,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/47053D46ABF54C6FB352FD0DF7715D11/rlob2flmab.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"source":"az.plot_density(\n    {'p':prior_checks['p']}\n    )\nplt.show()"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9092E470D04A4522874E2B45BC5D331E","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"结果发现，通过**链接函数**转换后的p值范围为 0到1。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9DA3B2B9238B492D85420F56F0A3C620","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (5) 拟合数据"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9C52A4B75A854C659F5C852A0827A700","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"首先定义 GLM 模型：\n- 其中 alpha 和 beta 为模型参数，$\\alpha + \\beta * x$。\n- x 为自变量刺激条件(condition), 0代表一致条件，1代表不一致条件。\n- 通过链接函数对参数进行转换。\n    - 首先令 $\\mu = \\alpha + \\beta * x$\n    - 然后通过链接函数 pm.math.invlogit(mu)，计算出 p。\n    注意，这里我们选择 logit 的反函数 invlogit作为链接函数。该链接函数使得 p 的范围为 $(0,1)$。\n-  最后将 p 输入到分布函数中 $y \\sim Bernoulli(p)$。"},{"cell_type":"code","execution_count":32,"metadata":{"collapsed":false,"id":"B68C4B46D79E4244A56E426AE5150851","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"with pm.Model() as GLM_model:\n    # 在pymc3中，pm.Model()定义了一个新的模型对象，这个对象是模型中随机变量的容器\n    # 在python中，容器是一种数据结构，是用来管理特殊数据的对象\n    # with语句定义了一个上下文管理器，以 linear_model 作为上下文，在这个上下文中定义的变量都被添加到这个模型\n    # 定义先验\n    alpha = pm.Normal('alpha',mu=0,sd=1)\n    beta = pm.Normal('beta',mu=0,sd=1)\n    # x为自变量，是之前已经载入的数据\n    x = pm.Data(\"x\", data['condition'])\n    # 线性模型：mu是确定性随机变量，这个变量的值完全由右端值确定\n    z = alpha + beta * x                            # 对应步骤1\n    p = pm.Deterministic(\"p\", pm.math.invlogit(z))  # 对应步骤2\n    # Y的观测值，这是一个特殊的观测随机变量，表示模型数据的可能性。也可以表示模型的似然，通过 observed 参数来告诉这个变量其值是已经被观测到了的，不会被拟合算法改变\n    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=data[\"correct\"])  # 对应步骤3"},{"cell_type":"code","execution_count":33,"metadata":{"collapsed":false,"id":"CD6277FC5DC7480486883408D5BF5845","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"<graphviz.graphs.Digraph at 0x7f9709507e50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/CD6277FC5DC7480486883408D5BF5845/rlob39k09k.svg\">"},"metadata":{},"execution_count":33}],"source":"# 展示模型结构\npm.model_to_graphviz(GLM_model)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"17FD60FD6B324BCC8243C0D5ACF06E01","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"注意：由于应用 GLM 模型时往往都会使用到链接函数，为了减轻使用者的工作量，在 pymc中可以通过设定 将 `pm.Bernoulli(\"y_obs\", p=p)` 的设定改为 `pm.Bernoulli(\"y_obs\", logit_p=p)` 。 完整代码如下："},{"cell_type":"code","execution_count":67,"metadata":{"collapsed":false,"id":"C2828364D1424F968F7DA2E7B21F2CF6","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"with pm.Model() as GLM_model:\n    # 定义先验\n    alpha = pm.Normal('alpha',mu=0,sd=1)\n    beta = pm.Normal('beta',mu=0,sd=1,shape=1)\n    # x为自变量，是之前已经载入的数据\n    x = pm.Data(\"x\", data['condition'])\n    # 线性模型：mu是确定性随机变量，这个变量的值完全由右端值确定\n    p = pm.Deterministic(\"p\", alpha + beta * x)\n    # Y的观测值，这是一个特殊的观测随机变量，表示模型数据的可能性。也可以表示模型的似然，通过 observed 参数来告诉这个变量其值是已经被观测到了的，不会被拟合算法改变\n    y_obs = pm.Bernoulli(\"y_obs\", logit_p=p, observed=data[\"correct\"])"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9DE229BD2025423B85C917275D6C3E63","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (6)采样过程诊断\n\n如果使用MCMC对后验进行近似，则需要首先对MCMC过程进行评估。\n\n* 是否收敛；\n* 是否接近真实的后验。\n\n对采样过程的评估我们会采用目视检查或rhat这个指标"},{"cell_type":"code","execution_count":34,"metadata":{"collapsed":false,"id":"7A0E244EED264490A4DAF144B89CD113","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Auto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [beta, alpha]\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{},"execution_count":null},{"output_type":"stream","name":"stderr","text":"Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 4 seconds.\n"}],"source":"with GLM_model :\n    # 使用mcmc方法进行采样，draws为采样次数，tune为调整采样策略的次数，这些次数将在采样结束后被丢弃，\n    # target_accept为接受率， return_inferencedata=True为该函数返回的对象是arviz.InnferenceData对象\n    # chains为我们采样的链数，cores为我们的调用的cpu数，多个链可以在多个cpu中并行计算，我们在和鲸中调用的cpu数为2\n    trace = pm.sample(draws = 2000, tune=1000, target_accept=0.9,chains=2, cores= 2,return_inferencedata=True)"},{"cell_type":"code","execution_count":35,"metadata":{"collapsed":false,"id":"B1294DE0536547A48E837C06ECEB677D","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x288 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/B1294DE0536547A48E837C06ECEB677D/rlob4fg02t.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"source":"az.plot_trace(trace, var_names=['alpha','beta'])\nplt.show()"},{"cell_type":"code","execution_count":36,"metadata":{"collapsed":false,"id":"9C6692072E1C44D78988AF65F5E5A4ED","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"       mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat\nalpha      0.010    0.007    1319.0    2059.0    1.0\nbeta       0.014    0.010    1262.0    1567.0    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alpha</th>\n      <td>0.010</td>\n      <td>0.007</td>\n      <td>1319.0</td>\n      <td>2059.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <td>0.014</td>\n      <td>0.010</td>\n      <td>1262.0</td>\n      <td>1567.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":36}],"source":"az.summary(trace, var_names=['alpha','beta'], kind=\"diagnostics\")"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"0C5F6A4325D84CF58C46E8E009EB0CA3","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (7)模型诊断\n\n在MCMC有效的前提下，需要继续检验模型是否能够较好地拟合数据。\n\n我们会使用后验预测分布通过我们得到的参数生成一批模拟数据，并将其与真实数据进行对比。"},{"cell_type":"code","execution_count":37,"metadata":{"collapsed":false,"id":"08DBC6B10B134772855BE0F0CF010E27","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{},"execution_count":null},{"output_type":"update_display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [4000/4000 00:03&lt;00:00]\n    </div>\n    "},"metadata":{},"execution_count":null},{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/arviz/data/io_pymc3.py:100: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n  FutureWarning,\n"}],"source":"# 后验预测分布的计算仍在容器中进行\nwith GLM_model:\n    # pm.sample_posterior_predictive()利用trace.posterior的后验分布计算后验预测分布\n    ppc_y = pm.sample_posterior_predictive(trace.posterior) \n#将ppc_y转化为InferenceData对象合并到trace中\naz.concat(trace, az.from_pymc3(posterior_predictive=ppc_y), inplace=True)"},{"cell_type":"code","execution_count":46,"metadata":{"collapsed":false,"id":"B3201FD32B234C05BD6942227CDE422E","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py:151: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  fig.canvas.print_figure(bytes_io, **kw)\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/B3201FD32B234C05BD6942227CDE422E/rlobt2osud.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"source":"# 绘制后验预测分布\naz.plot_ppc(trace)\nplt.show()"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"57BE24124330453D9B958A8CA14CDB48","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (8)模型比较"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9BF407CFF89149FABD2C42487A5E9ADA","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"当采样诊断与模型诊断说明模型是否可用后，我们可以通过模型检验来验证我们的研究问题：在不同刺激条件下(一致 vs. 不一致)个体正确率是否存在差异。\n\n![Image Name](https://cdn.kesci.com/upload/image/rkm3pw954u.png?imageView2/0/w/960/h/960)\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B289863A42C0439B8FDFAF7984F93EBE","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们可以定义一个不考虑自变量影响的模型 `GLM_null_model`。如果之前的模型拟合优度好于该模型，那么说明自变量对模型存在影响。"},{"cell_type":"code","execution_count":47,"metadata":{"collapsed":false,"id":"A56FF3B7614B4F2A84D893C81FE55738","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Auto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [p]\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{},"execution_count":null},{"output_type":"stream","name":"stderr","text":"Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 3 seconds.\n"}],"source":"with pm.Model() as GLM_null_model:\n    # 定义先验\n    p = pm.Uniform('p',0,1)  # 由于没有考虑自变量的影响，因此我们可以直接假设参数p服从0到1的均匀分布。\n    # Y的观测值，这是一个特殊的观测随机变量，表示模型数据的可能性。也可以表示模型的似然，通过 observed 参数来告诉这个变量其值是已经被观测到了的，不会被拟合算法改变\n    y_obs = pm.Bernoulli('y_obs',p=p, observed=data['correct'])\n\n    trace2 = pm.sample(draws = 2000, tune=1000, target_accept=0.9,chains=2, cores= 2,return_inferencedata=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"id":"1BCB182540814DCD87158EA248380C4A","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"############################\n# 练习\n# 要求：完成对 GLM_null_model 的采样过程诊断与模型诊断。\n############################\n\n# 绘制各参数的采样情况\n# Tips: 使用 az.plot_trace() 函数可以绘制 trace 图；使用 az.summary() 可以得到诊断统计结果\n\n\n# 模型诊断\n# Tips: 使用 pm.sample_posterior_predictive 可以进行后验预测检验；使用 az.plot_ppc() 可以得到后验预测检验图\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"A3CA35B7DF7545F38B48D09B27EAFA11","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"当对 GLM_null_model 进行同样的检验，我们可以正式进行模型比较了。"},{"cell_type":"code","execution_count":48,"metadata":{"collapsed":false,"id":"42C27ED05D8F4F698BBC58DE8F6AE318","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/arviz/stats/stats.py:146: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n  \"The default method used to estimate the weights for each model,\"\n"},{"output_type":"execute_result","data":{"text/plain":"                rank        loo     p_loo    d_loo  weight        se  \\\nGLM_null_model     0 -42.553073  0.926593  0.00000     1.0  5.975505   \nGLM_model          1 -43.220963  1.682689  0.66789     0.0  5.831746   \n\n                     dse  warning loo_scale  \nGLM_null_model  0.000000    False       log  \nGLM_model       0.276783    False       log  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>loo</th>\n      <th>p_loo</th>\n      <th>d_loo</th>\n      <th>weight</th>\n      <th>se</th>\n      <th>dse</th>\n      <th>warning</th>\n      <th>loo_scale</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>GLM_null_model</th>\n      <td>0</td>\n      <td>-42.553073</td>\n      <td>0.926593</td>\n      <td>0.00000</td>\n      <td>1.0</td>\n      <td>5.975505</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>log</td>\n    </tr>\n    <tr>\n      <th>GLM_model</th>\n      <td>1</td>\n      <td>-43.220963</td>\n      <td>1.682689</td>\n      <td>0.66789</td>\n      <td>0.0</td>\n      <td>5.831746</td>\n      <td>0.276783</td>\n      <td>False</td>\n      <td>log</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":48}],"source":"# 将三个模型的采样结果进行比较\ncompare_dict = {\"GLM_model\": trace, \"GLM_null_model\": trace2}\n# 选择loo方法进行比较\ncomp = az.compare(compare_dict, ic='loo')\ncomp"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"7F6A2002F94D44FC9B299B76C86EE6B9","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"结果显示，`GLM_null_model` 模型的拟合度好于 `GLM_model`，说明不存在充分的证据表明不同刺激条件会影响个体判断的正确率。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"22001E5F93364FC99A3726712CCB5E5C","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (9)统计推断\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"E18688A7735D4417817B20FF606C1100","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们可以进一步通过统计推断印证模型比较的结果。"},{"cell_type":"code","execution_count":49,"metadata":{"collapsed":false,"id":"A4B5B19F0D7F4C5482D2E420A644384A","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A4B5B19F0D7F4C5482D2E420A644384A/rlobu8htyk.png\">"},"metadata":{"needs_background":"light"},"execution_count":null}],"source":"az.plot_posterior(trace, var_names=['beta'])\nplt.show()"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CB32F6734DE944F4A5CF2F25493FA76C","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"参数 beta 反应了两个条件下正确率的差异。我们可以看到，该参数的后验分布的大部分包括0，说明支持两个条件下正确率存在差异的证据不足。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"DB0B9FC3440A415BBCFBDEBC35F2D830","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们进一步查看两个参数的情况："},{"cell_type":"code","execution_count":50,"metadata":{"collapsed":false,"id":"52EBF0FA633448C4AF5023F0C054A833","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nalpha  1.671  0.359   0.964    2.304      0.010    0.007    1319.0    2059.0   \nbeta  -0.134  0.484  -1.018    0.791      0.014    0.010    1262.0    1567.0   \n\n       r_hat  \nalpha    1.0  \nbeta     1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_3%</th>\n      <th>hdi_97%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alpha</th>\n      <td>1.671</td>\n      <td>0.359</td>\n      <td>0.964</td>\n      <td>2.304</td>\n      <td>0.010</td>\n      <td>0.007</td>\n      <td>1319.0</td>\n      <td>2059.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <td>-0.134</td>\n      <td>0.484</td>\n      <td>-1.018</td>\n      <td>0.791</td>\n      <td>0.014</td>\n      <td>0.010</td>\n      <td>1262.0</td>\n      <td>1567.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":50}],"source":"az.summary(trace, var_names=['alpha','beta'])"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"906A62361E184C67ACBED1A2F780B868","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"结果发现，两个参数值的范围不太“正常”。\n\n还记得 **链接函数**吗？\n- 链接函数 g() 将 $\\alpha + \\beta * x$ 的范围从 $(-\\infty, +\\infty)$ 转换为 (0,1)\n- 同时，其中的参数 $\\alpha$ 和 $\\beta$也被转换了，只不过他们从 (0,1) 转换为  $(-\\infty, +\\infty)$，所以  $\\alpha$ 大于1，并且 $\\beta$小于0。\n- 为了他们转换回来，我们需要使用 logit 函数， $p = \\frac{1}{1+e^θ}$。\n具体代码如下："},{"cell_type":"code","execution_count":51,"metadata":{"collapsed":false,"id":"945E275558AD401C8D5022804D28454E","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"alpha(一致条件) =  0.8416734472582508 \n alpha+beta(不一致条件) =  0.8229926850528553\n"}],"source":"p_congruent = 1 / (1 + np.exp(-trace.posterior[\"alpha\"].mean())).to_pandas()\np_incongruent = 1 / (1 + np.exp(-(trace.posterior[\"beta\"].mean()+trace.posterior[\"alpha\"].mean()))).to_pandas()\nprint(\"alpha(一致条件) = \",p_congruent, \"\\n alpha+beta(不一致条件) = \", p_incongruent)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D380DC53F4574EF2AA46153E16ABE690","jupyter":{},"notebookId":"637ac5cb53342897d983e412","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"转换后可以发现，虽然一致条件的正确率略高于不一致条件，但这个差异并不具有统计学意义。"},{"cell_type":"markdown","source":"值得注意的是，模型预测的正确率与实际数据的正确率存在差异。\n- 对于一致条件刺激，模型预测值为0.842，**低于**实际正确率为0.875。\n- 对于不一致条件刺激，模型预测值为0.823，**高于**实际正确率为0.813。\n- 模型预测两个条件的正确的差为(一致条件-不一致条件) = 0.02，而真实正确率的差异 = 0.06\n\n可见，模型预测的效应更小。这是因为我们设置先验时，认为条件间的差异(即beta参数)服从均值为0，标准差为1的正态分布。","metadata":{"id":"D91860FC2B9945E58E5742106411F8F8","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}},{"cell_type":"code","source":"data.groupby('condition').correct.describe() ","metadata":{"id":"77292BFB277B4735966D9341EE0FC3F8","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"           count    mean       std  min  25%  50%  75%  max\ncondition                                                  \n0           48.0  0.8750  0.334219  0.0  1.0  1.0  1.0  1.0\n1           48.0  0.8125  0.394443  0.0  1.0  1.0  1.0  1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>condition</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48.0</td>\n      <td>0.8750</td>\n      <td>0.334219</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48.0</td>\n      <td>0.8125</td>\n      <td>0.394443</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":54}],"execution_count":54},{"cell_type":"markdown","source":"假如我们存在先验知识，知道不一致条件的正确率低于一致条件，而不是他们可能相等。\n\n我们可以设置一个有信息的先验，比如假设这个差异为 0.6，即 beta = 0.6。\n\n需要注意的是，由于链接函数的存在，我们需要把 beta进行 logit转化，得到转化后的 beta 为 0.41。 \n\n因此，我们假定beta的先验分布服从 均值为 0.4，标准差为0.2的正态分布。使得beta大部分值都大于0 (相对于之前得到的beta = -0.134 < 0)。","metadata":{"id":"8F9A1979E06649BC8452C438854027AB","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}},{"cell_type":"code","source":"p = 0.6\nbeta = np.log(p/(1-p))\nprint(\"转化后的beta:\", beta)","metadata":{"id":"6C2306E24ED74026A1CFFC10A73BD263","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"转化后的beta: 0.4054651081081642\n"}],"execution_count":67},{"cell_type":"code","source":"with pm.Model() as GLM_model2:\n    # 定义先验\n    alpha = pm.Normal('alpha',mu=0,sd=1)\n    beta = pm.Normal('beta',mu=0.4,sd=0.2) # 我们假定beta的先验分布服从 均值为 0.4，标准差为0.2的正态分布\n    # x为自变量，是之前已经载入的数据\n    x = pm.Data(\"x\", data['condition'])\n    # 线性模型：mu是确定性随机变量，这个变量的值完全由右端值确定\n    z = alpha - beta * x                  # 这里使用减号是因为一致条件比不一致条件的正确率高          \n    p = pm.Deterministic(\"p\", pm.math.invlogit(z))  \n    # Y的观测值，这是一个特殊的观测随机变量，表示模型数据的可能性。也可以表示模型的似然，通过 observed 参数来告诉这个变量其值是已经被观测到了的，不会被拟合算法改变\n    y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=data[\"correct\"])  \n    trace3 = pm.sample(draws = 2000, tune=1000, target_accept=0.9,chains=2, cores= 2,return_inferencedata=True)","metadata":{"id":"87D17EF61F9148729A15CE9DC33341E1","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Auto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [beta, alpha]\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{},"execution_count":null},{"output_type":"stream","name":"stderr","text":"Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 5 seconds.\n"}],"execution_count":71},{"cell_type":"code","source":"p_congruent = 1 / (1 + np.exp(-trace3.posterior[\"alpha\"].mean())).to_pandas()\np_incongruent = 1 / (1 + np.exp(-(trace3.posterior[\"beta\"].mean()+trace3.posterior[\"alpha\"].mean()))).to_pandas()\nprint(\"alpha(一致条件) = \",p_congruent, \"\\n alpha+beta(不一致条件) = \", p_incongruent)","metadata":{"id":"6B072E86EC4B45E582C7ABE8B117FCDB","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"alpha(一致条件) =  0.8556328224753735 \n alpha+beta(不一致条件) =  0.8037238492379667\n"}],"execution_count":72},{"cell_type":"markdown","source":"- 上一个模型模型预测两个条件的正确的差(一致条件-不一致条件) = 0.02，而真实正确率的差异 = 0.06。\n- 该模型预测两个条件的正确的差 = 0.05。已经非常接近真实差异。\n\n该结果说明了先验设置对于结果的影响。\n\n感兴趣的同学可以在课后尝试不同的先验设置，并进行相应的的模型诊断、模型比较和统计推断的练习。","metadata":{"id":"A9369665D704438A9CD1C1D82F5AC23A","notebookId":"637ac5cb53342897d983e412","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}