{"cells":[{"cell_type":"markdown","metadata":{"_id":"D85BC855E789432595427C7B09FF56B8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"92CD1AE3449F46E7AD64CC7DBC687AC8","notebookId":"66d83816136d01cc20208d4c"},"source":"# <center>高级心理统计 (Advanced Statistics in Psych Sci) </center>  \n## <center>《贝叶斯统计及其在Python中的实现》 (Bayesian inference with Python) </center>  \n## <center>Instructor： 胡传鹏（博士）(Dr. Hu Chuan-Peng) </center>  \n### <center>南京师范大学心理学院 (School of Psychology, Nanjing Normal University)  </center>"},{"cell_type":"markdown","metadata":{"_id":"4640C4E4AEBB4527879FED3C775E0AA1","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7D2B3466FE33434C80F2AC8D4245B212","notebookId":"66d83816136d01cc20208d4c"},"source":"## Outlines  \n### 1. 为什么要学习本课程 [Why Bayesia inference]  \n### 2. 本课程的内容将是什么 [What is the syllabus]  \n###  3. 如何学好这门课[How can I learn this course well]"},{"cell_type":"markdown","metadata":{"_id":"075CB2AC42B943ED8004E9ED0CC667C9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0A6BA84DB12B4911AC1593844A883E46","notebookId":"66d83816136d01cc20208d4c"},"source":"##  0. 贝叶斯统计课程选课概况  \n- 学生身份  \n\n![Image Name](https://cdn.kesci.com/upload/sjboycorpy.png?imageView2/0/w/960/h/960)  \n\n- 教育程度  \n\n\n![Image Name](https://cdn.kesci.com/upload/sjbp057ve3.png?imageView2/0/w/960/h/960)  \n\n\n- 专业领域  \n\n![Image Name](https://cdn.kesci.com/upload/sjbor7adly.png?imageView2/0/w/960/h/960)  \n  \n\n- 编程经验  \n\n![Image Name](https://cdn.kesci.com/upload/sjbp0nk57u.png?imageView2/0/w/960/h/960)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"D2DD81FC430C4B389FAEE2DAF7282166","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9C4430B160204A82B50A00C81B6EAFE1","notebookId":"66d83816136d01cc20208d4c"},"source":"### <center>总结：贝叶斯统计线上课程吸引了众多高学历在读学生，但学员普遍缺乏编程基础。<center>"},{"cell_type":"markdown","metadata":{"_id":"FD0D865749E74CAE9FAF3BAD6A00592B","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"96832098FFA14472A124F741A4C8568F","notebookId":"66d83816136d01cc20208d4c"},"source":"<center><span style=\"font-size: 72px;\">Part 1: Why Bayesian statistics</span></center>"},{"cell_type":"markdown","metadata":{"_id":"3033C49087B94C218FFFD74D99545485","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"1A6F87B0CE8B4364A61C4BD3D45FB35F","notebookId":"66d83816136d01cc20208d4c"},"source":"<center> <span style=\"font-size: 56px;\">研究人类心理与行为的规律，  \n\t容易吗？  </center>  \n\t"},{"cell_type":"markdown","metadata":{"_id":"BA058676A5124ECD96BE6DAE7985D9C6","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8FF57FB9DE764F908CF5BEBF7F0AEC99","notebookId":"66d83816136d01cc20208d4c"},"source":"##  1.  为什么要学习本课程 (Why Bayesia inference)  \n\n### 1.1  为什么心理学需要更好的方法 (Why does psychological science need better methods?)  \n\n#### 原因1:  人类认知与行为本身的复杂性"},{"cell_type":"markdown","metadata":{"_id":"FAC0D53F106D4092A4F860FEABBF4B24","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3889BC2F95BA415899F250C1030EFE96","notebookId":"66d83816136d01cc20208d4c"},"source":" ![Image Name](https://cdn.kesci.com/upload/image/rhdcyu860w.gif?imageView2/0/w/960/h/960)  \n\nSource: https://www.science.org/toc/science/309/5731"},{"cell_type":"markdown","metadata":{"_id":"912B0A6492BF402FA2EB66B9811338FF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"08A6C46A8C7548B88E19549787864794","notebookId":"66d83816136d01cc20208d4c"},"source":"### **Q1:  What is the Uiverse Made of (physics)**  \n\n### **Q2:  What is the Biological Basis of Consciouness (psychological/cognitive science)**"},{"cell_type":"markdown","metadata":{"_id":"99319ED15324448794E5218653FFF8A6","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3CDD8C902CF844838F6EC133AF5F0278","notebookId":"66d83816136d01cc20208d4c"},"source":"### Q:   重要性和复杂度相似的问题，是否意味着研究方法也应该类似地复杂？"},{"cell_type":"markdown","metadata":{"_id":"DE5BCAE12B1C4B3C98F4FF406C3C68D2","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7B498D6777A040F58D136A7370C19CD5","notebookId":"66d83816136d01cc20208d4c"},"source":"### 物理学中的方法 (Methods in Physics):  \n\n#### Example 1: Webb telescope (韦伯望远镜)  (**equipment**)  \n![Image Name](https://cdn.kesci.com/upload/image/rhdd0r46k3.png?imageView2/0/w/720/h/640)  "},{"cell_type":"markdown","metadata":{"_id":"C2A7F135EF6F4A44B0DAF8921DD11E02","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"94DCF45875D74F5C8C594291479F0C02","notebookId":"66d83816136d01cc20208d4c"},"source":"### Example 2: Big-team science (CERN, the European Organization for Nuclear Research) ---- **equipment & practices**  \n\n### Example 3: **Mathematics**"},{"cell_type":"markdown","metadata":{"_id":"29FF762DCB7149A99442180ECAE19092","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AD3FC69002994E39BE28CBF60204D3DA","notebookId":"66d83816136d01cc20208d4c"},"source":"### 其他研究人类智能的领域所采用的方法 (Methods in other fields that also study \"intelligence\")  \n\n## **AI**  \n\n![Image Name](https://cdn.kesci.com/upload/image/rhdd1sr5y2.png?imageView2/0/w/640/h/640)  \n"},{"cell_type":"markdown","metadata":{"_id":"DCE2B11C74B541EAA68F9D4CFE94B8DF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EF839BDD2BF6494992515AD0B586C1E1","notebookId":"66d83816136d01cc20208d4c"},"source":"### 心理科学的研究方法 [What do psychological scientists have?]  \n##### 你们能够想到的研究方法包括哪些？  \n\n![Image Name](https://cdn.kesci.com/upload/image/rhdd2dgwc8.png?imageView2/0/w/640/h/640)  "},{"cell_type":"markdown","metadata":{"_id":"F838CB5773F6488F96B6BFB711788188","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"17492B425D7F4C368972A8D13B18E05F","notebookId":"66d83816136d01cc20208d4c"},"source":"#### **实证研究：**  \n* 质性研究  \n* 观察法  \n* 问卷  \n* 行为实验  \n* 眼动、生理数据记录  \n* EEG/ERP/MEG  \n* fMRI/PET/fNIRs  \n* TMS/tDCS  \n* ..."},{"cell_type":"markdown","metadata":{"_id":"1CA86845AF4C4D16824FEC8A43E59087","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F1D4D510F66B43F6AAF9286F7CF2CB47","notebookId":"66d83816136d01cc20208d4c"},"source":"#### **统计方法：**  \n* *t*-test  \n* ANOVA  \n* Correlation  \n* Structural equation model (SEM)  \n* ?"},{"cell_type":"markdown","metadata":{"_id":"FAC54F0497D24B1889E6F2813E53B215","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"31255CB36D084CFF9EFC4701C3ECED72","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 相关方法课程：  \n* 心理测量  \n* 心理统计（包括SPSS等）  \n* 实验心理学（包括E-prime等）  \n* ？"},{"cell_type":"markdown","metadata":{"_id":"9910383FCCD24C9994B647B6122EF542","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7067E7986432484F9AFA2101EA833087","notebookId":"66d83816136d01cc20208d4c"},"source":"* 更好的仪器  \n* **更好的统计/数据分析**  \n* 更好的实践 (e.g., big-team science)"},{"cell_type":"markdown","metadata":{"_id":"A61BA5E3CB224EA4A4A8DB9A57481C03","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"D24331DBD37F4F4895DD14AC43BCDBF2","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 原因2: 更复杂的数据  \n\n* 数据字化的时代，大数据  \n* 神经成像/生理数据  \n* 多模态的数据融合"},{"cell_type":"markdown","metadata":{"_id":"C3B54FAA352F4A57AB5B56F123EAA381","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5B2851F7BD3C48B6BF31EB8608B94DE4","notebookId":"66d83816136d01cc20208d4c"},"source":"  ##  <center>1.2 确实有更好的统计方法<center>"},{"cell_type":"markdown","metadata":{"_id":"306E16B7D392467298F24C1204028600","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DADF99D4CFDD4D45BD3297ADBA72A90A","notebookId":"66d83816136d01cc20208d4c"},"source":"### <cenrer>贝叶斯统计 (Bayesian inference) <cenrer>  \n\n\n![Image Name](https://cdn.kesci.com/upload/image/rhdf3bb12c.png?imageView2/0/w/640/h/640)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"F8D30543DCF44C6FADE92B5662CD7F56","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"76F47084C9A641C99AE0709B39834074","notebookId":"66d83816136d01cc20208d4c"},"source":"* 灵活/强大/能用  \n* 易用  \n* 可拓展性强  \n* 方便跨学科交流  \n* ..."},{"cell_type":"markdown","metadata":{"_id":"669F8D33D4C6499EB731DDF9DE231B3B","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6CB5494558464124A9736D5584F9AC94","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 通用/灵活/强大  \n\n* 通用：贝叶斯推断在多个学科特别是AI领域得到了广泛应用。  \n* 灵活：结合先验知识与新数据，灵活调整模型以适应不同数据情境。  \n* 强大：与频率主义学派相比，贝叶斯方法适用范围更广。"},{"cell_type":"markdown","metadata":{"_id":"C0B0D70D355D4D139017EB5673BE3272","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"93857B801CBB4877B06E6A6E7C8F9F97","notebookId":"66d83816136d01cc20208d4c"},"source":"#### （相对）易用  \n\n概率编程语言(Probabilistic Programming Languages)的发展和普及  \n\n\nPPLs: *computational languages for statistical modeling*  \n\n* Python\t \n  * PyMC  \n  * NumPyro   \n* R  \n  * Stan  \n  * JAGS  \n* BUGS  \n* Julia  \n  * Mamba  \n  * Turing.jl  \n* ..."},{"cell_type":"markdown","metadata":{"_id":"69ACCA0E2466404D83FC5D4547EE1878","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0AD66181D27C489D8DBC6E0A509E3398","notebookId":"66d83816136d01cc20208d4c"},"source":"##### 大部分情况下，开发者使用它可以轻松地定义概率模型，然后程序会自动地求解模型。  \n\n\n![Image Name](https://cdn.kesci.com/upload/image/rhdf4r9fbh.png?imageView2/0/w/640/h/640)  \n\n\nSource: https://towardsdatascience.com/intro-to-probabilistic-programming-b47c4e926ec5  \n"},{"cell_type":"markdown","metadata":{"_id":"B161A23285E24745A73EF7BAA9E41C11","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"74F8F0F660264EA2A41D3AEBAFB722BB","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 可拓展  \n\n贝叶斯概念已经应用到以深度学习为中心的新技术的发展，包括深度学习框架(TensorFlow, Pytorch)，创建表示能力更强、数据驱动的模型"},{"cell_type":"markdown","metadata":{"_id":"F416BD04635B4D20AA939E8E1E1931B4","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"127771B671484EFF9980C21DDBE91173","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 方便交流  \n大部分PPLs都有类似的数据结构，但是不同的学科使用的语言不同。  \n\n心理学/社会科学/神经科学：  \n* **PyMC**  (bambi)  \n* Stan (brms)  \n* BUGS"},{"cell_type":"markdown","metadata":{"_id":"1D85B3EAF96A4E8C9E29D6D03512140E","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"2D136AD0ECC846808F3C6B3A0E5AD96A","notebookId":"66d83816136d01cc20208d4c"},"source":"<center><span style=\"font-size: 72px;\">Part 2: Three examples </span></center>"},{"cell_type":"markdown","metadata":{"_id":"77D1FF940B1B44A6906BF868A50C7DD9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AC67C3A6ACF04E848A115D88F496F4C3","notebookId":"66d83816136d01cc20208d4c"},"source":"### 例1：社会关系地位与幸福感的关系  \n\n实例的数据来自[ Many Labs 2 项目](osf.io/uazdm/)中的一个研究。  \n\n该研究探究了社会关系地位对于幸福感的影响 “Sociometric status and well-being”， (Anderson, Kraus, Galinsky, & Keltner, 2012)。  \n\n该数据集包括6905个被试的数据。  \n\n<p style=\"font-size:14px\">参考文献：</p>  \n<p style=\"font-size:14px\">  \nAnderson, C., Kraus, M. W., Galinsky, A. D., & Keltner, D. (2012). The local-ladder effect: Social status and subjective well-being. Psychological Science, 23(7), 764-771. https://doi.org/10.1177/0956797611434537  \n</p>"},{"cell_type":"code","metadata":{"_id":"5C1256C501BC409796C6608C29AECA22","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C3FC1A1DC27D430A93B636773E9E4A24","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"import arviz as az\nfrom scipy.stats import levene\nfrom pingouin import ttest, tost, bayesfactor_ttest\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport xarray as xr\nimport pytensor.tensor as pt\nimport scipy.stats as stats\nimport seaborn as sns\nfrom pytensor.tensor import TensorVariable\nfrom scipy.stats import pearsonr\nimport graphviz\nfrom graphviz import Digraph\n\n# 设置随机种子\nrng = np.random.default_rng(202409)\n\n# 设置APA 7的画图样式\nplt.rcParams.update({\n    'figure.figsize': (4, 3),      # 设置画布大小\n    'font.size': 12,               # 设置字体大小\n    'axes.titlesize': 12,          # 标题字体大小\n    'axes.labelsize': 12,          # 轴标签字体大小\n    'xtick.labelsize': 12,         # x轴刻度字体大小\n    'ytick.labelsize': 12,         # y轴刻度字体大小\n    'lines.linewidth': 1,          # 线宽\n    'axes.linewidth': 1,           # 轴线宽度\n    'axes.edgecolor': 'black',     # 设置轴线颜色为黑色\n    'axes.facecolor': 'white',     # 轴背景颜色（白色）\n    'xtick.direction': 'in',       # x轴刻度线向内\n    'ytick.direction': 'out',    # y轴刻度线向内和向外\n    'xtick.major.size': 6,         # x轴主刻度线长度\n    'ytick.major.size': 6,         # y轴主刻度线长度\n    'xtick.minor.size': 4,         # x轴次刻度线长度（如果启用次刻度线）\n    'ytick.minor.size': 4,         # y轴次刻度线长度（如果启用次刻度线）\n    'xtick.major.width': 1,        # x轴主刻度线宽度\n    'ytick.major.width': 1,        # y轴主刻度线宽度\n    'xtick.minor.width': 0.5,      # x轴次刻度线宽度（如果启用次刻度线）\n    'ytick.minor.width': 0.5,      # y轴次刻度线宽度（如果启用次刻度线）\n    'ytick.labelleft': True,       # y轴标签左侧显示\n    'ytick.labelright': False      # 禁用y轴标签右侧显示\n})","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"_id":"4EE5F2EA1A6247999D4E84748102A4B7","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"16AAF0FC2C0C4C5FBD7B873F9FC348CD","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 导入数据, 注意在和鲸和在自己电脑（本地）时有差异）\ntry:\n  SMS_data = pd.read_csv('/home/mw/input/bayes3797/SMS_Well_being.csv')\nexcept:\n  SMS_data = pd.read_csv('data/SMS_Well_being.csv')\n# 选择需要的列\nSMS_data = SMS_data[['uID','variable','factor','Country']]\n# 查看数据\nSMS_data.head(2)","outputs":[{"output_type":"execute_result","data":{"text/plain":"   uID  variable factor Country\n0    2 -0.366739   High  Brazil\n1    4 -0.917172   High  Brazil","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uID</th>\n      <th>variable</th>\n      <th>factor</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>-0.366739</td>\n      <td>High</td>\n      <td>Brazil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>-0.917172</td>\n      <td>High</td>\n      <td>Brazil</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}],"execution_count":2},{"cell_type":"code","metadata":{"_id":"5BA13DCF386340FD852E287C60A6F34F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BE9D96AF08EE4CFCB7C8163D605646C5","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 把数据分为高低两种社会关系的地位的子数据以便画图与后续分析\nfactor_high = [sorted(SMS_data.query('factor==\"High\"').variable.loc[0:3000])]\nfactor_low = [sorted(SMS_data.query('factor==\"Low\"').variable.loc[0:3000])]","outputs":[],"execution_count":3},{"cell_type":"markdown","metadata":{"_id":"AC7BEA6186BC4F409D04E3FB752557B3","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"96EB26574D5B40518AC6E1436DE6130D","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 通过画图可视化两种社会关系地位对幸福感的影响  \n\n图中横坐标代表高低两种社会关系地位，纵坐标代表了主观幸福感评分。"},{"cell_type":"code","metadata":{"_id":"762C4583317149AF82095D0C79F8080D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8E23D40A124846029E77D81BEDD1CF58","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 定义绘图函数\ndef adjacent_values(vals, q1, q3):\n    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n\n    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n    return lower_adjacent_value, upper_adjacent_value\n\ndef set_axis_style(ax, labels):\n    ax.xaxis.set_tick_params(direction='out')\n    ax.xaxis.set_ticks_position('bottom')\n    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n    ax.set_xlim(0.25, len(labels) + 0.75)\n    ax.set_xlabel('Soceity Status')\n\ndef plot_violin_apa7(data, x_labels, y_label, title=None):\n    \n    fig, ax = plt.subplots(figsize=(6, 4))  # 调整图形大小\n\n    # 创建小提琴图\n    parts = ax.violinplot(data, showmeans=False, showmedians=False, showextrema=False)\n\n    # 设置小提琴图的样式\n    for pc in parts['bodies']:\n        pc.set_facecolor('#D43F3A')\n        pc.set_edgecolor('black')\n        pc.set_alpha(0.8)\n\n    # 计算分位数和须\n    quartile1, medians, quartile3 = np.percentile(data, [25, 50, 75], axis=1)\n    whiskers = np.array([adjacent_values(sorted_array, q1, q3)\n                         for sorted_array, q1, q3 in zip(data, quartile1, quartile3)])\n\n    whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n\n    # 绘制中位数和须\n    inds = np.arange(1, len(medians) + 1)\n    ax.scatter(inds, medians, marker='o', color='white', s=30, zorder=3)\n    ax.vlines(inds, quartile1, quartile3, color='k', linestyle='-', lw=5)\n    ax.vlines(inds, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n\n    # 设置x轴和y轴标签\n    ax.set_xticks(np.arange(1, len(x_labels) + 1))\n    ax.set_xticklabels(x_labels)\n    ax.set_ylabel(y_label)\n\n    # 设置y轴从0开始\n    ax.set_ylim(0, None)\n\n    # 保留左侧和底部的框线，移除右侧和顶部的框线\n    ax.spines['bottom'].set_visible(True)\n    ax.spines['left'].set_visible(True)\n    ax.spines['bottom'].set_linewidth(1)\n    ax.spines['left'].set_linewidth(1)\n\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    # 如果有标题，则设置标题\n    if title:\n        ax.set_title(title, pad=10)\n\n    # 设置x轴风格\n    set_axis_style(ax, x_labels)\n\n    # 图形的显示\n    plt.tight_layout()\n    plt.show()","outputs":[],"execution_count":4},{"cell_type":"code","metadata":{"_id":"804CC5AE1DB040B698285BB9464D853A","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A105B16EA7BE491B96B8B2A2AF884612","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 示例数据和函数调用\nplot_data = [np.random.normal(70, 10, 100), np.random.normal(60, 15, 100)]\nplot_violin_apa7(plot_data, ['Low', 'High'], 'Well-being',\n                 'The impact of social status on well-being')\n","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A105B16EA7BE491B96B8B2A2AF884612/sjbpobjnhb.png\">"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","metadata":{"_id":"0E4F624CE40C4DB3BB3490D5D1E53E2D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"491C6E58B2C74EC5BC05EBCF8352B0BB","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 通过*t*检验，分析两种社会关系地位下幸福感的差异  "},{"cell_type":"code","metadata":{"_id":"D16D2D87A81E49BDB5D3A951754CAFB1","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"414AFC72EA304D8B84AB76B1D0D7AF43","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# levene检验\nlevene_stat, levene_p = levene(SMS_data['variable'][SMS_data['factor'] == 'High'], \n                               SMS_data['variable'][SMS_data['factor'] == 'Low'])\nprint(f'Levene Test p-value: {levene_p}')","outputs":[{"output_type":"stream","name":"stdout","text":"Levene Test p-value: 0.1560218938980748\n"}],"execution_count":6},{"cell_type":"markdown","metadata":{"_id":"F9426A5C3FC84F19BA37A358661E17BF","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"B6719A2E9C0E48C49CE0F2A1D1B17CE4","notebookId":"66d83816136d01cc20208d4c"},"source":"根据独立样本*t*检验结果，低社会地位组（*M* = 0.014, *SD* = 0.66）和高社会地位组（*M* = -0.014, *SD* = 0.67）之间的差异在统计学上不显著，*t* = 1.76, *p* = 0.079。  \n\n这意味着我们无法在传统显著性水平（α = 0.05）下拒绝原假设($H_0$)。因此高社会地位和低社会地位下的幸福感差异在统计学上不是显著的。"},{"cell_type":"code","metadata":{"_id":"C2C1396F28194EAD8589EDE161E46174","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"92379E86F63943B296536AC852716200","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"SMS_low = SMS_data.query('factor==\"Low\"').variable.values\nSMS_high = SMS_data.query('factor==\"High\"').variable.values\nprint(\n    f\"Low Social Status：{np.around(np.mean(SMS_low),3)} ± {np.around(np.std(SMS_low),2)}；\",\n    f\"High Social Status：{np.around(np.mean(SMS_high),3)} ± {np.around(np.std(SMS_high),2)}\")\n\n# 进行独立样本t检验  \nresults = stats.ttest_ind(\n    a= SMS_low,\n    b= SMS_high, \n    equal_var=True)\nprint(f\"t={round(results[0],2)}, p={round(results[1],3)}\")","outputs":[{"output_type":"stream","name":"stdout","text":"Low Social Status：0.014 ± 0.66； High Social Status：-0.014 ± 0.67\nt=1.76, p=0.079\n"}],"execution_count":7},{"cell_type":"markdown","metadata":{"_id":"18824ECAB2A24E759487D16DB03226A2","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F22A6BC493AE45499A75AFBE20CB0A1F","notebookId":"66d83816136d01cc20208d4c"},"source":"TOST检验是一种常用于等效性检验的方法，其目的是评估两个组之间的差异是否可以被视为“等效”。在该方法中，等效性被定义为组间差异位于预先设定的“等效边界”范围内。如果组间的差异落在这一范围内，则可以认为这两个组在统计上是等效的。  \n\n等效边界设定为0.2（bound=0.2），意味着如果两个组之间的差异不超过0.2，就可以认为它们是等效的。  \n\n因此，检验得出的*p*值（2.265256e-27）可以表明有非常强的证据表明这两个组之间的差异在等效边界之内。"},{"cell_type":"code","metadata":{"_id":"A9B8CB4C634044A381F23B4BC806A073","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DC16CB5BFB484283A4273CD500401BC7","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 双单侧检验（Two one-side test, TOST）\ntost_res = tost(x=SMS_data['variable'][SMS_data['factor'] == 'High'], \n                y=SMS_data['variable'][SMS_data['factor'] == 'Low'], \n                bound=0.20, paired=False) # 将等效边界值设为0.2\nprint(tost_res)","outputs":[{"output_type":"stream","name":"stdout","text":"      bound   dof          pval\nTOST    0.2  6903  2.265256e-27\n"}],"execution_count":8},{"cell_type":"markdown","metadata":{"_id":"1103A67F66D840839B710FA872CE3DB9","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C9BF44542134436E96851ABA96606F4B","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 通过贝叶斯因子替代*t*检验  \n传统的零假设显著性检验（Null hypothesis significance test, NHST）的框架之下，*t*检验只提供了一个二分的结果：拒绝或者无法拒绝$H_0$。 但 ***p* = 0.079**这样的结果无法支持$H_0$。而贝叶斯因子（Bayes Factor, BF）方法可以提供一种更直观和渐进的方式来评估数据支持原假设（无效假设，$H_0$）还是备择假设($H_1$)。 "},{"cell_type":"code","metadata":{"_id":"8FE84B2C458C4B5B90FDB92538CA182C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CB1887F8E9014ACFB931B45C3A53806D","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 贝叶斯因子\n## 比较高低社会关系地位的社会关系的效应\nttest_res = ttest(SMS_data['variable'][SMS_data['factor'] == 'High'], \n                     SMS_data['variable'][SMS_data['factor'] == 'Low'], \n                     paired=False)\n\n## 计算贝叶斯因子\nt_value = ttest_res['T'].values[0] # 提取t值\ndof = ttest_res['dof'].values[0] # 提取自由度\n\n# 计算‘High’组和‘Low’组的样本量大小\nsample_size_high = len(SMS_data['variable'][SMS_data['factor'] == 'High'])\nsample_size_low = len(SMS_data['variable'][SMS_data['factor'] == 'Low'])\n\n# 使用默认的r值= 0.707\nBF_sms = bayesfactor_ttest(t_value, nx=sample_size_high, ny=sample_size_low, paired=False, r=0.707)\n\n# 输出贝叶斯因子\nprint(BF_sms)","outputs":[{"output_type":"stream","name":"stdout","text":"0.12703440686826656\n"}],"execution_count":9},{"cell_type":"markdown","metadata":{"_id":"55E5190C30F446F0B55F5E875020D610","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0241D6005A2842D392CF7FC21BCBD703","notebookId":"66d83816136d01cc20208d4c"},"source":"贝叶斯因子为$BF_{10}$ = 0.127表明，对于当前数据支持零假设$H_0$ ，说明高低社会关系地位组之间的社会关系效应没有显著差异。  \n\n贝叶斯因子（Bayes Factor，$BF$）  \n\n| 贝叶斯因子，$BF_{01}$ | 解释标准                      |  \n|-----------------------------|-------------------------------|  \n| > 100                        | 极强的证据支持$H_0$    |  \n| 30 ~ 100                     | 非常强的证据支持$H_0$ |  \n| 10 ~ 30                      | 较强的证据支持$H_0$    |  \n| 3 ~ 10                       | 中等程度的证据支持$H_0$ |  \n| 1 ~ 3                        | 较弱的证据支持$H_0$    |  \n| 1                            | 没有证据                      |  \n| 1/3 ~ 1                      | 较弱的证据支持$H_1$    |  \n| 1/10 ~ 1/3                   | 中等程度的证据支持$H_1$|  \n| 1/30 ~ 1/10                  | 较强的证据支持$H_1$    |  \n| 1/100 ~ 1/30                 | 非常强的证据支持$H_1$  |  \n| < 1/100                      | 极强的证据支持$H_1$    |  \n\n<p style=\"font-size:14px\">参考文献：</p>  \n\n<p style=\"font-size:14px\">  \n胡传鹏, 孔祥祯, Wagenmakers, E.-J., Ly, A., 彭凯平 (2018). 贝叶斯因子及其在JASP中的实现. 心理科学进展, 26(6), 951-965.  \n</p>  \n\n<p style=\"font-size:14px\">  \nWagenmakers, E.-J., & Brown, S. (2007). On the linear relation between the mean and the standard deviation of a response time distribution. Psychological Review, 114(3), 830-841. https://doi.org/10.1037/0033-295X.114.3.830  \n</p>"},{"cell_type":"code","metadata":{"_id":"EFE1850A76A14F37971A95312126C7CC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A0C5D5116649486481073CC5AD8C457F","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 敏感性分析\n# Cauchy (0, 1)\nBF_sms_1 = bayesfactor_ttest(t_value, nx=sample_size_high, ny=sample_size_low, paired=False, r=1)\nprint(BF_sms_1)","outputs":[{"output_type":"stream","name":"stdout","text":"0.09002474489275247\n"}],"execution_count":10},{"cell_type":"markdown","metadata":{"_id":"BC5DA70AA49649B7BC64601C7DF85FB6","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A83A7E640EDF43F9A9A7180DEF5D6BB6","notebookId":"66d83816136d01cc20208d4c"},"source":"### 贝叶斯推断  \n\n\n这个模型是怎么来的呢？  \n\n一个简单的线性模型：  \n\n1. 通过建立线性模型去替代原本的*t*检验模型。  \n\n2. 通过PyMC对后验进行采样  \n\n3. 通过Arviz对结果进行展示，辅助统计推断"},{"cell_type":"code","metadata":{"_id":"4017E1984B114D6086856850743F45AC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9B93C356B97C4DFBA43E22CC0CD4D7C3","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 通过pymc建立基于贝叶斯的线性模型\nx = pd.factorize(SMS_data.factor)[0] # high为0，low为1\n# 设置beta1的先验分布的尺度参数，与r=0.707相匹配\nbeta1_scale = 0.707\n\n# 建立模型\nwith pm.Model() as linear_regression:\n    sigma = pm.HalfCauchy(\"sigma\", beta=2)\n    beta0 = pm.Normal(\"beta0\", 0, sigma=5)\n    beta1 = pm.Normal(\"beta1\", 0, sigma=beta1_scale)\n    # beta1 = pm.StudentT(\"beta1\", nu=1, mu=0, sigma=beta1_scale)  # 使用 StudentT 分布接近 Cauchy 分布\n    # beta1 = pm.Cauchy(\"beta1\", alpha=0, beta=beta1_scale)  # 使用 Cauchy 分布，参数 beta 与 r 值对应\n    x = pm.Data(\"x\", x)\n    mu = pm.Deterministic(\"μ\", beta0 + beta1 * x)\n    pm.Normal(\"y\", mu=mu, sigma=sigma, observed=SMS_data.variable)","outputs":[],"execution_count":11},{"cell_type":"markdown","metadata":{"_id":"DDFFB18034DC472A846A51B5F59ED2FE","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"9982BD5D3A004A5981FD2C3E7706B9DB","notebookId":"66d83816136d01cc20208d4c"},"source":"可以通过pymc自带的可视化工具将模型关系可视化。  \n\nx 为自变量，其中1为低社会关系，0为高社会关系。  \n\n参数 $\\beta0$ 是线性模型的截距，而 $\\beta1$ 是斜率。  \n\n截距代表了高社会关系地位被试的幸福感；而截距加上斜率表示低社会关系地位被试的幸福感。  \n\n参数$sigma$是残差，因变量$y$即主观幸福感。  \n\n模型图展示了各参数通过怎样的关系影响到因变量。"},{"cell_type":"code","metadata":{"_id":"0A4840BCE552439298319244586F76D7","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A518B086592A43B39C72054F3A21A2F8","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"pm.model_to_graphviz(linear_regression)","outputs":[{"output_type":"execute_result","data":{"text/plain":"<graphviz.graphs.Digraph at 0x7f505cb35900>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A518B086592A43B39C72054F3A21A2F8/sjbpoct18o.svg\">"},"metadata":{},"execution_count":12}],"execution_count":12},{"cell_type":"markdown","metadata":{"_id":"FCD7ACD235B44D70BA0F78A072962F06","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EABC448F80C7472A889C4D21B262FE99","notebookId":"66d83816136d01cc20208d4c"},"source":"Pymc 贝叶斯模型结合 Arviz 计算得到的贝叶斯因子结果(基于 Savage-Dickey 方法)与贝叶斯Ttest结果接近。"},{"cell_type":"code","metadata":{"_id":"688C93C32E184403AA0C998CD5EB05AA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0D8B31FCE62D4C4990E458097A1AC127","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 模型拟合过程 (mcmc采样过程)\nwith linear_regression:\n    # 先验采样\n    prior_checks = pm.sample_prior_predictive(samples=5000)\n    # 后验采样\n    idata = pm.sample(2000, tune=1000, target_accept=0.9, return_inferencedata=True)\n    # 将先验采样的结果合并到推断数据中\n    idata.extend(pm.sample_prior_predictive(samples=500, model=linear_regression))","outputs":[{"output_type":"display_data","data":{"text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:09\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:09</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 10 seconds.\nSampling: [beta0, beta1, sigma, y]\n"}],"execution_count":13},{"cell_type":"code","metadata":{"_id":"021E8B7B437649F9850AF9021DDF4F9D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4EEC141C4FDC40419B5F46E1685E1051","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"fig, axs = plt.subplots(1, 2, figsize=(6, 3))\naz.plot_posterior(prior_checks.prior[\"beta1\"], ax=axs[0])\naxs[0].set_title(\"Prior\")\naz.plot_posterior(idata.posterior[\"beta1\"], ax=axs[1], color=\"C1\")\naxs[1].set_title(\"Posterior\")\nplt.show()","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x300 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/4EEC141C4FDC40419B5F46E1685E1051/sjbppjez88.png\">"},"metadata":{}}],"execution_count":14},{"cell_type":"code","metadata":{"_id":"04575357E27546DDA7A564500B54F66F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E6CC757F84054281852CBA381F18FB80","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"print(f\"The Bayes T-test is {BF_sms}\")\nax = az.plot_bf(idata, var_name=\"beta1\", ref_val=0)\nax[1].set_xlim(-0.5, 0.5)\nax[1].set_xlabel(\"beta1 \\n(represents the difference \\nbetween two groups)\")\nplt.show()","outputs":[{"output_type":"stream","name":"stdout","text":"The Bayes T-test is 0.12703440686826656\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x300 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/E6CC757F84054281852CBA381F18FB80/sjbppjw1ey.png\">"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","metadata":{"_id":"8A4DA6B6116747209FC9F9B51A2BD17B","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FBFAE5DC7148471C8C3FD32B200E0330","notebookId":"66d83816136d01cc20208d4c"},"source":"### 例2 贝叶斯分层模型（Hierarchical Model） 可以更准确地估计信度  \n\n在前面的内容中，我们通过社会关系地位（高与低）对幸福感的影响进行了可视化，并使用贝叶斯因子和贝叶斯推断对模型进行了进一步的分析。然而，现实世界的数据往往存在分层结构（例如，数据可能来自不同的群体、地区、时间段等），这些层次结构可以对我们感兴趣的效应（如社会关系地位对幸福感的影响）产生影响。  "},{"cell_type":"markdown","metadata":{"_id":"F78D9DACDCB248E4ADF15547C700E625","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0A1716A9AFA74D4CB9F09FCD7BD80192","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 分层模型（Hierarchical Model）：  \n可以自然地扩展我们之前的模型，以捕捉数据中的这种分层结构，从而提供更精细、更具解释力的分析。  \n\n例2的数据来源于Haines (2020)的论文（ https://osf.io/preprints/psyarxiv/xr7y3 ）。  \n\n<p style=\"font-size:14px\">参考文献：</p>  \n<p style=\"font-size:14px\">  \nHaines, N., Kvam, P. D., Irving, L. H., Smith, C., Beauchaine, T. P., Pitt, M., & Turner, B. (2020, August 24). Theoretically informed generative models can advance the psychological and brain sciences: Lessons from the reliability paradox. PsyArXiv. https://doi.org/10.31234/osf.io/xr7y3  \n</p>"},{"cell_type":"markdown","metadata":{"_id":"ECCB95F3C9F840748FF213D14DE3BB96","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4F37C9B333A144BEA69A63EE86CC288D","notebookId":"66d83816136d01cc20208d4c"},"source":"例2数据集包括Flanker任务中的反应时间（RT）和正确率数据。Flanker任务要求被试对中央箭头的方向作出反应，同时忽略周围的干扰箭头。  \n\n\t•\t反应时间 (RT)：以秒为单位，记录每次试验的反应时间。  \n\t•\t正确率 (Correct)：记录被试反应是否正确。  \n\t•\t条件 (Condition)：任务分为一致性和不一致性试验，箭头方向是否一致会影响被试的反应时间。  \n\t•\t试验和区块：任务分为多个区块，每个区块包含一系列试验。  \n\n<div style=\"text-align: center;\">  \n    <img src=\"https://tse1-mm.cn.bing.net/th/id/OIP-C.mWWpZdVKA6TlyCuwQlnQSQHaEs?rs=1&pid=ImgDetMain\" alt=\"Flanker Example\" width=\"640\" height=\"640\">  \n    <p style=\"font-size:12px\">(Kim et al., 2022)</p>  \n</div>"},{"cell_type":"code","metadata":{"_id":"B6503B693D104C6AAEF591D8F564F3AE","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"FA24B3321FA54A6EABEE57D80A5A32F4","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 导入例2数据\ntry:\n  df_flanker = pd.read_csv('/home/mw/input/bayes3797/flanker_1.csv')\nexcept:\n  df_flanker = pd.read_csv('data/flanker_1.csv')\n\n# 分层模型数据预处理\ndf_model = df_flanker.copy()\ndf_model = df_model[(df_model.RT > 0) & (df_model.Condition != 1)].reset_index(drop=True)\n# 将条件进行重新编码，1为不一致，0为一致\ndf_model[\"Condition\"] = np.where(df_model[\"Condition\"] == 2, 1,df_model[\"Condition\"])\n# 将时间变量进行重新编码\ndf_model[\"Time\"].replace(1, 0, inplace=True)\ndf_model[\"Time\"].replace(2, 1, inplace=True)\n# 生成所有试次的索引\ndf_model[\"trial_idx\"] = range(len(df_model))\n# 重新编码被试编号\ndf_model['subj_num'] = df_model['subj_num'] - 1\n# 每个被试不同时间rt的最小值\nrt_min = df_model.groupby(['subj_num','Time']).RT.min().unstack().to_numpy()","outputs":[],"execution_count":16},{"cell_type":"code","metadata":{"_id":"78877C0A46034BA086465076C105A9D8","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CDABAD208A5E4DC98EC8C1B4D94007D4","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"df_model.head()","outputs":[{"output_type":"execute_result","data":{"text/plain":"   Block  Trial  Arrow  Condition  Correct       RT  subj_num  Time     Task  \\\n0      1      1      2          0        1  3.07760         0     0  Flanker   \n1      1      2      1          0        1  0.76228         0     0  Flanker   \n2      1      3      1          1        1  2.65480         0     0  Flanker   \n3      1      4      2          1        1  0.68876         0     0  Flanker   \n4      1      5      1          1        1  0.47930         0     0  Flanker   \n\n   trial_idx  \n0          0  \n1          1  \n2          2  \n3          3  \n4          4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Block</th>\n      <th>Trial</th>\n      <th>Arrow</th>\n      <th>Condition</th>\n      <th>Correct</th>\n      <th>RT</th>\n      <th>subj_num</th>\n      <th>Time</th>\n      <th>Task</th>\n      <th>trial_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.07760</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Flanker</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.76228</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Flanker</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.65480</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Flanker</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.68876</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Flanker</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.47930</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Flanker</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":17}],"execution_count":17},{"cell_type":"markdown","metadata":{"_id":"A764509A25F4488FA394CE17DC63E400","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7C1D07971BA4430386D6CC6A3A1E7858","notebookId":"66d83816136d01cc20208d4c"},"source":"##  <center>Two-stage model <center>"},{"cell_type":"code","metadata":{"_id":"38E6D06877BD44AD88D7D1E6B640FCA0","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CEBF22C74DC0416D94B6A440F4CEE29C","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# two-stage model 数据预处理\n\ndf_trad = df_flanker.copy()\n# 选择反应时大于0且条件不为1\ndf_trad = df_trad[(df_trad.RT > 0) & (df_trad.Condition != 1)].reset_index(drop=True)\n# 将条件进行重新编码，2为不一致，0为一致\ndf_trad[\"Condition\"] = df_trad[\"Condition\"].replace({2: 'incon', 0: 'con'})\n# 将时间变量进行重新编码\ndf_trad[\"Time\"] = df_trad[\"Time\"].replace({1: 't1', 2: 't2'})\n# 根据条件分组\ndf_trad = df_trad.groupby(['subj_num','Condition','Time'])['RT'].agg(['mean','std']).reset_index()\n# 将需要做相关的转成长数据\ndf_trad= df_trad.pivot(index='subj_num',columns=['Condition','Time'],values=['mean','std']).reset_index()\ndf_trad.columns = [\n    'subj_num' if col1 == 'subj_num' else f'{col1}_{col2}_{col3}' \n    for col1, col2, col3 in df_trad.columns]\n# 关注平均值、标准差的差值\ndf_trad['mean_contrast_t1'] = df_trad['mean_con_t1'] - df_trad['mean_incon_t1']\ndf_trad['mean_contrast_t2'] = df_trad['mean_con_t2'] - df_trad['mean_incon_t2']\ndf_trad['sd_contrast_t1'] = df_trad['std_con_t1'] - df_trad['std_incon_t1']\ndf_trad['sd_contrast_t2'] = df_trad['std_con_t2'] - df_trad['std_incon_t2']\ndf_trad = df_trad[['subj_num','mean_contrast_t1','mean_contrast_t2','sd_contrast_t1','sd_contrast_t2']]","outputs":[],"execution_count":18},{"cell_type":"code","metadata":{"_id":"C4FB6F50019F4719A3CA5DBE72C5BEB3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"60ACFC9C97A543B6A29961D0BF55C53E","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 经过数据预处理后，定义函数，计算time 1和time 2数据的皮尔逊相关系数\ndef pearson_df(method, var, col1, col2): # 定义函数，用于计算皮尔逊相关系数\n    contrast_cor = pearsonr(col1, col2) # 计算皮尔逊相关系数\n    contrast_coef = contrast_cor[0]\n    ci_low, ci_high = contrast_cor.confidence_interval(confidence_level=0.95) # 计算置信区间\n    \n    # 创建结果数据框\n    result_df = pd.DataFrame({\n        'mean': [contrast_coef],\n        'hdi_2.5%': [ci_low],\n        'hdi_97.5%': [ci_high]},\n        index = [['Two-Stage'],\n                [f'{method}_{var}']])\n\n    return result_df","outputs":[],"execution_count":19},{"cell_type":"code","metadata":{"_id":"5F978789F40C4F09BA99E7AD27AD2935","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"59B78A26653B4254AD221B958C36EEB9","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"trad_mu = pearson_df(method = \"trad\",  \n           var = \"mean\", # 均值\n           col1 = df_trad['mean_contrast_t1'], \n           col2 = df_trad['mean_contrast_t2']) # 两个时间点的均值对比\n\ntrad_sigma = pearson_df(method = \"trad\", # 传统方法\n           var = \"sd\", \n           col1 = df_trad['sd_contrast_t1'], \n           col2 = df_trad['sd_contrast_t2'])\n# 合并结果\ntrad_result = pd.concat([trad_mu, trad_sigma]) \ntrad_result = trad_result.reset_index() # 重置索引\ntrad_result[\"level_1\"] = trad_result[\"level_1\"].replace({'trad_mean': 'mu', 'trad_sd': 'sigma'}) # 重命名列名\nprint(trad_result)","outputs":[{"output_type":"stream","name":"stdout","text":"     level_0 level_1      mean  hdi_2.5%  hdi_97.5%\n0  Two-Stage      mu  0.317663  0.033557   0.554268\n1  Two-Stage   sigma -0.024678 -0.309650   0.264363\n"}],"execution_count":20},{"cell_type":"markdown","metadata":{"_id":"1E3DB8ADE3CC4E6EB0FE777C7D09BD25","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F484FE8FD5674CC39409F60F27B7D6B1","notebookId":"66d83816136d01cc20208d4c"},"source":"### <center>贝叶斯分层模型（Hierarchical Model）<center>  \n###  <center>Shifted Lognormal model <center>"},{"cell_type":"code","metadata":{"_id":"A40CC82F650149A98233B100312A0277","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3CCD335481474B4F8C111AFF0FA05040","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"def logshift_model(data):\n    def shifted_lognormal(mu, sigma, loc, size=None):\n        return loc + pm.LogNormal.dist(mu=mu, sigma=sigma, size=size)\n\n    coords = {\"cond\": data['Condition'].unique(),\n            \"time\": data['Time'].unique(),\n            \"subj\": data['subj_num'].unique(),\n            \"trial\": data['trial_idx']}\n\n\n    with pm.Model(coords=coords) as model:\n\n        rho_R_mu = pm.LKJCorr('rho_R_mu', n=2, eta=1)\n        rho_R_sigma = pm.LKJCorr('rho_R_sigma', n=2, eta=1)\n\n        ######\n        triu_idx = np.triu_indices(2, k=1)\n        mu_corr_upper = pt.set_subtensor(pt.zeros((2, 2))[triu_idx], rho_R_mu)\n        sigma_corr_upper = pt.set_subtensor(pt.zeros((2, 2))[triu_idx], rho_R_sigma)\n        R_mu = pt.eye(2) + mu_corr_upper + mu_corr_upper.T\n        R_sigma = pt.eye(2) + sigma_corr_upper + sigma_corr_upper.T\n        L_R_mu = pt.linalg.cholesky(R_mu)\n        L_R_sigma = pt.linalg.cholesky(R_sigma)\n\n        #####\n\n        # Group-level parameter means\n        mu_mean_base = pm.Normal('mu_mean_base',mu=0, sigma=1, dims=\"time\")\n        mu_sd_base = pm.HalfNormal('mu_sd_base', sigma=1, dims=\"time\")\n\n        \n        sigma_mean_base = pm.Normal('sigma_mean_base', mu=0, sigma=1, dims=\"time\")\n        sigma_sd_base = pm.HalfNormal('sigma_sd_base', sigma=1, dims=\"time\")\n\n        mu_mean_delta = pm.Normal('mu_mean_delta', mu=0, sigma=1, dims=\"time\")\n        mu_sd_delta = pm.HalfNormal('mu_sd_delta', sigma=1, dims=\"time\") #/*\n\n        sigma_mean_delta = pm.Normal('sigma_mean_delta', mu=0, sigma=1, dims=\"time\")\n        sigma_sd_delta = pm.HalfNormal('sigma_sd_delta', sigma=1, dims=\"time\") #/*\n\n        ndt_mean = pm.Normal('ndt_mean', mu=0, sigma=1, dims=\"time\")\n        ndt_sigma = pm.Normal('ndt_sigma', mu=0, sigma=1, dims=\"time\")\n\n        # to make diagnol matrix/ can multiply with L_R_mu/L_R_sigma\n        mu_sd_delta_re = pt.diag(mu_sd_delta)\n        sigma_sd_delta_re = pt.diag(sigma_sd_delta)\n        L_S_mu =  pm.Deterministic(\"L_S_mu\",pt.dot(mu_sd_delta_re,L_R_mu))\n        L_S_sigma = pm.Deterministic(\"L_S_sigma\", pt.dot(sigma_sd_delta_re, L_R_sigma))\n        \n        # individual-level parameters/congruent\n        mu_i_base_pr = pm.Normal('mu_i_base_pr', mu=0, sigma=1, dims=[\"subj\",\"time\"])\n        sigma_i_base_pr = pm.Normal(\"sigma_i_base_pr\", mu=0, sigma=1, dims=[\"subj\",\"time\"])\n        # individual-level parameters/incongruent\n        mu_i_delta_pr = pm.Normal(\"mu_i_delta_pr\", mu=0, sigma=1, dims=[\"time\",\"subj\"])\n        sigma_i_delta_pr = pm.Normal(\"sigma_i_delta_pr\", mu=0, sigma=1, dims=[\"time\",\"subj\"])\n\n        ndt_i_pr = pm.Normal('ndt_i_pr', mu=0, sigma=1, dims=[\"subj\",\"time\"])\n        rv = pm.Normal.dist(0,1)\n        phi = pm.logcdf(rv,ndt_mean+ndt_sigma*ndt_i_pr)\n        phi = pm.math.exp(phi)\n        ndt_i = pm.Deterministic('ndt_i', phi*rt_min, dims=[\"subj\",\"time\"])\n\n    \n        # 得到公式2的后半部分\n        mu_i_delta_tilde = pm.Deterministic(\"mu_i_delta_tilde\", pt.dot(L_S_mu, mu_i_delta_pr))\n        sigma_i_delta_tilde = pm.Deterministic(\"sigma_i_delta_tilde\", pt.dot(L_S_sigma, sigma_i_delta_pr))\n\n        #----------------------------\n        \n        # mu congruent\n        mu_i_base = pm.Deterministic(\"mu_i_base\", mu_mean_base + mu_sd_base*mu_i_base_pr,dims=[\"subj\",\"time\"])\n        # sigma congruent\n        sigma_i_base = pm.Deterministic(\"sigma_i_base\", sigma_mean_base + sigma_sd_base*sigma_i_base_pr,dims=[\"subj\",\"time\"])\n        # congruent effect\n        mu_i_effect = pm.Deterministic(\"mu_i_effect\", mu_mean_delta + mu_i_delta_tilde.T,dims=[\"subj\",\"time\"])\n        # sigma incongruent\n        sigma_i_effect = pm.Deterministic(\"sigma_i_effect\", sigma_mean_delta + sigma_i_delta_tilde.T,dims=[\"subj\",\"time\"])\n        # mu incongruent\n        mu_i_incon = pm.Deterministic(\"mu_i_incon\", mu_i_base + mu_i_effect,dims=[\"subj\",\"time\"])\n        # sigma incongruent\n        sigma_i_incon = pm.Deterministic(\"sigma_i_incon\", sigma_i_base + sigma_i_effect,dims=[\"subj\",\"time\"])\n\n        mu = pm.Deterministic(\"mu\",pm.math.stack([mu_i_base,mu_i_incon]), dims=[\"cond\",\"subj\",\"time\"])\n        sigma_stack = pm.Deterministic(\"sigma_stack\",pm.math.stack([sigma_i_base,sigma_i_incon]),dims=[\"cond\",\"subj\",\"time\"])\n        sigma = pm.Deterministic(\"sigma\", pm.math.exp(sigma_stack), dims=[\"cond\",\"subj\",\"time\"])\n\n        time_idx = pm.MutableData(\"time_idx\",data.Time, dims=\"trial\")\n        subj_idx = pm.MutableData(\"subj_idx\",data.subj_num, dims=\"trial\")\n        cond_idx = pm.MutableData(\"cond_idx\",data.Condition, dims=\"trial\")\n\n        likelihood = pm.CustomDist(\"likelihood\",\n                    mu[cond_idx, subj_idx, time_idx], \n                    sigma[cond_idx, subj_idx, time_idx],\n                    ndt_i[subj_idx, time_idx],\n                    dist = shifted_lognormal,\n                    observed=data.RT,\n                    dims=\"trial\")\n                                    \n        # pred = pm.Deterministic(\"pred\", likelihood + ndt_i[subj_idx, time_idx], dims=\"trial\")\n\n    return model","outputs":[],"execution_count":21},{"cell_type":"code","metadata":{"_id":"29C656B901C342B0B453FF59D86ED6FA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"4147A1E9161E46C4B28E07DDED2E0C51","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 根据不同的方法选择不同的模型\ndef process_model(data, distribution):\n    if distribution == 'log_shift':\n        return logshift_model(data)","outputs":[],"execution_count":22},{"cell_type":"code","metadata":{"_id":"E4DACC48ADEB4751A8F423D845BAD761","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A42ECA07516A4F879F10051B5A931A95","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 进行先验预测检验并输出\ndef prior_predictive_check(model, samples=50, random_seed=43201):\n    model_prior_check = pm.sample_prior_predictive(\n        samples=samples,\n        model=model,\n        var_names=[\"mu\",\"sigma\"],\n        random_seed=random_seed\n    )\n\n    fig, ax = plt.subplots(1, 2, figsize = (15,5))\n    fig.suptitle(\"Prior predictive check\")\n    ax[0].set_title(\"mu\")\n    az.plot_dist(model_prior_check.prior[\"mu\"], ax=ax[0])\n\n    ax[1].set_title(\"sigma\")\n    az.plot_dist(model_prior_check.prior[\"sigma\"], ax=ax[1])\n\n    return fig","outputs":[],"execution_count":23},{"cell_type":"code","metadata":{"_id":"588C6B41397A4E0C97561726DEC29043","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"882FA1DBD78D4FA18A49C54938182528","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 进行采样\ndef model_sampling(model):\n    trace = pm.sample(draws=2000,            # 使用mcmc方法进行采样，draws为采样次数\n                    tune=1000,                    # tune为调整采样策略的次数，可以决定这些结果是否要被保留\n                    chains=4,                     # 链数\n                    cores=4,\n                    discard_tuned_samples= True,  # tune的结果将在采样结束后被丢弃\n                    random_seed=43201,\n                    target_accept=0.8,\n                    model=model)\n    return trace","outputs":[],"execution_count":24},{"cell_type":"code","metadata":{"_id":"D11C4A0008AB4D448062CDB590442189","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"DABE830946A4436F889420FC1A668CEA","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 对重测信度参数进行总结\ndef diagnostic_summary(trace, model_name):\n    diagnostic = az.plot_trace(trace,\n                               var_names = [\"rho_R_mu\", \"rho_R_sigma\"],\n                               figsize=(15,10))\n    hdi_sum = az.summary(trace, \n                        var_names =[\"rho_R_mu\", \"rho_R_sigma\"],\n                        hdi_prob = 0.95)\n    hdi_sum = hdi_sum[[\"mean\",\"hdi_2.5%\",\"hdi_97.5%\"]]\n\n    hdi_sum.index = pd.MultiIndex.from_arrays([[f'{model_name}'] * len(hdi_sum.index), hdi_sum.index])\n    return diagnostic, hdi_sum","outputs":[],"execution_count":25},{"cell_type":"code","metadata":{"_id":"0379C2C73849471AA886D791F5D6C7F5","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"EFF8CCEF89AB4997BD4078225A79F780","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 集合需要的结果并输出\nimport gc\n\ndef result_output(data, distribution, model_name):\n    model = process_model(data=data, distribution=distribution)\n    prior_plot = prior_predictive_check(model, samples=50, random_seed=43201)\n    trace = model_sampling(model)\n    diag, hdi = diagnostic_summary(trace, model_name)\n    del trace\n    gc.collect()\n    return diag, hdi, prior_plot","outputs":[],"execution_count":26},{"cell_type":"code","metadata":{"_id":"C2AA0F5D7008496C8C6B8A45E5CDBF04","jupyter":{},"collapsed":false,"scrolled":true,"tags":[],"slideshow":{"slide_type":"slide"},"id":"A6F0BF8EB8CF43AEA448A74AED1D043B","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 使用4核16G的计算资源，运行以下代码，需要约2小时\ndiag_logshift, hdi_logshift, priorplot_logshift = result_output(df_model, \"log_shift\",\"Shifted Lognormal\")","outputs":[{"output_type":"display_data","data":{"text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m3:06:42\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">3:06:42</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11203 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A6F0BF8EB8CF43AEA448A74AED1D043B/sjbygmodn6.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1000 with 4 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/A6F0BF8EB8CF43AEA448A74AED1D043B/sjbygn8y3z.png\">"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","metadata":{"_id":"29EBE4DDF8804D5FBA3B6E2E711CE8C8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"7B2340339095410C9A514062238E171C","notebookId":"66d83816136d01cc20208d4c"},"source":"### Two-Stage model vs. Shifted Lognormal model  \n\n与Two-Stage model相比，Shifted Lognormal model具有更高的信度。"},{"cell_type":"code","metadata":{"_id":"6FC61907BC7844DDA03B074BF801130B","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"841040713C1C446BA0D5C9C697824FF5","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"# 对变量名进行修改\ndef rename_hdi(data):\n    data = data.reset_index()\n    data[\"level_1\"] = data[\"level_1\"].replace({'rho_R_mu[0]': 'mu', 'rho_R_sigma[0]': 'sigma'})\n    return data\nhdi_logshift = rename_hdi(hdi_logshift)","outputs":[],"execution_count":28},{"cell_type":"code","metadata":{"_id":"A1C7B10830DE4EB2A7231D8C1C516AD5","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"ABBE09B95EB14405AFA13EA30FF91825","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"#选择mu的重测信度参数进行绘制\nplot = pd.concat([trad_result, hdi_logshift])\nplot = plot[plot['level_1'] == 'mu']\nplot","outputs":[{"output_type":"execute_result","data":{"text/plain":"             level_0 level_1      mean  hdi_2.5%  hdi_97.5%\n0          Two-Stage      mu  0.317663  0.033557   0.554268\n0  Shifted Lognormal      mu  0.711000  0.442000   0.952000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>level_1</th>\n      <th>mean</th>\n      <th>hdi_2.5%</th>\n      <th>hdi_97.5%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Two-Stage</td>\n      <td>mu</td>\n      <td>0.317663</td>\n      <td>0.033557</td>\n      <td>0.554268</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Shifted Lognormal</td>\n      <td>mu</td>\n      <td>0.711000</td>\n      <td>0.442000</td>\n      <td>0.952000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":29}],"execution_count":29},{"cell_type":"code","metadata":{"_id":"B7567741B14145279BA479D78F257736","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C16DAA627BC744E9B33C626C02BB4466","notebookId":"66d83816136d01cc20208d4c","trusted":true},"source":"plt.figure(figsize=(6,3), dpi=150)\n\n# 计算可信区间\nci = [plot['mean'] - plot['hdi_2.5%'], plot['hdi_97.5%'] - plot['mean']]\n\n# 通过error bar的形式展现区间和均值\nplt.errorbar(x=plot['mean'], y=plot['level_0'], xerr=ci,\n                color='black', capsize=3, linestyle='None', linewidth=1,\n                marker=\"o\", markersize=5, mfc=\"black\", mec=\"black\")\n\n# 调整y轴的刻度使其更集中\nplt.gca().set_ylim(-0.5, len(plot['level_0']) - 0.5)  # Adjust based on your data\n\n# 添加标题\nplt.xlabel('Test-Retest Correlation', fontsize=8)\n\nsns.despine()","outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 900x450 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/C16DAA627BC744E9B33C626C02BB4466/sjbygncfq3.png\">"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","metadata":{"_id":"A163F9FE53034CE6AE6832BD1AD6403B","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"517BC30F8DAB4AC0976EEC161789B116","notebookId":"66d83816136d01cc20208d4c"},"source":"## 例3: 贝叶斯推断在认知模型中的应用  \n\n在实验数据的收集时，研究者往往会采集个体反应的正确率与反应时。  \n\n而传统分析方法并不能同时对两种数据进行分析，从而推断潜在的认知机制。比如，个体是否愿意牺牲更多的反应时间去获得一个更准确的判断。  \n"},{"cell_type":"markdown","metadata":{"_id":"53C36B066F3A4BE1897D78A71B8C4836","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C3F4218811B44324B862B86D58C84F4D","notebookId":"66d83816136d01cc20208d4c"},"source":"**认知模型能有效的弥补这一问题，比如 drift-diffusion model, DDM。**  \n\n\n![Image Name](https://cdn.kesci.com/upload/sj8vp25j27.jpeg?imageView2/0/w/960/h/960)  \n\n"},{"cell_type":"markdown","metadata":{"_id":"A9006F98E02642B5AAB38A37EC3B2CEA","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"72FEDEC424564CB1A286FC7282FDFCFE","notebookId":"66d83816136d01cc20208d4c"},"source":"<center><span style=\"font-size: 68px;\">Part 3: About this course  </span></center>"},{"cell_type":"markdown","metadata":{"_id":"2D63626B86E64EFFB3986F244A530521","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"0DAE924A00E1451B9E2DD280B42996E5","notebookId":"66d83816136d01cc20208d4c"},"source":"### 2. 课程内容  \n#### 2.0 课时  \n9.06 ～ 1.03，18周，十一假期和秋季运动会可能会被放假一次  \n\n#### 2.1 教学目标：  \n\n（1）使用Python进行基本的数据处理  \n\n（2）理解贝叶斯推断的基本原理；  \n\n（2）了解PyMC3的语法和结构，并能应用于相对简单的情境  "},{"cell_type":"markdown","metadata":{"_id":"18C8E526751D4A33907A1243716694C5","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"5FADE0196F6A49D594379E6FA08FBA48","notebookId":"66d83816136d01cc20208d4c"},"source":"\n### 2.2 考核方式：  \n\n### 考勤(10%) + 3次小作业 (45%) + 大作业 (45%)   "},{"cell_type":"markdown","metadata":{"_id":"761874B9E47F43B383525FFEBF659246","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"AC1A2E517AB545C18E01B121824B6B78","notebookId":"66d83816136d01cc20208d4c"},"source":"#### 大作业  \n\n大作业要求  \n\n* 真实的数据分析，数据来源：  \n  * Science: https://www.science.org/  \n  * Science advances: https://www.science.org/journal/sciadv  \n  * Nature: https://www.nature.com/  \n  * Nature human behaviour：https://www.nature.com/nathumbehav/  \n  * Nature communications: https://www.nature.com/ncomms/  \n  * Psychological Science: https://journals.sagepub.com/home/pss  \n  * Cognition: https://www.sciencedirect.com/journal/cognition  \n  * Collabra: Psychology: https://online.ucpress.edu/collabra  \n* 合作完成 (每个小组3-5人, 可自行组队或随机分配)  \n\n大作业提交内容  \n\n* 代码 (对公开数据进行完整分析的代码，使用贝叶斯统计方法，具有可重复性，有注释和文档说明)  \n\t* 如果原文章使用非贝叶斯方法，可以考虑先重复原文档的分析，再进行贝叶斯分析。  \n* 与文字报告 (包括标题，摘要，研究背景或研究问题，研究方法，分析结果，结论六个主要部分)  \n* 进行汇报 (使用 PPT 汇报对研究问题和代码的分析过程进行汇报)  \n\n大作业评分标准  \n* 分工合理、数据分析流程完整、汇报展示清晰美观"},{"cell_type":"markdown","metadata":{"_id":"EF60A81CC874472DBFEF3998F5131BD0","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"56659BCC66C84D71920DB92500DC4D90","notebookId":"66d83816136d01cc20208d4c"},"source":"\n### 2.3 课程风格：  \n\t（1）内容有挑战、考核不复杂  \n\t（2）1/3一节课展示或互动抄代码  \n\t（3）专门设有答疑时间，助教给大家答疑解惑  \n\n\n"},{"cell_type":"markdown","metadata":{"_id":"D3222771EBA840BFA5A0B1FCFF1E612D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"C4F671D90CD142F5A157D00B8F29EEAC","notebookId":"66d83816136d01cc20208d4c"},"source":"\n### 2.4 课程大纲  \n### Intro  \n1: 课程介绍（为什么要用贝叶斯/PyMC3，展示一个贝叶斯因子和贝叶斯层级模型例子，课程安排）  \n\n### I Basics：  \n2: 贝叶斯公式  \n* 单一事件的贝叶斯模型(先验、似然、分母和后验)  \n* 随机变量的贝叶斯模型(先验、似然、分母和后验)  \n\n3: 建立一个完成的贝叶斯模型：Beta-Binomial model  \n* Beta先验  \n* Binomial与似然  \n* Beta-Binomial model  \n\n4: 贝叶斯模型的特点：数据-先验与动态更新  \n* 先验与数据对后验的影响  \n* 数据顺序不影响后验  \n\n5: 经典的贝叶斯模型：Conjugate families  \n* Gamma-Poisson  \n* Normal-Normal  \n\n### II 近似后验估计  \n6: 近似后验的方法  \n* 网格法  \n* MCMC  \n\n7: 深入一种MCMC算法  \n* M-H 算法  \n\n8: 基于后验的推断  \n* 后验估计  \n* 假设检验  \n* 后验预没  \n\n### III Bayesian回归模型  \n9: 简单的Bayesian线性回归模型  \n* 建立模型  \n* 调整先验  \n* 近似后验  \n* 基于近似后验的推断  \n* 序列分析  \n\n10: 对回归模型的评估  \n* 评估模型的标准  \n* 对简单线性模型的估计  \n  \n11: 扩展的线性模型  \n* 多自变量的线性回归  \n\n12: GLM: Bayes factors  \n\n13: GLM: Logistic Regression  \n\n14: Hierachical Bayesian Model 1  \n\n15: Hierachical Bayesian Model 2"},{"cell_type":"markdown","metadata":{"_id":"64CD1073F7F041D08FE0CFF3082A7534","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"03F3F2DD1C59449EAFC006363FCC4CAC","notebookId":"66d83816136d01cc20208d4c"},"source":"### 2.5 参考书  \n\n#### 1. 英文教材：  \n\n![Image Name](https://cdn.kesci.com/upload/sj8izbv81l.png?imageView2/0/w/960/h/960)  \n\n\n#### 2. 中文教材：  \n\n![Image Name](https://cdn.kesci.com/upload/sj8iytode2.png?imageView2/0/w/320/h/320)  \n"},{"cell_type":"markdown","metadata":{"_id":"76542B79E6944D39905C62B010B8459D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8B5F9CE0D87C47658E6A55FE9D6600F8","notebookId":"66d83816136d01cc20208d4c"},"source":"### 2.6 课程好帮手（AI工具）  \n\n- 如果你有问题，除了可以向老师和助教寻求帮助，还可以使用AI工具。  \n- 这款工具是为贝叶斯课程特别定制的，免费且无需翻墙。  \n\n<p align=\"center\">  \n  <img src=\"https://cdn.kesci.com/upload/sj6zpgijv9.jpeg?imageView2/0/w/960/h/960\" alt=\"Image Name\" />  \n</p>"},{"cell_type":"markdown","metadata":{"_id":"746B6B55BFEA43E89E94158603BDAB2D","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"95906B7445D74F2C857A3BCBDDE5A2D6","notebookId":"66d83816136d01cc20208d4c"},"source":"<center><span style=\"font-size: 68px;\">THANK YOU  </span></center>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}